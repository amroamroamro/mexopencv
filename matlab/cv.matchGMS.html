<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
   
      <link rel="stylesheet" href="helpwin.css" />
      <title>cv.matchGMS - mexopencv</title>
   <link rel="stylesheet" type="text/css" href="helpwin_custom.css" />
<meta name="generator" content="MATLAB 9.4.0.902940 (R2018a) Update 4" />
<meta name="description" content="cv.matchGMS - GMS (Grid-based Motion Statistics) feature matching strategy" />
<link rel="stylesheet" type="text/css" href="matlab.min.css" />
</head>
   <body onload="PR.prettyPrint();">
      <!--Single-page help-->
      <table border="0" cellspacing="0" width="100%">
         <tbody><tr class="subheader">
            <td class="headertitle">cv.matchGMS - MATLAB File Help</td>
            <td class="subheader-right"></td>
         </tr>
      </tbody></table>
      <div class="title">cv.matchGMS</div>
      <div class="helpcontent"><p class=" h1line">GMS (Grid-based Motion Statistics) feature matching strategy</p>
<pre class=" prettyprint lang-matlab"><code>matchesGMS = <a href="cv.matchGMS.html">cv.matchGMS</a>(size1, keypoints1, size2, keypoints2, matches1to2)
matchesGMS = <a href="cv.matchGMS.html">cv.matchGMS</a>(..., 'OptionName', optionValue, ...)
</code></pre>
<h2>Input</h2>
<ul>
<li><strong>size1</strong> Size of first image <code>[w,h]</code>.</li>
<li><strong>keypoints1</strong> Keypoints from the first source image. A 1-by-N structure
array with the following fields:
<ul>
<li><strong>pt</strong> coordinates of the keypoint <code>[x,y]</code></li>
<li><strong>size</strong> diameter of the meaningful keypoint neighborhood</li>
<li><strong>angle</strong> computed orientation of the keypoint (-1 if not applicable).
Its possible values are in a range [0,360) degrees. It is measured
relative to image coordinate system (y-axis is directed downward), i.e
in clockwise.</li>
<li><strong>response</strong> the response by which the most strong keypoints have been
selected. Can be used for further sorting or subsampling.</li>
<li><strong>octave</strong> octave (pyramid layer) from which the keypoint has been
extracted.</li>
<li><strong>class_id</strong> object id that can be used to clustered keypoints by an
object they belong to.</li>
</ul>
</li>
<li><strong>size2</strong> Size of second image <code>[w,h]</code>.</li>
<li><strong>keypoints2</strong> Keypoints from the second source image. Same format as
<code>keypoints1</code>.</li>
<li><strong>matches1to2</strong> Input 1-nearest neighbor matches from the first image to
the second one. A 1-by-M structure array with the following fields:
<ul>
<li><strong>queryIdx</strong> query descriptor index (zero-based index)</li>
<li><strong>trainIdx</strong> train descriptor index (zero-based index)</li>
<li><strong>imgIdx</strong> train image index (zero-based index)</li>
<li><strong>distance</strong> distance between descriptors (scalar)</li>
</ul>
</li>
</ul>
<h2>Output</h2>
<ul>
<li><strong>matchesGMS</strong> Matches returned by the GMS matching strategy.</li>
</ul>
<h2>Options</h2>
<ul>
<li><strong>WithRotation</strong> Take rotation transformation into account. default false</li>
<li><strong>WithScale</strong> Take scale transformation into account. default false</li>
<li><strong>ThresholdFactor</strong> The higher, the less matches. default 6.0</li>
</ul>
<p>GMS feature matching strategy by [Bian2017gms].</p>
<h2>Notes</h2>
<ul>
<li>Since GMS works well when the number of features is large, we recommend to
use <a href="cv.ORB.html">cv.ORB</a> features and set <code>FastThreshold</code> to 0 to get as many features
as possible quickly.</li>
<li>If matching results are not satisfying, please add more features (we use
10000 for images with 640x480 size).</li>
<li>If your images have big rotation and scale changes, please set
<code>WithRotation</code> or <code>WithScale</code> to true.</li>
</ul>
<h2>References</h2>
<p>[Bian2017gms]:</p>
<blockquote>
<p>JiaWang Bian, Wen-Yan Lin, Yasuyuki Matsushita, Sai-Kit Yeung, Tan Dat
Nguyen, and Ming-Ming Cheng. &quot;GMS: Grid-based motion statistics for fast,
ultra-robust feature correspondence&quot;.
In IEEE Conference on Computer Vision and Pattern Recognition, 2017.</p>
</blockquote>
</div><!--after help --><!--seeAlso--><div class="footerlinktitle">See also</div><div class="footerlink"> <a href="cv.FeatureDetector.html">cv.FeatureDetector</a>, <a href="cv.DescriptorMatcher.html">cv.DescriptorMatcher</a>, <a href="cv.drawMatches.html">cv.drawMatches</a></div>
   
<script type="text/javascript" src="prettify.js"></script>
<script type="text/javascript" src="lang-matlab.min.js"></script>
</body></html>