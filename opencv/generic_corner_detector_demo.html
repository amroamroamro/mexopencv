<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>Corner Detection</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="generic_corner_detector_demo.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">Corner Detection</h1>
         <!--introduction-->
         <p>In this demo we will understand concepts behind Harris Corner Detection, by learning what features are and why they are important,
            and how to use the function <tt>cv.cornerHarris</tt> to detect corners using the Harris-Stephens method. We also learn about another corner detector, the Shi-Tomasi Corner Detector,
            and how to use the function <tt>cv.goodFeaturesToTrack</tt>.
         </p>
         <p>In addition, we show how to:</p>
         <div>
            <ul>
               <li>Use the OpenCV function <tt>cv.cornerEigenValsAndVecs</tt> to find the   eigenvalues and eigenvectors to determine if a pixel is a corner.
               </li>
               <li>Use the OpenCV function <tt>cv.cornerMinEigenVal</tt> to find the minimum   eigenvalues for corner detection.
               </li>
               <li>To implement our own version of the Harris detector as well as the   Shi-Tomasi detector, by using the two functions above.</li>
            </ul>
         </div>
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://docs.opencv.org/3.2.0/d9/dbc/tutorial_generic_corner_detector.html">https://docs.opencv.org/3.2.0/d9/dbc/tutorial_generic_corner_detector.html</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/d4/d7d/tutorial_harris_detector.html">https://docs.opencv.org/3.2.0/d4/d7d/tutorial_harris_detector.html</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/dc/d0d/tutorial_py_features_harris.html">https://docs.opencv.org/3.2.0/dc/d0d/tutorial_py_features_harris.html</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/d4/d8c/tutorial_py_shi_tomasi.html">https://docs.opencv.org/3.2.0/d4/d8c/tutorial_py_shi_tomasi.html</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/TrackingMotion/cornerDetector_Demo.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/TrackingMotion/cornerDetector_Demo.cpp</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/TrackingMotion/cornerHarris_Demo.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/TrackingMotion/cornerHarris_Demo.cpp</a></li>
            </ul>
         </div>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Theory</a></li>
               <li><a href="#3">Implementation</a></li>
               <li><a href="#4">Code</a></li>
               <li><a href="#8">cv.cornerEigenValsAndVecs, cv.cornerMinEigenVal</a></li>
               <li><a href="#15">cv.goodFeaturesToTrack</a></li>
               <li><a href="#17">cv.cornerHarris</a></li>
            </ul>
         </div>
         <h2 id="2">Theory</h2>
         <p>In computer vision, usually we need to find matching points between different frames of an environment. Why? If we know how
            two images relate to each other, we can use <i>both</i> images to extract information of them. When we say <b>matching points</b> we are referring, in a general sense, to <i>characteristics</i> in the scene that we can recognize easily. We call these characteristics <b>features</b>. So, what characteristics should a feature have? It must be <i>uniquely recognizable</i>.
         </p>
         <p>To mention a few image features:</p>
         <div>
            <ul>
               <li>Edges</li>
               <li><b>Corners</b> (also known as interest points)
               </li>
               <li>Blobs (also known as regions of interest)</li>
            </ul>
         </div>
         <p>In this tutorial we will study the <i>corner</i> features, specifically.
         </p>
         <p>Why is a corner so special? Because, since it is the intersection of two edges, it represents a point in which the directions
            of these two edges <i>change</i>. Hence, the gradient of the image (in both directions) have a high variation, which can be used to detect it.
         </p>
         <p>To see how it works, let's look for corners. Since corners represents a variation in the gradient in the image, we will look
            for this "variation". Consider a grayscale image <img src="generic_corner_detector_demo_eq17419315245227113761.png" alt="$I$" class="equation" width="7" height="10">. We are going to sweep a window <img src="generic_corner_detector_demo_eq10831252136345246685.png" alt="$w(x,y)$" class="equation" width="44" height="15"> over <img src="generic_corner_detector_demo_eq17419315245227113761.png" alt="$I$" class="equation" width="7" height="10"> (with displacements <img src="generic_corner_detector_demo_eq11776305044305525613.png" alt="$u$" class="equation" width="8" height="7"> in the x direction and <img src="generic_corner_detector_demo_eq03158747792916826732.png" alt="$v$" class="equation" width="7" height="7"> in the y direction) and will calculate the variation of intensity.
         </p>
         <p><img src="generic_corner_detector_demo_eq06095406263217454108.png" alt="$$E(u,v) = \sum_{x,y} w(x,y)[ I(x+u,y+v) - I(x,y)]^{2}$$" class="equation" width="300" height="34"></p>
         <p>where:</p>
         <div>
            <ul>
               <li><img src="generic_corner_detector_demo_eq10831252136345246685.png" alt="$w(x,y)$" class="equation" width="44" height="15"> is the window at position <img src="generic_corner_detector_demo_eq18047527249248817779.png" alt="$(x,y)$" class="equation" width="32" height="15"></li>
               <li><img src="generic_corner_detector_demo_eq03744512032217266162.png" alt="$I(x,y)$" class="equation" width="40" height="15"> is the intensity at <img src="generic_corner_detector_demo_eq18047527249248817779.png" alt="$(x,y)$" class="equation" width="32" height="15"></li>
               <li><img src="generic_corner_detector_demo_eq12492155917327147991.png" alt="$I(x+u,y+v)$" class="equation" width="92" height="15"> is the intensity at the moved window <img src="generic_corner_detector_demo_eq14368554001786154424.png" alt="$(x+u,y+v)$" class="equation" width="84" height="15"></li>
            </ul>
         </div>
         <p>Since we are looking for windows with corners, we are looking for windows with a large variation in intensity. Hence, we have
            to maximize the equation above, specifically the term:
         </p>
         <p><img src="generic_corner_detector_demo_eq09405110683161253490.png" alt="$$\sum_{x,y}[ I(x+u,y+v) - I(x,y)]^{2}$$" class="equation" width="187" height="34"></p>
         <p>Using <i>Taylor expansion</i>:
         </p>
         <p><img src="generic_corner_detector_demo_eq00166035168561325943.png" alt="$$E(u,v) \approx \sum_{x,y}[ I(x,y) + u I_{x} + vI_{y} - I(x,y)]^{2}$$" class="equation" width="278" height="34"></p>
         <p>Here, <img src="generic_corner_detector_demo_eq11508508002233644711.png" alt="$I_x$" class="equation" width="12" height="13"> and <img src="generic_corner_detector_demo_eq05960738100551949621.png" alt="$I_y$" class="equation" width="12" height="15"> are image derivatives in x and y directions respectively (can be easily found out using <tt>cv.Sobel</tt>).
         </p>
         <p>Expanding the equation and cancelling properly:</p>
         <p><img src="generic_corner_detector_demo_eq01966179423898845865.png" alt="$$E(u,v) \approx \sum_{x,y} u^{2}I_{x}^{2} + 2uvI_{x}I_{y} + v^{2}I_{y}^{2}$$" class="equation" width="227" height="34"></p>
         <p>Which can be expressed in a matrix form as:</p>
         <p><img src="generic_corner_detector_demo_eq15837514206292299029.png" alt="$$E(u,v) \approx&#xA;      \left[{\matrix{ u &amp; v }}\right]&#xA;      \left(&#xA;          \displaystyle \sum_{x,y} w(x,y)&#xA;          \left[{\matrix{&#xA;              I_x^{2} &amp; I_{x}I_{y} \cr&#xA;              I_xI_{y} &amp; I_{y}^{2}&#xA;          }}\right]&#xA;      \right)&#xA;      \left[{\matrix{ u \cr v }}\right]$$" class="equation" width="320" height="46"></p>
         <p>Let's denote:</p>
         <p><img src="generic_corner_detector_demo_eq13833875665358739059.png" alt="$$M = \displaystyle \sum_{x,y} w(x,y)&#xA;      \left[{\matrix{&#xA;          I_x^{2} &amp; I_{x}I_{y} \cr&#xA;          I_xI_{y} &amp; I_{y}^{2}&#xA;      }}\right]$$" class="equation" width="189" height="41"></p>
         <p>So, our equation now is:</p>
         <p><img src="generic_corner_detector_demo_eq04572398278844787798.png" alt="$$E(u,v) \approx&#xA;      \left[{\matrix{ u &amp; v }}\right]&#xA;       M&#xA;      \left[{\matrix{ u \cr v }}\right]$$" class="equation" width="155" height="36"></p>
         <p>A score is calculated for each window, to determine if it can possibly contain a corner:</p>
         <p><img src="generic_corner_detector_demo_eq05276907097150755556.png" alt="$$R = det(M) - k(trace(M))^{2}$$" class="equation" width="181" height="17"></p>
         <p>where:</p>
         <div>
            <ul>
               <li><img src="generic_corner_detector_demo_eq00662172799527216231.png" alt="$det(M) = \lambda_{1}\lambda_{2}$" class="equation" width="94" height="15"></li>
               <li><img src="generic_corner_detector_demo_eq11056235369408140952.png" alt="$trace(M) = \lambda_{1}+\lambda_{2}$" class="equation" width="126" height="15"></li>
               <li><img src="generic_corner_detector_demo_eq03591910203080329667.png" alt="$\lambda_{1}$" class="equation" width="13" height="13"> and <img src="generic_corner_detector_demo_eq18332970384824971791.png" alt="$\lambda_{2}$" class="equation" width="13" height="13"> are the eigen values of <img src="generic_corner_detector_demo_eq00802513524912003067.png" alt="$M$" class="equation" width="15" height="10"></li>
            </ul>
         </div>
         <p>a window with a score <img src="generic_corner_detector_demo_eq03442895190380135198.png" alt="$R$" class="equation" width="11" height="11"> greater than a certain value is considered a "corner".
         </p>
         <p>So the values of these eigen values decide whether a region is corner, edge or flat:</p>
         <div>
            <ul>
               <li>When <img src="generic_corner_detector_demo_eq10733207077195231665.png" alt="$|R|$" class="equation" width="16" height="15"> is small, which happens when <img src="generic_corner_detector_demo_eq06952556603745606606.png" alt="$\lambda_1$" class="equation" width="13" height="13"> and <img src="generic_corner_detector_demo_eq01939127397082388770.png" alt="$\lambda_2$" class="equation" width="13" height="13"> are   small, the region is flat.
               </li>
               <li>When <img src="generic_corner_detector_demo_eq12731800755172280658.png" alt="$R<0$" class="equation" width="37" height="11">, which happens when <img src="generic_corner_detector_demo_eq07029778206336949046.png" alt="$\lambda_1 \gg \lambda_2$" class="equation" width="51" height="13"> or vice versa,   the region is edge.
               </li>
               <li>When <img src="generic_corner_detector_demo_eq03442895190380135198.png" alt="$R$" class="equation" width="11" height="11"> is large, which happens when <img src="generic_corner_detector_demo_eq06952556603745606606.png" alt="$\lambda_1$" class="equation" width="13" height="13"> and <img src="generic_corner_detector_demo_eq01939127397082388770.png" alt="$\lambda_2$" class="equation" width="13" height="13"> are   large and <img src="generic_corner_detector_demo_eq17848729820906342901.png" alt="$\lambda_1 \sim \lambda_2$" class="equation" width="47" height="13">, the region is a corner.
               </li>
            </ul>
         </div>
         <p>It can be represented in a nice picture as follows:</p>
         <p><img src="https://docs.opencv.org/3.2.0/harris_region.jpg"></p>
         <p>So the result of Harris Corner Detection is a grayscale image with these scores. Thresholding for a suitable give you the
            corners in the image.
         </p>
         <p>A modification was later made in 1994 by J. Shi and C. Tomasi it in their paper "Good Features to Track" which showed better
            results compared to the Harris Corner Detector. The scoring function in Harris Corner Detector was given by:
         </p>
         <p><img src="generic_corner_detector_demo_eq04066445042086111087.png" alt="$$R = \lambda_1 \lambda_2 - k(\lambda_1+\lambda_2)^2$$" class="equation" width="149" height="17"></p>
         <p>Instead of this, Shi-Tomasi proposed:</p>
         <p><img src="generic_corner_detector_demo_eq03853601115946263816.png" alt="$$R = min(\lambda_1, \lambda_2)$$" class="equation" width="103" height="15"></p>
         <p>If it is greater than a threshold value, it is considered as a corner. If we plot it in <img src="generic_corner_detector_demo_eq03490318115994957767.png" alt="$\lambda_1 - \lambda_2$" class="equation" width="46" height="13"> space as we did in Harris Corner Detector, we get an image as below:
         </p>
         <p><img src="https://docs.opencv.org/3.2.0/shitomasi_space.png"></p>
         <p>From the figure, you can see that only when <img src="generic_corner_detector_demo_eq06952556603745606606.png" alt="$\lambda_1$" class="equation" width="13" height="13"> and <img src="generic_corner_detector_demo_eq01939127397082388770.png" alt="$\lambda_2$" class="equation" width="13" height="13"> are above a minimum value, <img src="generic_corner_detector_demo_eq16305500928493069936.png" alt="$\lambda_{min}$" class="equation" width="27" height="13">, it is conidered as a corner (green region).
         </p>
         <h2 id="3">Implementation</h2>
         <p>OpenCV has a function, <tt>cv.goodFeaturesToTrack</tt>. It finds N strongest corners in the image by Shi-Tomasi method (or Harris Corner Detection, if you specify it). As usual,
            image should be a grayscale image. Then you specify number of corners you want to find. Then you specify the quality level,
            which is a value between 0-1, which denotes the minimum quality of corner below which everyone is rejected. Then we provide
            the minimum euclidean distance between corners detected.
         </p>
         <p>With all these informations, the function finds corners in the image. All corners below quality level are rejected. Then it
            sorts the remaining corners based on quality in the descending order. Then function takes first strongest corner, throws away
            all the nearby corners in the range of minimum distance and returns N strongest corners.
         </p>
         <p>This function is a good choice for tracking applications.</p>
         <h2 id="4">Code</h2>
         <p>Options</p><pre class="codeinput">blockSz = 3;
apertureSz = 3;
k = 0.04;
qualityLevel = 50;  <span class="comment">% pick a value in the [1,100] range</span></pre><p>Params for drawing circles</p><pre class="codeinput">opts = {3, <span class="string">'Color'</span>,[255 0 0], <span class="string">'Thickness'</span>,<span class="string">'Filled'</span>};
params = {<span class="string">'LineStyle'</span>,<span class="string">'none'</span>, <span class="string">'Marker'</span>,<span class="string">'o'</span>, <span class="string">'MarkerSize'</span>,8, <span class="string">'Color'</span>,<span class="string">'r'</span>};</pre><p>Load source image and convert it to gray</p><pre class="codeinput">src = cv.imread(fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'blox.jpg'</span>), <span class="string">'Color'</span>,true);
gray = cv.cvtColor(src, <span class="string">'RGB2GRAY'</span>);</pre><h2 id="8">cv.cornerEigenValsAndVecs, cv.cornerMinEigenVal</h2>
         <p>We will implement the steps of Harris and Shi-Tomasi corner detectors by computing eigenvalues/eigenvectors of the Harris
            matrix (covariance matrix of image partial derivatives in local neighborhoods)
         </p><pre class="codeinput">ev_Harris = cv.cornerEigenValsAndVecs(gray, <span class="string">'BlockSize'</span>,blockSz, <span class="string">'KSize'</span>,apertureSz);
ev_ShiTomasi = cv.cornerMinEigenVal(gray, <span class="string">'BlockSize'</span>,blockSz, <span class="string">'KSize'</span>,apertureSz);</pre><p>Calculate Harris corner response measure: <tt>Mc = lambda1*lambda2 - k*(lambda1 + lambda2)^2</tt></p><pre class="codeinput">Mc_Harris = prod(ev_Harris(:,:,1:2), 3) - k * sum(ev_Harris(:,:,1:2), 3).^2;</pre><p>Shi-Tomasi corner response measure: <tt>Mc = min(lambda1, lambda2)</tt></p><pre class="codeinput">Mc_ShiTomasi = min(ev_Harris(:,:,1:2), [], 3);
err = norm(abs(ev_ShiTomasi - Mc_ShiTomasi))  <span class="comment">% output of cv.cornerMinEigenVal</span></pre><pre class="codeoutput">err =
  single
  6.9262e-08
</pre><p>Classify image pixels by thresholding the corner response</p><pre class="codeinput">mnH = min(Mc_Harris(:));
mxH = max(Mc_Harris(:));
mnST = min(Mc_ShiTomasi(:));
mxST = max(Mc_ShiTomasi(:));

<span class="comment">% find locatiosn where response is above threshold</span>
mask_Harris = Mc_Harris &gt; (mnH + (mxH - mnH)*qualityLevel/100);
mask_ShiTomasi = Mc_ShiTomasi &gt; (mnST + (mxST - mnST)*qualityLevel/100);</pre><p>Corresponding corner locations</p><pre class="codeinput">sz = size(Mc_Harris);
[X,Y] = meshgrid(1:sz(2), 1:sz(1));
pts_Harris = [X(mask_Harris) Y(mask_Harris)];
pts_ShiTomasi = [X(mask_ShiTomasi) Y(mask_ShiTomasi)];</pre><p>Draw circles around corners and show results</p><pre class="codeinput">figure(1)
out = cv.circle(src, pts_Harris, opts{:});
subplot(121), imshow(out), title(<span class="string">'My Harris'</span>)
out = cv.circle(src, pts_ShiTomasi, opts{:});
subplot(122), imshow(out), title(<span class="string">'My Shi-Tomasi'</span>)</pre><img src="generic_corner_detector_demo_01.png"><p>Show corner response maps</p><pre class="codeinput">figure(2)
subplot(121), imshow(Mc_Harris, []), title(<span class="string">'Harris response'</span>)
line(pts_Harris(:,1), pts_Harris(:,2), params{:})
subplot(122), imshow(Mc_ShiTomasi, []), title(<span class="string">'Shi-Tomasi response'</span>)
line(pts_ShiTomasi(:,1), pts_ShiTomasi(:,2), params{:})</pre><img src="generic_corner_detector_demo_02.png"><h2 id="15">cv.goodFeaturesToTrack</h2>
         <p>Compare against builtin function, note that "quality level" is interpreterd a bit differently, plus the implementation does
            additional processing (non-max suppression)
         </p><pre class="codeinput">ptsH = cv.goodFeaturesToTrack(gray, <span class="string">'UseHarrisDetector'</span>,true, <span class="string">'K'</span>,k, <span class="keyword">...</span>
    <span class="string">'QualityLevel'</span>,qualityLevel/100, <span class="string">'BlockSize'</span>,blockSz);
ptsST = cv.goodFeaturesToTrack(gray, <span class="string">'UseHarrisDetector'</span>,false, <span class="keyword">...</span>
    <span class="string">'QualityLevel'</span>,qualityLevel/100, <span class="string">'BlockSize'</span>,blockSz);
ptsH = cat(1, ptsH{:});
ptsST = cat(1, ptsST{:});</pre><p>Draw corners</p><pre class="codeinput">figure(3)
out = cv.circle(src, ptsH, opts{:});
subplot(121), imshow(out), title(<span class="string">'Harris corner detector'</span>)
out = cv.circle(src, ptsST, opts{:});
subplot(122), imshow(out), title(<span class="string">'Shi-Tomasi corner detector'</span>)</pre><img src="generic_corner_detector_demo_03.png"><h2 id="17">cv.cornerHarris</h2>
         <p>Compare against builtin function</p><pre class="codeinput">Mc = cv.cornerHarris(gray, <span class="string">'K'</span>,k, <span class="string">'BlockSize'</span>,blockSz, <span class="string">'KSize'</span>,apertureSz);
err = norm(abs(Mc_Harris - Mc))</pre><pre class="codeoutput">err =
  single
  1.4702e-09
</pre><p>Another example of thresholding response map to find corners</p><pre class="codeinput">mask = cv.dilate(Mc) &gt; 0.01*max(Mc(:));
out = src(:,:,1);
out(mask) = 255;
out = cat(3, out, src(:,:,2:3));
figure(4), imshow(out), title(<span class="string">'Harris corners'</span>)</pre><img src="generic_corner_detector_demo_04.png"><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div><script type="text/x-mathjax-config">
  // https://stackoverflow.com/a/14631703/97160
  MathJax.Extension.myImg2jax = {
    version: "1.0",
    PreProcess: function (element) {
      var images = element.getElementsByTagName("img");
      for (var i = images.length - 1; i >= 0; i--) {
        var img = images[i];
        if (img.className === "equation") {
          var match = img.alt.match(/^(\$\$?)([\s\S]*)\1$/m);
          if (!match) continue;
          var script = document.createElement("script");
          script.type = "math/tex";
          if (match[1] === "$$") {script.type += ";mode=display"}
          MathJax.HTML.setScript(script, match[2]);
          img.parentNode.replaceChild(script, img);
        }
      }
    }
  };
  MathJax.Hub.Register.PreProcessor(["PreProcess", MathJax.Extension.myImg2jax]);
  </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
      <!--
##### SOURCE BEGIN #####
%% Corner Detection
%
% In this demo we will understand concepts behind Harris Corner Detection, by
% learning what features are and why they are important, and how to use
% the function |cv.cornerHarris| to detect corners using the Harris-Stephens
% method. We also learn about another corner detector, the Shi-Tomasi Corner
% Detector, and how to use the function |cv.goodFeaturesToTrack|.
%
% In addition, we show how to:
%
% * Use the OpenCV function |cv.cornerEigenValsAndVecs| to find the
%   eigenvalues and eigenvectors to determine if a pixel is a corner.
% * Use the OpenCV function |cv.cornerMinEigenVal| to find the minimum
%   eigenvalues for corner detection.
% * To implement our own version of the Harris detector as well as the
%   Shi-Tomasi detector, by using the two functions above.
%
% Sources:
%
% * <https://docs.opencv.org/3.2.0/d9/dbc/tutorial_generic_corner_detector.html>
% * <https://docs.opencv.org/3.2.0/d4/d7d/tutorial_harris_detector.html>
% * <https://docs.opencv.org/3.2.0/dc/d0d/tutorial_py_features_harris.html>
% * <https://docs.opencv.org/3.2.0/d4/d8c/tutorial_py_shi_tomasi.html>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/TrackingMotion/cornerDetector_Demo.cpp>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/TrackingMotion/cornerHarris_Demo.cpp>
%

%% Theory
%
% In computer vision, usually we need to find matching points between
% different frames of an environment. Why? If we know how two images relate to
% each other, we can use _both_ images to extract information of them.
% When we say *matching points* we are referring, in a general sense, to
% _characteristics_ in the scene that we can recognize easily. We call these
% characteristics *features*. So, what characteristics should a feature have?
% It must be _uniquely recognizable_.
%
% To mention a few image features:
%
% * Edges
% * *Corners* (also known as interest points)
% * Blobs (also known as regions of interest)
%
% In this tutorial we will study the _corner_ features, specifically.
%
% Why is a corner so special? Because, since it is the intersection of two
% edges, it represents a point in which the directions of these two edges
% _change_. Hence, the gradient of the image (in both directions) have a high
% variation, which can be used to detect it.
%
% To see how it works, let's look for corners. Since corners represents a
% variation in the gradient in the image, we will look for this "variation".
% Consider a grayscale image $I$. We are going to sweep a window $w(x,y)$
% over $I$ (with displacements $u$ in the x direction and $v$ in the y
% direction) and will calculate the variation of intensity.
%
% $$E(u,v) = \sum_{x,y} w(x,y)[ I(x+u,y+v) - I(x,y)]^{2}$$
%
% where:
%
% * $w(x,y)$ is the window at position $(x,y)$
% * $I(x,y)$ is the intensity at $(x,y)$
% * $I(x+u,y+v)$ is the intensity at the moved window $(x+u,y+v)$
%
% Since we are looking for windows with corners, we are looking for windows
% with a large variation in intensity. Hence, we have to maximize the equation
% above, specifically the term:
%
% $$\sum_{x,y}[ I(x+u,y+v) - I(x,y)]^{2}$$
%
% Using _Taylor expansion_:
%
% $$E(u,v) \approx \sum_{x,y}[ I(x,y) + u I_{x} + vI_{y} - I(x,y)]^{2}$$
%
% Here, $I_x$ and $I_y$ are image derivatives in x and y directions
% respectively (can be easily found out using |cv.Sobel|).
%
% Expanding the equation and cancelling properly:
%
% $$E(u,v) \approx \sum_{x,y} u^{2}I_{x}^{2} + 2uvI_{x}I_{y} + v^{2}I_{y}^{2}$$
%
% Which can be expressed in a matrix form as:
%
% $$E(u,v) \approx
%       \left[{\matrix{ u & v }}\right]
%       \left(
%           \displaystyle \sum_{x,y} w(x,y)
%           \left[{\matrix{
%               I_x^{2} & I_{x}I_{y} \cr
%               I_xI_{y} & I_{y}^{2}
%           }}\right]
%       \right)
%       \left[{\matrix{ u \cr v }}\right]$$
%
% Let's denote:
%
% $$M = \displaystyle \sum_{x,y} w(x,y)
%       \left[{\matrix{
%           I_x^{2} & I_{x}I_{y} \cr
%           I_xI_{y} & I_{y}^{2}
%       }}\right]$$
%
% So, our equation now is:
%
% $$E(u,v) \approx
%       \left[{\matrix{ u & v }}\right]
%        M
%       \left[{\matrix{ u \cr v }}\right]$$
%
% A score is calculated for each window, to determine if it can possibly
% contain a corner:
%
% $$R = det(M) - k(trace(M))^{2}$$
%
% where:
%
% * $det(M) = \lambda_{1}\lambda_{2}$
% * $trace(M) = \lambda_{1}+\lambda_{2}$
% * $\lambda_{1}$ and $\lambda_{2}$ are the eigen values of $M$
%
% a window with a score $R$ greater than a certain value is considered a
% "corner".
%
% So the values of these eigen values decide whether a region is corner, edge
% or flat:
%
% * When $|R|$ is small, which happens when $\lambda_1$ and $\lambda_2$ are
%   small, the region is flat.
% * When $R<0$, which happens when $\lambda_1 \gg \lambda_2$ or vice versa,
%   the region is edge.
% * When $R$ is large, which happens when $\lambda_1$ and $\lambda_2$ are
%   large and $\lambda_1 \sim \lambda_2$, the region is a corner.
%
% It can be represented in a nice picture as follows:
%
% <<https://docs.opencv.org/3.2.0/harris_region.jpg>>
%
% So the result of Harris Corner Detection is a grayscale image with these
% scores. Thresholding for a suitable give you the corners in the image.
%
% A modification was later made in 1994 by J. Shi and C. Tomasi it in their
% paper "Good Features to Track" which showed better results compared to the
% Harris Corner Detector. The scoring function in Harris Corner Detector was
% given by:
%
% $$R = \lambda_1 \lambda_2 - k(\lambda_1+\lambda_2)^2$$
%
% Instead of this, Shi-Tomasi proposed:
%
% $$R = min(\lambda_1, \lambda_2)$$
%
% If it is greater than a threshold value, it is considered as a corner. If
% we plot it in $\lambda_1 - \lambda_2$ space as we did in Harris Corner
% Detector, we get an image as below:
%
% <<https://docs.opencv.org/3.2.0/shitomasi_space.png>>
%
% From the figure, you can see that only when $\lambda_1$ and $\lambda_2$ are
% above a minimum value, $\lambda_{min}$, it is conidered as a corner
% (green region).
%

%% Implementation
%
% OpenCV has a function, |cv.goodFeaturesToTrack|. It finds N strongest
% corners in the image by Shi-Tomasi method (or Harris Corner Detection, if
% you specify it). As usual, image should be a grayscale image. Then you
% specify number of corners you want to find. Then you specify the quality
% level, which is a value between 0-1, which denotes the minimum quality of
% corner below which everyone is rejected. Then we provide the minimum
% euclidean distance between corners detected.
%
% With all these informations, the function finds corners in the image. All
% corners below quality level are rejected. Then it sorts the remaining
% corners based on quality in the descending order. Then function takes first
% strongest corner, throws away all the nearby corners in the range of minimum
% distance and returns N strongest corners.
%
% This function is a good choice for tracking applications.
%

%% Code

%%
% Options
blockSz = 3;
apertureSz = 3;
k = 0.04;
qualityLevel = 50;  % pick a value in the [1,100] range

%%
% Params for drawing circles
opts = {3, 'Color',[255 0 0], 'Thickness','Filled'};
params = {'LineStyle','none', 'Marker','o', 'MarkerSize',8, 'Color','r'};

%%
% Load source image and convert it to gray
src = cv.imread(fullfile(mexopencv.root(),'test','blox.jpg'), 'Color',true);
gray = cv.cvtColor(src, 'RGB2GRAY');

%% cv.cornerEigenValsAndVecs, cv.cornerMinEigenVal
% We will implement the steps of Harris and Shi-Tomasi corner detectors
% by computing eigenvalues/eigenvectors of the Harris matrix
% (covariance matrix of image partial derivatives in local neighborhoods)
ev_Harris = cv.cornerEigenValsAndVecs(gray, 'BlockSize',blockSz, 'KSize',apertureSz);
ev_ShiTomasi = cv.cornerMinEigenVal(gray, 'BlockSize',blockSz, 'KSize',apertureSz);

%%
% Calculate Harris corner response measure:
% |Mc = lambda1*lambda2 - k*(lambda1 + lambda2)^2|
Mc_Harris = prod(ev_Harris(:,:,1:2), 3) - k * sum(ev_Harris(:,:,1:2), 3).^2;

%%
% Shi-Tomasi corner response measure:
% |Mc = min(lambda1, lambda2)|
Mc_ShiTomasi = min(ev_Harris(:,:,1:2), [], 3);
err = norm(abs(ev_ShiTomasi - Mc_ShiTomasi))  % output of cv.cornerMinEigenVal

%%
% Classify image pixels by thresholding the corner response
mnH = min(Mc_Harris(:));
mxH = max(Mc_Harris(:));
mnST = min(Mc_ShiTomasi(:));
mxST = max(Mc_ShiTomasi(:));

% find locatiosn where response is above threshold
mask_Harris = Mc_Harris > (mnH + (mxH - mnH)*qualityLevel/100);
mask_ShiTomasi = Mc_ShiTomasi > (mnST + (mxST - mnST)*qualityLevel/100);

%%
% Corresponding corner locations
sz = size(Mc_Harris);
[X,Y] = meshgrid(1:sz(2), 1:sz(1));
pts_Harris = [X(mask_Harris) Y(mask_Harris)];
pts_ShiTomasi = [X(mask_ShiTomasi) Y(mask_ShiTomasi)];

%%
% Draw circles around corners and show results
figure(1)
out = cv.circle(src, pts_Harris, opts{:});
subplot(121), imshow(out), title('My Harris')
out = cv.circle(src, pts_ShiTomasi, opts{:});
subplot(122), imshow(out), title('My Shi-Tomasi')

%%
% Show corner response maps
figure(2)
subplot(121), imshow(Mc_Harris, []), title('Harris response')
line(pts_Harris(:,1), pts_Harris(:,2), params{:})
subplot(122), imshow(Mc_ShiTomasi, []), title('Shi-Tomasi response')
line(pts_ShiTomasi(:,1), pts_ShiTomasi(:,2), params{:})

%% cv.goodFeaturesToTrack
% Compare against builtin function,
% note that "quality level" is interpreterd a bit differently,
% plus the implementation does additional processing (non-max suppression)
ptsH = cv.goodFeaturesToTrack(gray, 'UseHarrisDetector',true, 'K',k, ...
    'QualityLevel',qualityLevel/100, 'BlockSize',blockSz);
ptsST = cv.goodFeaturesToTrack(gray, 'UseHarrisDetector',false, ...
    'QualityLevel',qualityLevel/100, 'BlockSize',blockSz);
ptsH = cat(1, ptsH{:});
ptsST = cat(1, ptsST{:});

%%
% Draw corners
figure(3)
out = cv.circle(src, ptsH, opts{:});
subplot(121), imshow(out), title('Harris corner detector')
out = cv.circle(src, ptsST, opts{:});
subplot(122), imshow(out), title('Shi-Tomasi corner detector')


%% cv.cornerHarris
% Compare against builtin function
Mc = cv.cornerHarris(gray, 'K',k, 'BlockSize',blockSz, 'KSize',apertureSz);
err = norm(abs(Mc_Harris - Mc))

%%
% Another example of thresholding response map to find corners
mask = cv.dilate(Mc) > 0.01*max(Mc(:));
out = src(:,:,1);
out(mask) = 255;
out = cat(3, out, src(:,:,2:3));
figure(4), imshow(out), title('Harris corners')

##### SOURCE END #####
--></body>
</html>