<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>Histogram-based face tracker with CAMShift</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="camshift_track_demo.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">Histogram-based face tracker with CAMShift</h1>
         <!--introduction-->
         <p>In this demo, we implement a simple face tracker applied on an input video.</p>
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://docs.opencv.org/3.2.0/db/df8/tutorial_py_meanshift.html">https://docs.opencv.org/3.2.0/db/df8/tutorial_py_meanshift.html</a></li>
               <li><a href="https://www.mathworks.com/help/vision/examples/face-detection-and-tracking-using-camshift.html">https://www.mathworks.com/help/vision/examples/face-detection-and-tracking-using-camshift.html</a></li>
            </ul>
         </div>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Video</a></li>
               <li><a href="#4">Options</a></li>
               <li><a href="#6">Detect a face to track</a></li>
               <li><a href="#7">Facial feature to track (hue color)</a></li>
               <li><a href="#8">Track the face</a></li>
            </ul>
         </div>
         <h2 id="2">Video</h2>
         <p>Create the video file reader</p><pre class="codeinput"><span class="keyword">if</span> true
    v = which(<span class="string">'vipcolorsegmentation.avi'</span>);
    s = 3;                    <span class="comment">% scale since frames are a bit too small</span>
    win = [40 45 25 25] * s;  <span class="comment">% hardcoded object location</span>
<span class="keyword">else</span>
    v = which(<span class="string">'visionface.avi'</span>);
    s = 1;
    win = [275 125 75 100];
<span class="keyword">end</span>
<span class="keyword">if</span> isempty(v)
    <span class="keyword">if</span> true
        filtspec = strjoin(strcat(<span class="string">'*.'</span>, {<span class="string">'avi'</span>,<span class="string">'mpg'</span>,<span class="string">'mpeg'</span>,<span class="string">'mp4'</span>,<span class="string">'wmv'</span>}), <span class="string">';'</span>);
        [fn,fp] = uigetfile(filtspec, <span class="string">'Select a video file'</span>);
        <span class="keyword">if</span> fp==0, error(<span class="string">'No file selected'</span>); <span class="keyword">end</span>
        v = fullfile(fp,fn);
    <span class="keyword">else</span>
        v = 0;
    <span class="keyword">end</span>
    s = 1;
    win = [];
<span class="keyword">end</span>
vid = cv.VideoCapture(v);
assert(vid.isOpened(), <span class="string">'Could not initialize capturing'</span>);</pre><p>Read the first video frame which contains the object to track</p><pre class="codeinput">img = vid.read();
assert(~isempty(img), <span class="string">'Failed to read frame'</span>);
<span class="keyword">if</span> s ~= 1, img = cv.resize(img, s, s); <span class="keyword">end</span>
sz = size(img);</pre><h2 id="4">Options</h2><pre class="codeinput"><span class="comment">% visualization options</span>
use_hg = false;
vis_prob = false;
str = {<span class="string">'meanshift'</span>, <span class="string">'camshift'</span>, <span class="string">'camshift rotated'</span>};
clr = 255 * eye(3);

<span class="comment">% mean shift termination criteria</span>
crit = struct(<span class="string">'type'</span>,<span class="string">'Count+EPS'</span>, <span class="string">'maxCount'</span>,10, <span class="string">'epsilon'</span>,1.0);</pre><p>Prepare plot</p><pre class="codeinput">hImg = imshow(img);
title(<span class="string">'Histogram-based Tracker (MeanShift &amp; CamShift)'</span>)
<span class="keyword">if</span> use_hg
    hRectMS = rectangle(<span class="string">'Position'</span>,win, <span class="string">'EdgeColor'</span>,<span class="string">'r'</span>);
    hRectCS = rectangle(<span class="string">'Position'</span>,win, <span class="string">'EdgeColor'</span>,<span class="string">'g'</span>);
    hLineCS = line(NaN, NaN, <span class="string">'Color'</span>,<span class="string">'b'</span>);
<span class="keyword">end</span></pre><img src="camshift_track_demo_01.png"><h2 id="6">Detect a face to track</h2>
         <p>Define the object region. This initial window is typically found using some sort of object detection. Optionally, you can
            select the object region using your mouse with IMRECT. The object must occupy the majority of the region.
         </p><pre class="codeinput"><span class="keyword">if</span> isempty(win)
    <span class="keyword">if</span> false
        <span class="comment">% automatically detect biggest face in image</span>
        xmlfile = fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'haarcascade_frontalface_alt2.xml'</span>);
        obj = cv.CascadeClassifier(xmlfile);
        faces = obj.detect(cv.equalizeHist(cv.cvtColor(img, <span class="string">'RGB2GRAY'</span>)));
        clear <span class="string">obj</span>
        <span class="keyword">if</span> ~isempty(faces)
            <span class="comment">%TODO: we can further improve this by detecting nose within face,</span>
            <span class="comment">% as it provides more accurate measure of skin tone with less</span>
            <span class="comment">% background pixels</span>
            [~,idx] = max(cellfun(@(f) cv.Rect.area(f), faces));
            win = faces{idx};
        <span class="keyword">end</span>
    <span class="keyword">elseif</span> ~mexopencv.isOctave() &amp;&amp; mexopencv.require(<span class="string">'images'</span>)
        <span class="comment">% interactively select region with mouse</span>
        hRect = imrect(gca);
        setColor(hRect, clr(1,:)/255);
        win = wait(hRect);
        mask = uint8(createMask(hRect, hImg) * 255);
        delete(hRect);
        win(1:2) = win(1:2) - 1;
    <span class="keyword">else</span>
        <span class="comment">% fallback to using an input dialog to prompt for region</span>
        win = inputdlg(strcat(<span class="string">'win.'</span>,{<span class="string">'x'</span>,<span class="string">'y'</span>,<span class="string">'w'</span>,<span class="string">'h'</span>}), <span class="string">'Window'</span>, 1);
        win = str2double(win);
    <span class="keyword">end</span>
<span class="keyword">end</span>
assert(~isempty(win) &amp;&amp; cv.Rect.area(win) &gt; 0, <span class="string">'invalid object region'</span>);
win = cv.Rect.intersect(win, [0 0 sz(2) sz(1)]);
winMS = win;
winCS = win;

<span class="comment">% set up ROI mask marking the object to track</span>
<span class="keyword">if</span> true
    mask = zeros(sz(1:2), <span class="string">'uint8'</span>);
    mask = cv.rectangle(mask, win, <span class="string">'Color'</span>,255, <span class="string">'Thickness'</span>,<span class="string">'Filled'</span>);
<span class="keyword">elseif</span> true
    w = win + [1 1 0 0];
    mask = false(sz(1:2));
    mask(w(2):w(2)+w(4), w(1):w(1)+w(3)) = true;
<span class="keyword">end</span></pre><h2 id="7">Facial feature to track (hue color)</h2>
         <p>Set the object, based on the hue channel of the first video frame. (Convert to HSV color space and calculate the hue histogram
            of object)
         </p><pre class="codeinput">imgHSV = cv.cvtColor(img, <span class="string">'RGB2HSV'</span>);
<span class="keyword">if</span> true
    H = cv.calcHist(imgHSV(:,:,1), 0:180, <span class="string">'Mask'</span>,mask);
<span class="keyword">else</span>
    hue = imgHSV(:,:,1);
    H = histc(imgHSV(mask), 0:179);
<span class="keyword">end</span></pre><h2 id="8">Track the face</h2>
         <p>Track and display the object in each video frame. The while loop reads each image frame, converts the image to HSV color space,
            then tracks the object in the hue channel where it is distinct from the background. Finally, the example draws a box around
            the object and displays the results.
         </p><pre class="codeinput"><span class="keyword">while</span> ishghandle(hImg)
    <span class="comment">% next video frame</span>
    img = vid.read();
    <span class="keyword">if</span> isempty(img), <span class="keyword">break</span>; <span class="keyword">end</span>
    <span class="keyword">if</span> s ~= 1, img = cv.resize(img, s, s); <span class="keyword">end</span>

    <span class="comment">% probability according to histogram empirical model</span>
    imgHSV = cv.cvtColor(img, <span class="string">'RGB2HSV'</span>);
    <span class="keyword">if</span> true
        D = cv.calcBackProject(imgHSV(:,:,1), H, 0:180);
    <span class="keyword">else</span>
        [~,idx] = histc(imgHSV(:,:,1), 0:179);
        D = H(idx);
    <span class="keyword">end</span>

    <span class="comment">% normalize the probability</span>
    <span class="keyword">if</span> true
        D = cv.normalize(D, <span class="string">'NormType'</span>,<span class="string">'MinMax'</span>, <span class="keyword">...</span>
            <span class="string">'Alpha'</span>,0, <span class="string">'Beta'</span>,1, <span class="string">'DType'</span>,<span class="string">'double'</span>);
    <span class="keyword">else</span>
        D = double(D);
        D = (D - min(D(:))) ./ (max(D(:)) - min(D(:)));
    <span class="keyword">end</span>

    <span class="comment">% find new window</span>
    <span class="keyword">if</span> true
        <span class="comment">%TODO: camshift tends to give larger windows??</span>
        <span class="comment">% so we use the meanshift window</span>
        winCS = winMS;
    <span class="keyword">end</span>
    winMS = cv.meanShift(D, winMS, <span class="string">'Criteria'</span>,crit);
    [boxCS,winCS] = cv.CamShift(D, winCS, <span class="string">'Criteria'</span>,crit);
    <span class="comment">%winCS = cv.RotatedRect.boundingRect(boxCS);</span>

    <span class="comment">% visualize backprojection instead of raw frame</span>
    <span class="keyword">if</span> vis_prob
        img = cv.cvtColor(uint8(D * 255), <span class="string">'GRAY2RGB'</span>);
    <span class="keyword">end</span>

    <span class="comment">% draw meanshift and camshift tracking windows</span>
    boxPts = cv.RotatedRect.points(boxCS);
    <span class="keyword">if</span> use_hg
        set(hRectMS, <span class="string">'Position'</span>,winMS);
        set(hRectCS, <span class="string">'Position'</span>,winCS);
        set(hLineCS, <span class="string">'XData'</span>,boxPts([1:4 1],1), <span class="string">'YData'</span>,boxPts([1:4 1],2));
    <span class="keyword">else</span>
        img = cv.rectangle(img, winMS, <span class="string">'Color'</span>,clr(1,:));
        img = cv.rectangle(img, winCS, <span class="string">'Color'</span>,clr(2,:));
        img = cv.polylines(img, {boxPts}, <span class="string">'Color'</span>,clr(3,:), <span class="string">'Closed'</span>,true, <span class="keyword">...</span>
            <span class="string">'LineType'</span>,<span class="string">'AA'</span>);
        <span class="keyword">for</span> i=1:3
            <span class="comment">% draw legend</span>
            img = cv.putText(img, [<span class="string">'- '</span> str{i}], [10 i*10], <span class="keyword">...</span>
                <span class="string">'Color'</span>,clr(i,:), <span class="string">'FontScale'</span>,0.4, <span class="string">'LineType'</span>,<span class="string">'AA'</span>);
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="comment">% show result</span>
    set(hImg, <span class="string">'CData'</span>,img);
    pause(0.05);
<span class="keyword">end</span></pre><img src="camshift_track_demo_02.png"><p>Release the video reader</p><pre class="codeinput">vid.release();</pre><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Histogram-based face tracker with CAMShift
%
% In this demo, we implement a simple face tracker applied on an input video.
%
% Sources:
%
% * <https://docs.opencv.org/3.2.0/db/df8/tutorial_py_meanshift.html>
% * <https://www.mathworks.com/help/vision/examples/face-detection-and-tracking-using-camshift.html>
%

%% Video
% Create the video file reader
if true
    v = which('vipcolorsegmentation.avi');
    s = 3;                    % scale since frames are a bit too small
    win = [40 45 25 25] * s;  % hardcoded object location
else
    v = which('visionface.avi');
    s = 1;
    win = [275 125 75 100];
end
if isempty(v)
    if true
        filtspec = strjoin(strcat('*.', {'avi','mpg','mpeg','mp4','wmv'}), ';');
        [fn,fp] = uigetfile(filtspec, 'Select a video file');
        if fp==0, error('No file selected'); end
        v = fullfile(fp,fn);
    else
        v = 0;
    end
    s = 1;
    win = [];
end
vid = cv.VideoCapture(v);
assert(vid.isOpened(), 'Could not initialize capturing');

%%
% Read the first video frame which contains the object to track
img = vid.read();
assert(~isempty(img), 'Failed to read frame');
if s ~= 1, img = cv.resize(img, s, s); end
sz = size(img);

%% Options

% visualization options
use_hg = false;
vis_prob = false;
str = {'meanshift', 'camshift', 'camshift rotated'};
clr = 255 * eye(3);

% mean shift termination criteria
crit = struct('type','Count+EPS', 'maxCount',10, 'epsilon',1.0);

%%
% Prepare plot
hImg = imshow(img);
title('Histogram-based Tracker (MeanShift & CamShift)')
if use_hg
    hRectMS = rectangle('Position',win, 'EdgeColor','r');
    hRectCS = rectangle('Position',win, 'EdgeColor','g');
    hLineCS = line(NaN, NaN, 'Color','b');
end

%% Detect a face to track
% Define the object region. This initial window is typically found using some
% sort of object detection. Optionally, you can select the object region using
% your mouse with IMRECT. The object must occupy the majority of the region.
if isempty(win)
    if false
        % automatically detect biggest face in image
        xmlfile = fullfile(mexopencv.root(),'test','haarcascade_frontalface_alt2.xml');
        obj = cv.CascadeClassifier(xmlfile);
        faces = obj.detect(cv.equalizeHist(cv.cvtColor(img, 'RGB2GRAY')));
        clear obj
        if ~isempty(faces)
            %TODO: we can further improve this by detecting nose within face,
            % as it provides more accurate measure of skin tone with less
            % background pixels
            [~,idx] = max(cellfun(@(f) cv.Rect.area(f), faces));
            win = faces{idx};
        end
    elseif ~mexopencv.isOctave() && mexopencv.require('images')
        % interactively select region with mouse
        hRect = imrect(gca);
        setColor(hRect, clr(1,:)/255);
        win = wait(hRect);
        mask = uint8(createMask(hRect, hImg) * 255);
        delete(hRect);
        win(1:2) = win(1:2) - 1;
    else
        % fallback to using an input dialog to prompt for region
        win = inputdlg(strcat('win.',{'x','y','w','h'}), 'Window', 1);
        win = str2double(win);
    end
end
assert(~isempty(win) && cv.Rect.area(win) > 0, 'invalid object region');
win = cv.Rect.intersect(win, [0 0 sz(2) sz(1)]);
winMS = win;
winCS = win;

% set up ROI mask marking the object to track
if true
    mask = zeros(sz(1:2), 'uint8');
    mask = cv.rectangle(mask, win, 'Color',255, 'Thickness','Filled');
elseif true
    w = win + [1 1 0 0];
    mask = false(sz(1:2));
    mask(w(2):w(2)+w(4), w(1):w(1)+w(3)) = true;
end

%% Facial feature to track (hue color)
% Set the object, based on the hue channel of the first video frame.
% (Convert to HSV color space and calculate the hue histogram of object)
imgHSV = cv.cvtColor(img, 'RGB2HSV');
if true
    H = cv.calcHist(imgHSV(:,:,1), 0:180, 'Mask',mask);
else
    hue = imgHSV(:,:,1);
    H = histc(imgHSV(mask), 0:179);
end

%% Track the face
% Track and display the object in each video frame. The while loop reads each
% image frame, converts the image to HSV color space, then tracks the object
% in the hue channel where it is distinct from the background. Finally, the
% example draws a box around the object and displays the results.
while ishghandle(hImg)
    % next video frame
    img = vid.read();
    if isempty(img), break; end
    if s ~= 1, img = cv.resize(img, s, s); end

    % probability according to histogram empirical model
    imgHSV = cv.cvtColor(img, 'RGB2HSV');
    if true
        D = cv.calcBackProject(imgHSV(:,:,1), H, 0:180);
    else
        [~,idx] = histc(imgHSV(:,:,1), 0:179);
        D = H(idx);
    end

    % normalize the probability
    if true
        D = cv.normalize(D, 'NormType','MinMax', ...
            'Alpha',0, 'Beta',1, 'DType','double');
    else
        D = double(D);
        D = (D - min(D(:))) ./ (max(D(:)) - min(D(:)));
    end

    % find new window
    if true
        %TODO: camshift tends to give larger windows??
        % so we use the meanshift window
        winCS = winMS;
    end
    winMS = cv.meanShift(D, winMS, 'Criteria',crit);
    [boxCS,winCS] = cv.CamShift(D, winCS, 'Criteria',crit);
    %winCS = cv.RotatedRect.boundingRect(boxCS);

    % visualize backprojection instead of raw frame
    if vis_prob
        img = cv.cvtColor(uint8(D * 255), 'GRAY2RGB');
    end

    % draw meanshift and camshift tracking windows
    boxPts = cv.RotatedRect.points(boxCS);
    if use_hg
        set(hRectMS, 'Position',winMS);
        set(hRectCS, 'Position',winCS);
        set(hLineCS, 'XData',boxPts([1:4 1],1), 'YData',boxPts([1:4 1],2));
    else
        img = cv.rectangle(img, winMS, 'Color',clr(1,:));
        img = cv.rectangle(img, winCS, 'Color',clr(2,:));
        img = cv.polylines(img, {boxPts}, 'Color',clr(3,:), 'Closed',true, ...
            'LineType','AA');
        for i=1:3
            % draw legend
            img = cv.putText(img, ['- ' str{i}], [10 i*10], ...
                'Color',clr(i,:), 'FontScale',0.4, 'LineType','AA');
        end
    end

    % show result
    set(hImg, 'CData',img);
    pause(0.05);
end

%%
% Release the video reader
vid.release();

##### SOURCE END #####
-->
   </body>
</html>