<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>High Dynamic Range Imaging</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="hdr_imaging_demo.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">High Dynamic Range Imaging</h1>
         <!--introduction-->
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://docs.opencv.org/3.2.0/d3/db7/tutorial_hdr_imaging.html">https://docs.opencv.org/3.2.0/d3/db7/tutorial_hdr_imaging.html</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/d2/df0/tutorial_py_hdr.html">https://docs.opencv.org/3.2.0/d2/df0/tutorial_py_hdr.html</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/photo/hdr_imaging/hdr_imaging.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/photo/hdr_imaging/hdr_imaging.cpp</a></li>
            </ul>
         </div>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Introduction</a></li>
               <li><a href="#3">Load images and exposure times</a></li>
               <li><a href="#6">Estimate camera response</a></li>
               <li><a href="#8">Make HDR image</a></li>
               <li><a href="#9">Tonemap HDR image</a></li>
               <li><a href="#10">Perform exposure fusion</a></li>
               <li><a href="#11">Write results</a></li>
               <li><a href="#12">Compare against MATLAB's implementation</a></li>
            </ul>
         </div>
         <h2 id="2">Introduction</h2>
         <p>Today most digital images and imaging devices use 8 bits per channel thus limiting the dynamic range of the device to two
            orders of magnitude (actually 256 levels), while human eye can adapt to lighting conditions varying by ten orders of magnitude.
            When we take photographs of a real world scene bright regions may be overexposed, while the dark ones may be underexposed,
            so we can't capture all details using a single exposure. HDR imaging works with images that use more that 8 bits per channel
            (usually 32-bit float values), allowing much wider dynamic range.
         </p>
         <p>There are different ways to obtain HDR images, but the most common one is to use photographs of the scene taken with different
            exposure values. To combine this exposures it is useful to know your camera's response function and there are algorithms to
            estimate it. After the HDR image has been blended it has to be converted back to 8-bit to view it on usual displays. This
            process is called tonemapping. Additional complexities arise when objects of the scene or camera move between shots, since
            images with different exposures should be registered and aligned.
         </p>
         <p>In this tutorial we show how to generate and display HDR image from an exposure sequence. In our case images are already aligned
            and there are no moving objects. We also demonstrate an alternative approach called exposure fusion that produces low dynamic
            range image. Each step of HDR pipeline can be implemented using different algorithms so take a look at the reference manual
            to see them all.
         </p>
         <h2 id="3">Load images and exposure times</h2>
         <p>Choose which images to load: memorial, office, or user-defined</p><pre class="codeinput">use_memorial = true;
use_office = false;
<span class="keyword">if</span> use_memorial
    <span class="comment">% samples from OpenCV</span>
    fpath = fullfile(mexopencv.root(),<span class="string">'test'</span>);
    files = dir(fullfile(fpath,<span class="string">'memorial*.png'</span>));
    files = sort({files.name});
<span class="keyword">elseif</span> use_office
    <span class="comment">% samples from Image Processing Toolbox</span>
    fpath = fileparts(which(<span class="string">'office_1.jpg'</span>));
    files = dir(fullfile(fpath,<span class="string">'office_*.jpg'</span>));
    files = sort({files.name});
<span class="keyword">else</span>
    <span class="comment">% custom images</span>
    fmts = imformats();
    filtspec = strjoin(strcat(<span class="string">'*.'</span>, [fmts.ext]), <span class="string">';'</span>);
    [files,fpath] = uigetfile(filtspec, <span class="string">'Select images'</span>, <span class="string">'MultiSelect'</span>,<span class="string">'on'</span>);
    <span class="keyword">if</span> fpath==0, error(<span class="string">'No file selected'</span>); <span class="keyword">end</span>
<span class="keyword">end</span>
files = cellfun(@(f) fullfile(fpath,f), files(:), <span class="string">'UniformOutput'</span>,false);
assert(numel(files) &gt;= 2, <span class="string">'Not enough images'</span>);</pre><p>First we read exposure times</p><pre class="codeinput"><span class="keyword">if</span> use_memorial
    <span class="comment">% the folder should contain images and memorial.txt,</span>
    <span class="comment">% a text file that contains file names and inverse exposure times.</span>
    <span class="keyword">if</span> exist(fullfile(fpath,<span class="string">'memorial.txt'</span>), <span class="string">'file'</span>) == 2
        fid = fopen(fullfile(fpath,<span class="string">'memorial.txt'</span>), <span class="string">'rt'</span>);
        C = textscan(fid, <span class="string">'%s %f'</span>);
        fclose(fid);
        [~,ord] = sort(C{1});
        etimes = 1 ./ C{2}(ord);
    <span class="keyword">else</span>
        etimes = 2.^(5:-1:-10);
    <span class="keyword">end</span>
<span class="keyword">else</span>
    <span class="comment">% read exposure times from EXIF tags</span>
    etimes = zeros(size(files));
    <span class="keyword">for</span> i=1:numel(files)
        meta = imfinfo(files{i});
        assert(isfield(meta, <span class="string">'DigitalCamera'</span>), <span class="string">'Missing EXIF'</span>);
        etimes(i) = meta.DigitalCamera.ExposureTime;
        <span class="comment">%fstop = meta.DigitalCamera.FNumber;  % expect the same f-stop number</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="comment">% sort by exposure times</span>
[etimes,ord] = sort(etimes, <span class="string">'descend'</span>);
files = files(ord);</pre><p>Next we load input images</p><pre class="codeinput">images = cellfun(@(f) imread(f), files, <span class="string">'UniformOutput'</span>,false);

<span class="keyword">if</span> mexopencv.require(<span class="string">'images'</span>)
    montage(cat(4,images{:}), <span class="string">'Size'</span>,[2 NaN])
<span class="keyword">end</span>

<span class="keyword">if</span> ~mexopencv.isOctave()
    t = table(files, strtrim(cellstr(rats(etimes))), <span class="keyword">...</span>
        <span class="string">'VariableNames'</span>,{<span class="string">'File'</span>,<span class="string">'ExposureTime'</span>});
    disp(t)
<span class="keyword">end</span></pre><pre class="codeoutput">Warning: Image is too big to fit on screen; displaying at 33% 
                            File                             ExposureTime
    _____________________________________________________    ____________
    'C:\Users\Amro\Desktop\mexopencv\test\memorial00.png'    '32'        
    'C:\Users\Amro\Desktop\mexopencv\test\memorial01.png'    '16'        
    'C:\Users\Amro\Desktop\mexopencv\test\memorial02.png'    '8'         
    'C:\Users\Amro\Desktop\mexopencv\test\memorial03.png'    '4'         
    'C:\Users\Amro\Desktop\mexopencv\test\memorial04.png'    '2'         
    'C:\Users\Amro\Desktop\mexopencv\test\memorial05.png'    '1'         
    'C:\Users\Amro\Desktop\mexopencv\test\memorial06.png'    '1/2'       
    'C:\Users\Amro\Desktop\mexopencv\test\memorial07.png'    '1/4'       
    'C:\Users\Amro\Desktop\mexopencv\test\memorial08.png'    '1/8'       
    'C:\Users\Amro\Desktop\mexopencv\test\memorial09.png'    '1/16'      
    'C:\Users\Amro\Desktop\mexopencv\test\memorial10.png'    '1/32'      
    'C:\Users\Amro\Desktop\mexopencv\test\memorial11.png'    '1/64'      
    'C:\Users\Amro\Desktop\mexopencv\test\memorial12.png'    '1/128'     
    'C:\Users\Amro\Desktop\mexopencv\test\memorial13.png'    '1/256'     
    'C:\Users\Amro\Desktop\mexopencv\test\memorial14.png'    '1/512'     
    'C:\Users\Amro\Desktop\mexopencv\test\memorial15.png'    '1/1024'    
</pre><img src="hdr_imaging_demo_01.png"><h2 id="6">Estimate camera response</h2>
         <p>It is necessary to know camera response function (CRF) for a lot of HDR construction algorithms. We use one of the calibration
            algorithms to estimate inverse CRF for all 256 pixel values.
         </p><pre class="codeinput"><span class="keyword">if</span> true
    calibrate = cv.CalibrateDebevec();
    <span class="comment">%calibrate.Samples = 100;</span>
    <span class="comment">%calibrate.Lambda = 20;</span>
<span class="keyword">else</span>
    calibrate = cv.CalibrateRobertson();
<span class="keyword">end</span>
tic
response = calibrate.process(images, etimes);
toc</pre><pre class="codeoutput">Elapsed time is 5.308985 seconds.
</pre><p>plot CRF</p><pre class="codeinput">figure(2)
h = semilogy(0:255, reshape(response, 256, []));
set(h, {<span class="string">'Color'</span>},{<span class="string">'r'</span>;<span class="string">'g'</span>;<span class="string">'b'</span>})
legend(h, {<span class="string">'R'</span>, <span class="string">'G'</span>, <span class="string">'B'</span>}, <span class="string">'Location'</span>,<span class="string">'southeast'</span>)
xlabel(<span class="string">'pixel value z'</span>)
ylabel(<span class="string">'log exposure g(z)'</span>)
title(<span class="string">'camera response function'</span>)
xlim([0 255]), grid <span class="string">on</span></pre><img src="hdr_imaging_demo_02.png"><h2 id="8">Make HDR image</h2>
         <p>We use Debevec's weighting scheme to construct HDR image using response calculated in the previous item.</p><pre class="codeinput"><span class="keyword">if</span> true
    merge = cv.MergeDebevec();
<span class="keyword">else</span>
    merge = cv.MergeRobertson();
<span class="keyword">end</span>
tic
hdr = merge.process(images, etimes, response);
toc
fprintf(<span class="string">'HDR: min=%f, max=%f\n'</span>, min(hdr(:)), max(hdr(:)))</pre><pre class="codeoutput">Elapsed time is 0.174492 seconds.
HDR: min=0.001132, max=835.111511
</pre><h2 id="9">Tonemap HDR image</h2>
         <p>Since we want to see our results on common LDR display, we have to map our HDR image to 8-bit range preserving most details.
            It is the main goal of tonemapping methods. We use tonemapper with bilateral filtering and set 2.2 as the value for gamma
            correction.
         </p><pre class="codeinput"><span class="keyword">if</span> false
    tone = cv.TonemapDurand(<span class="string">'Gamma'</span>,2.2);
<span class="keyword">else</span>
    tone = cv.TonemapReinhard(<span class="string">'Gamma'</span>,2.2, <span class="keyword">...</span>
        <span class="string">'Intensity'</span>,-8, <span class="string">'LightAdaptation'</span>,0.6, <span class="string">'ColorAdaptation'</span>,0.5);
<span class="keyword">end</span>
tic
ldr = tone.process(hdr);
toc
fprintf(<span class="string">'LDR: min=%f, max=%f\n'</span>, min(ldr(:)), max(ldr(:)))
figure(3), imshow(ldr, []), title(<span class="string">'TonemapReinhard'</span>)</pre><pre class="codeoutput">Elapsed time is 0.049119 seconds.
LDR: min=0.000000, max=1.000000
Warning: Image is too big to fit on screen; displaying at 67% 
</pre><img src="hdr_imaging_demo_03.png"><h2 id="10">Perform exposure fusion</h2>
         <p>There is an alternative way to merge our exposures in case when we don't need HDR image. This process is called exposure fusion
            and produces LDR image that doesn't require gamma correction. It also doesn't use exposure values of the photographs.
         </p><pre class="codeinput">fuse = cv.MergeMertens();
tic
fusion = fuse.process(images);
toc
fprintf(<span class="string">'LDR: min=%f, max=%f\n'</span>, min(fusion(:)), max(fusion(:)))
figure(4), imshow(fusion, []), title(<span class="string">'MergeMertens'</span>)</pre><pre class="codeoutput">Elapsed time is 0.470477 seconds.
LDR: min=-0.005889, max=1.771424
Warning: Image is too big to fit on screen; displaying at 67% 
</pre><img src="hdr_imaging_demo_04.png"><h2 id="11">Write results</h2>
         <p>Now it's time to look at the results. Note that HDR image can't be stored in one of common image formats, so we save it to
            Radiance image (.hdr). Also all HDR imaging functions return results in [0,1] range so we should multiply result by 255.
         </p><pre class="codeinput"><span class="keyword">if</span> true
    to8bit = @(im) uint8(im * 255);
<span class="keyword">else</span>
    to8bit = @(im) cv.convertTo(im, <span class="string">'RType'</span>,<span class="string">'uint8'</span>, <span class="string">'Alpha'</span>,255);
<span class="keyword">end</span>
cv.imwrite(fullfile(tempdir(), <span class="string">'hdr.hdr'</span>), hdr);
cv.imwrite(fullfile(tempdir(), <span class="string">'ldr.png'</span>), to8bit(ldr));
cv.imwrite(fullfile(tempdir(), <span class="string">'fusion.png'</span>), to8bit(fusion));</pre><h2 id="12">Compare against MATLAB's implementation</h2><pre class="codeinput"><span class="comment">%HACK: HDRREAD/MAKEHDR/TONEMAP not implemented in Octave</span>
<span class="keyword">if</span> ~mexopencv.isOctave() &amp;&amp; mexopencv.require(<span class="string">'images'</span>)
    <span class="comment">% HDR image</span>
    <span class="keyword">if</span> true &amp;&amp; ~use_memorial
        <span class="comment">% create HDR image from LDR images using MAKEHDR</span>
        <span class="keyword">if</span> use_memorial
            <span class="keyword">if</span> true
                opts = {<span class="string">'RelativeExposure'</span>,etimes./etimes(1)};
            <span class="keyword">else</span>
                ev = log2(etimes ./ (log2(max(etimes) / min(etimes)) * min(etimes)));
                opts = {<span class="string">'ExposureValues'</span>,ev};
            <span class="keyword">end</span>
        <span class="keyword">else</span>
            opts = {};  <span class="comment">% exposure times stored in EXIF</span>
        <span class="keyword">end</span>
        hdr2 = makehdr(files, opts{:});
    <span class="keyword">elseif</span> true
        <span class="comment">% read premade HDR image</span>
        <span class="keyword">if</span> use_memorial
            fname = fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'memorial.hdr'</span>);
            <span class="keyword">if</span> exist(fname, <span class="string">'file'</span>) ~= 2
                url = <span class="string">'http://www.pauldebevec.com/Research/HDR/memorial.hdr'</span>;
                urlwrite(url, fname);
            <span class="keyword">end</span>
        <span class="keyword">elseif</span> use_office
            fname = which(<span class="string">'office.hdr'</span>);
        <span class="keyword">else</span>
            fname = fullfile(tempdir(), <span class="string">'hdr.hdr'</span>);
        <span class="keyword">end</span>
        <span class="keyword">if</span> true
            hdr2 = hdrread(fname);
        <span class="keyword">else</span>
            hdr2 = cv.imread(fname, <span class="string">'Unchanged'</span>,true);
        <span class="keyword">end</span>
    <span class="keyword">else</span>
        <span class="comment">% use previous HDR result</span>
        hdr2 = hdr;
    <span class="keyword">end</span>

    <span class="comment">% tonemapping: HDR -&gt; LDR</span>
    tic
    ldr2 = tonemap(hdr2);
    toc
    figure(5), imshow(ldr2), title(<span class="string">'tonemap'</span>)
    imwrite(ldr2, fullfile(tempdir(), <span class="string">'ldr2.png'</span>));
<span class="keyword">end</span></pre><pre class="codeoutput">Elapsed time is 2.497523 seconds.
Warning: Image is too big to fit on screen; displaying at 67% 
</pre><img src="hdr_imaging_demo_05.png"><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div>
      <!--
##### SOURCE BEGIN #####
%% High Dynamic Range Imaging
%
% Sources:
%
% * <https://docs.opencv.org/3.2.0/d3/db7/tutorial_hdr_imaging.html>
% * <https://docs.opencv.org/3.2.0/d2/df0/tutorial_py_hdr.html>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/photo/hdr_imaging/hdr_imaging.cpp>
%

%% Introduction
% Today most digital images and imaging devices use 8 bits per channel thus
% limiting the dynamic range of the device to two orders of magnitude
% (actually 256 levels), while human eye can adapt to lighting conditions
% varying by ten orders of magnitude. When we take photographs of a real world
% scene bright regions may be overexposed, while the dark ones may be
% underexposed, so we can't capture all details using a single exposure. HDR
% imaging works with images that use more that 8 bits per channel (usually
% 32-bit float values), allowing much wider dynamic range.
%
% There are different ways to obtain HDR images, but the most common one is to
% use photographs of the scene taken with different exposure values. To
% combine this exposures it is useful to know your camera's response function
% and there are algorithms to estimate it. After the HDR image has been
% blended it has to be converted back to 8-bit to view it on usual displays.
% This process is called tonemapping. Additional complexities arise when
% objects of the scene or camera move between shots, since images with
% different exposures should be registered and aligned.
%
% In this tutorial we show how to generate and display HDR image from an
% exposure sequence. In our case images are already aligned and there are no
% moving objects. We also demonstrate an alternative approach called exposure
% fusion that produces low dynamic range image. Each step of HDR pipeline can
% be implemented using different algorithms so take a look at the reference
% manual to see them all.
%

%% Load images and exposure times
% Choose which images to load: memorial, office, or user-defined
use_memorial = true;
use_office = false;
if use_memorial
    % samples from OpenCV
    fpath = fullfile(mexopencv.root(),'test');
    files = dir(fullfile(fpath,'memorial*.png'));
    files = sort({files.name});
elseif use_office
    % samples from Image Processing Toolbox
    fpath = fileparts(which('office_1.jpg'));
    files = dir(fullfile(fpath,'office_*.jpg'));
    files = sort({files.name});
else
    % custom images
    fmts = imformats();
    filtspec = strjoin(strcat('*.', [fmts.ext]), ';');
    [files,fpath] = uigetfile(filtspec, 'Select images', 'MultiSelect','on');
    if fpath==0, error('No file selected'); end
end
files = cellfun(@(f) fullfile(fpath,f), files(:), 'UniformOutput',false);
assert(numel(files) >= 2, 'Not enough images');

%%
% First we read exposure times
if use_memorial
    % the folder should contain images and memorial.txt,
    % a text file that contains file names and inverse exposure times.
    if exist(fullfile(fpath,'memorial.txt'), 'file') == 2
        fid = fopen(fullfile(fpath,'memorial.txt'), 'rt');
        C = textscan(fid, '%s %f');
        fclose(fid);
        [~,ord] = sort(C{1});
        etimes = 1 ./ C{2}(ord);
    else
        etimes = 2.^(5:-1:-10);
    end
else
    % read exposure times from EXIF tags
    etimes = zeros(size(files));
    for i=1:numel(files)
        meta = imfinfo(files{i});
        assert(isfield(meta, 'DigitalCamera'), 'Missing EXIF');
        etimes(i) = meta.DigitalCamera.ExposureTime;
        %fstop = meta.DigitalCamera.FNumber;  % expect the same f-stop number
    end
end

% sort by exposure times
[etimes,ord] = sort(etimes, 'descend');
files = files(ord);

%%
% Next we load input images
images = cellfun(@(f) imread(f), files, 'UniformOutput',false);

if mexopencv.require('images')
    montage(cat(4,images{:}), 'Size',[2 NaN])
end

if ~mexopencv.isOctave()
    t = table(files, strtrim(cellstr(rats(etimes))), ...
        'VariableNames',{'File','ExposureTime'});
    disp(t)
end

%% Estimate camera response
% It is necessary to know camera response function (CRF) for a lot of HDR
% construction algorithms. We use one of the calibration algorithms to
% estimate inverse CRF for all 256 pixel values.
if true
    calibrate = cv.CalibrateDebevec();
    %calibrate.Samples = 100;
    %calibrate.Lambda = 20;
else
    calibrate = cv.CalibrateRobertson();
end
tic
response = calibrate.process(images, etimes);
toc

%%
% plot CRF
figure(2)
h = semilogy(0:255, reshape(response, 256, []));
set(h, {'Color'},{'r';'g';'b'})
legend(h, {'R', 'G', 'B'}, 'Location','southeast')
xlabel('pixel value z')
ylabel('log exposure g(z)')
title('camera response function')
xlim([0 255]), grid on

%% Make HDR image
% We use Debevec's weighting scheme to construct HDR image using response
% calculated in the previous item.
if true
    merge = cv.MergeDebevec();
else
    merge = cv.MergeRobertson();
end
tic
hdr = merge.process(images, etimes, response);
toc
fprintf('HDR: min=%f, max=%f\n', min(hdr(:)), max(hdr(:)))

%% Tonemap HDR image
% Since we want to see our results on common LDR display, we have to map our
% HDR image to 8-bit range preserving most details. It is the main goal of
% tonemapping methods. We use tonemapper with bilateral filtering and set
% 2.2 as the value for gamma correction.
if false
    tone = cv.TonemapDurand('Gamma',2.2);
else
    tone = cv.TonemapReinhard('Gamma',2.2, ...
        'Intensity',-8, 'LightAdaptation',0.6, 'ColorAdaptation',0.5);
end
tic
ldr = tone.process(hdr);
toc
fprintf('LDR: min=%f, max=%f\n', min(ldr(:)), max(ldr(:)))
figure(3), imshow(ldr, []), title('TonemapReinhard')

%% Perform exposure fusion
% There is an alternative way to merge our exposures in case when we don't
% need HDR image. This process is called exposure fusion and produces LDR
% image that doesn't require gamma correction. It also doesn't use exposure
% values of the photographs.
fuse = cv.MergeMertens();
tic
fusion = fuse.process(images);
toc
fprintf('LDR: min=%f, max=%f\n', min(fusion(:)), max(fusion(:)))
figure(4), imshow(fusion, []), title('MergeMertens')

%% Write results
% Now it's time to look at the results. Note that HDR image can't be stored
% in one of common image formats, so we save it to Radiance image (.hdr).
% Also all HDR imaging functions return results in [0,1] range so we should
% multiply result by 255.
if true
    to8bit = @(im) uint8(im * 255);
else
    to8bit = @(im) cv.convertTo(im, 'RType','uint8', 'Alpha',255);
end
cv.imwrite(fullfile(tempdir(), 'hdr.hdr'), hdr);
cv.imwrite(fullfile(tempdir(), 'ldr.png'), to8bit(ldr));
cv.imwrite(fullfile(tempdir(), 'fusion.png'), to8bit(fusion));

%% Compare against MATLAB's implementation
%HACK: HDRREAD/MAKEHDR/TONEMAP not implemented in Octave
if ~mexopencv.isOctave() && mexopencv.require('images')
    % HDR image
    if true && ~use_memorial
        % create HDR image from LDR images using MAKEHDR
        if use_memorial
            if true
                opts = {'RelativeExposure',etimes./etimes(1)};
            else
                ev = log2(etimes ./ (log2(max(etimes) / min(etimes)) * min(etimes)));
                opts = {'ExposureValues',ev};
            end
        else
            opts = {};  % exposure times stored in EXIF
        end
        hdr2 = makehdr(files, opts{:});
    elseif true
        % read premade HDR image
        if use_memorial
            fname = fullfile(mexopencv.root(),'test','memorial.hdr');
            if exist(fname, 'file') ~= 2
                url = 'http://www.pauldebevec.com/Research/HDR/memorial.hdr';
                urlwrite(url, fname);
            end
        elseif use_office
            fname = which('office.hdr');
        else
            fname = fullfile(tempdir(), 'hdr.hdr');
        end
        if true
            hdr2 = hdrread(fname);
        else
            hdr2 = cv.imread(fname, 'Unchanged',true);
        end
    else
        % use previous HDR result
        hdr2 = hdr;
    end

    % tonemapping: HDR -> LDR
    tic
    ldr2 = tonemap(hdr2);
    toc
    figure(5), imshow(ldr2), title('tonemap')
    imwrite(ldr2, fullfile(tempdir(), 'ldr2.png'));
end

##### SOURCE END #####
-->
   </body>
</html>