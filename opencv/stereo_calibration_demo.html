<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>Stereo Calibration</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="stereo_calibration_demo.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">Stereo Calibration</h1>
         <!--introduction-->
         <p>Demonstration of stereo calibration, rectification, and correspondence.</p>
         <p>You will learn how to use the following OpenCV functions and classes:</p>
         <div>
            <ul>
               <li><tt>cv.findChessboardCorners</tt>, <tt>cv.drawChessboardCorners</tt></li>
               <li><tt>cv.cornerSubPix</tt></li>
               <li><tt>cv.initCameraMatrix2D</tt></li>
               <li><tt>cv.stereoCalibrate</tt></li>
               <li><tt>cv.undistortPoints</tt></li>
               <li><tt>cv.computeCorrespondEpilines</tt></li>
               <li><tt>cv.stereoRectify</tt>, <tt>cv.stereoRectifyUncalibrated</tt></li>
               <li><tt>cv.findFundamentalMat</tt></li>
               <li><tt>cv.getDefaultNewCameraMatrix</tt></li>
               <li><tt>cv.initUndistortRectifyMap</tt>, <tt>cv.remap</tt></li>
               <li><tt>cv.StereoBM</tt>, <tt>cv.StereoSGBM</tt></li>
               <li><tt>cv.reprojectImageTo3D</tt></li>
            </ul>
         </div>
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/stereo_calib.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/stereo_calib.cpp</a></li>
               <li><a href="https://github.com/oreillymedia/Learning-OpenCV-3_examples/blob/master/example_19-03.cpp">https://github.com/oreillymedia/Learning-OpenCV-3_examples/blob/master/example_19-03.cpp</a></li>
            </ul>
         </div>
         <p>See also: stereoCameraCalibrator</p>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Options</a></li>
               <li><a href="#3">Stereo Images</a></li>
               <li><a href="#5">Object Points</a></li>
               <li><a href="#6">Image Points</a></li>
               <li><a href="#8">Calibration</a></li>
               <li><a href="#12">Rectification</a></li>
               <li><a href="#15">Plot: apply and show rectified images</a></li>
               <li><a href="#19">Corrrespondence: Disparity Map</a></li>
               <li><a href="#25">3D Reconstruction</a></li>
            </ul>
         </div>
         <h2 id="2">Options</h2><pre class="codeinput">squareSize = 30.0;         <span class="comment">% square size in world units (mm)</span>
isVerticalStereo = false;  <span class="comment">% left-right or up-down stereo camera arrangement</span>
useCalibrated = true;      <span class="comment">% calibrated or uncalibrated stereo rectification</span>
doCheck = true;            <span class="comment">% calibration check</span></pre><h2 id="3">Stereo Images</h2>
         <p>list of chessboard images and the number of chessboard corners</p><pre class="codeinput"><span class="keyword">if</span> true
    files1 = cv.glob(fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'left*.jpg'</span>));
    files2 = cv.glob(fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'right*.jpg'</span>));
    patternSize = [9,6];
<span class="keyword">elseif</span> ~mexopencv.isOctave() &amp;&amp; mexopencv.require(<span class="string">'vision'</span>)
    fpath = fullfile(toolboxdir(<span class="string">'vision'</span>),<span class="string">'visiondata'</span>,<span class="string">'calibration'</span>,<span class="string">'stereo'</span>);
    files1 = cv.glob(fullfile(fpath, <span class="string">'left'</span>, <span class="string">'left*.png'</span>));
    files2 = cv.glob(fullfile(fpath, <span class="string">'right'</span>, <span class="string">'right*.png'</span>));
    patternSize = [7,6];
<span class="keyword">end</span>
assert(~isempty(files1) &amp;&amp; numel(files1) == numel(files2));
N = numel(files1);</pre><p>images info (assumed all images are of same size)</p><pre class="codeinput">finfo = imfinfo(files1{1});
imgSiz = [finfo.Width, finfo.Height];
fprintf(<span class="string">'%d pairs of stereo images\n'</span>, N);
fprintf(<span class="string">'Image size = %dx%d\n'</span>, imgSiz);
fprintf(<span class="string">'Pattern size (nx,ny) = %dx%d\n'</span>, patternSize);</pre><pre class="codeoutput">13 pairs of stereo images
Image size = 640x480
Pattern size (nx,ny) = 9x6
</pre><h2 id="5">Object Points</h2>
         <p>Prepare calibration patterns (points traversed row-wise, same order as findChessboardCorners)</p><pre class="codeinput">[X,Y] = ndgrid(1:patternSize(1), 1:patternSize(2));
pts_o = ([X(:) Y(:)] - 1) * squareSize;
pts_o(:,3) = 0;                 <span class="comment">% Z=0</span>
pts_o = repmat({pts_o}, 1, N);  <span class="comment">% same calibration coords used in all views</span></pre><h2 id="6">Image Points</h2>
         <p>Find coordinates of chessboard corners in left/right images</p><pre class="codeinput"><span class="comment">%TODO: reject image pairs where detection fails (any of left or right)</span>
<span class="comment">%TODO: we could also detect corners on multiple scales in case detection fails</span>
pts1 = cell(1,N);
pts2 = cell(1,N);
opts = {<span class="string">'WinSize'</span>,[11 11], <span class="keyword">...</span>
    <span class="string">'Criteria'</span>,struct(<span class="string">'type'</span>,<span class="string">'Count+EPS'</span>, <span class="string">'maxCount'</span>,30, <span class="string">'epsilon'</span>,0.01)};
tic
<span class="keyword">for</span> i=1:N
    im = cv.imread(files1{i}, <span class="string">'Grayscale'</span>,true);
    pts = cv.findChessboardCorners(im, patternSize);
    pts = cat(1, pts{:});
    pts1{i} = cv.cornerSubPix(im, pts, opts{:});

    im = cv.imread(files2{i}, <span class="string">'Grayscale'</span>,true);
    pts = cv.findChessboardCorners(im, patternSize);
    pts = cat(1, pts{:});
    pts2{i} = cv.cornerSubPix(im, pts, opts{:});
<span class="keyword">end</span>
toc</pre><pre class="codeoutput">Elapsed time is 0.776578 seconds.
</pre><p>Show detected checkerboards in first pair of images</p><pre class="codeinput">i = 1;
im1 = cv.imread(files1{i}, <span class="string">'Color'</span>,true);
im2 = cv.imread(files2{i}, <span class="string">'Color'</span>,true);
im1 = cv.drawChessboardCorners(im1, patternSize, pts1{i});
im2 = cv.drawChessboardCorners(im2, patternSize, pts2{i});
<span class="keyword">if</span> ~isVerticalStereo
    im = cat(2, im1, im2);
<span class="keyword">else</span>
    im = cat(1, im1, im2);
<span class="keyword">end</span>
imshow(im), title(sprintf(<span class="string">'Chessboard Corners, %02d / %02d'</span>, i, N))</pre><img src="stereo_calibration_demo_01.png"><h2 id="8">Calibration</h2>
         <p>calibrate the stereo camera, specifying the distortion model in the options. (we could have also calibrated each camera independently
            first)
         </p><pre class="codeinput"><span class="keyword">if</span> false
    M1 = cv.initCameraMatrix2D(pts_o, pts1, imgSiz);  <span class="comment">% 'AspectRatio',0</span>
    M2 = cv.initCameraMatrix2D(pts_o, pts2, imgSiz);  <span class="comment">% 'AspectRatio',0</span>
    guess = {<span class="string">'UseIntrinsicGuess'</span>,true, <span class="keyword">...</span>
        <span class="string">'CameraMatrix1'</span>,M1, <span class="string">'CameraMatrix2'</span>,M2};
<span class="keyword">else</span>
    guess = {};
<span class="keyword">end</span>
tic
S = cv.stereoCalibrate(pts_o, pts1, pts2, imgSiz, <span class="keyword">...</span>
    <span class="string">'FixIntrinsic'</span>,false, guess{:}, <span class="keyword">...</span>
    <span class="string">'SameFocalLength'</span>,true, <span class="string">'FixAspectRatio'</span>,true, <span class="keyword">...</span>
    <span class="string">'ZeroTangentDist'</span>,true, <span class="string">'FixK3'</span>,true, <span class="keyword">...</span>
    <span class="string">'RationalModel'</span>,true, <span class="string">'FixK4'</span>,true, <span class="string">'FixK5'</span>,true, <span class="keyword">...</span>
    <span class="string">'ThinPrismModel'</span>,false, <span class="string">'TiltedModel'</span>,false, <span class="keyword">...</span>
    <span class="string">'Criteria'</span>,struct(<span class="string">'type'</span>,<span class="string">'Count+EPS'</span>, <span class="string">'maxCount'</span>,100, <span class="string">'epsilon'</span>,1e-5));
    <span class="comment">%'FixAspectRatio',false, 'ZeroTangentDist',false, 'RationalModel',false</span>
toc
<span class="keyword">if</span> ~mexopencv.isOctave(), display(S); <span class="keyword">end</span></pre><pre class="codeoutput">Elapsed time is 2.790928 seconds.
S = 
  struct with fields:

    cameraMatrix1: [3&times;3 double]
      distCoeffs1: [-0.2745 -0.0184 0 0 0 0 0 -0.2443 0 0 0 0 0 0]
    cameraMatrix2: [3&times;3 double]
      distCoeffs2: [-0.2808 0.0932 0 0 0 0 0 0.0167 0 0 0 0 0 0]
                R: [3&times;3 double]
                T: [3&times;1 double]
                E: [3&times;3 double]
                F: [3&times;3 double]
        reprojErr: 0.4828
</pre><p>calibration accuracy</p><pre class="codeinput">assert(all(isfinite([S.cameraMatrix1(:); S.cameraMatrix2(:)])));
assert(all(isfinite([S.distCoeffs1(:); S.distCoeffs2(:)])));
fprintf(<span class="string">'Total RMS reprojection error: %f\n'</span>, S.reprojErr);</pre><pre class="codeoutput">Total RMS reprojection error: 0.482773
</pre><p>calibration quality check: (check how nearly the points in image1 lie on the epipolar lines of image2)</p><pre class="codeinput"><span class="keyword">if</span> doCheck
    <span class="comment">% because the output fundamental matrix implicitly includes all the output</span>
    <span class="comment">% information, we can check the quality of calibration using the epipolar</span>
    <span class="comment">% geometry constraint |m2'*F*m1=0| (for the undistorted points)</span>
    points1 = cat(1, pts1{:});
    points2 = cat(1, pts2{:});
    points1 = cv.undistortPoints(points1, S.cameraMatrix1, S.distCoeffs1, <span class="keyword">...</span>
        <span class="string">'P'</span>,S.cameraMatrix1);
    points2 = cv.undistortPoints(points2, S.cameraMatrix2, S.distCoeffs2, <span class="keyword">...</span>
        <span class="string">'P'</span>,S.cameraMatrix2);
    lines1 = cv.computeCorrespondEpilines(points1, S.F, <span class="string">'WhichImage'</span>,1);
    lines2 = cv.computeCorrespondEpilines(points2, S.F, <span class="string">'WhichImage'</span>,2);

    <span class="comment">% dot product of points with epilines (ideal is zero) and accumulate error</span>
    err1 = abs(sum([points1 ones(size(points1,1),1)] .* lines2, 2));
    err2 = abs(sum([points2 ones(size(points2,1),1)] .* lines1, 2));
    err = err1 + err2;

    <span class="comment">% mean error per stereo image pair</span>
    G = repmat(1:N, prod(patternSize), 1);
    G = G(:);
    e1 = accumarray(G, err1, [N 1], @mean);
    e2 = accumarray(G, err2, [N 1], @mean);
    avgErr = mean(err)/2;  <span class="comment">% (mean(e1) + mean(e2))/2</span>

    <span class="comment">% plot</span>
    figure, bar(1:N, [e1 e2])
    line(xlim(), [1 1]*avgErr, <span class="string">'LineStyle'</span>,<span class="string">'--'</span>, <span class="string">'Color'</span>,<span class="string">'r'</span>)
    legend({<span class="string">'Camera 1'</span>, <span class="string">'Camera 2'</span>, <span class="string">'Overall Epipolar Error'</span>})
    xlabel(<span class="string">'Image Pairs'</span>), ylabel(<span class="string">'Mean Epipolar Error (in pixel)'</span>)
    title(sprintf(<span class="string">'average epipolar error = %f'</span>, avgErr))
<span class="keyword">end</span></pre><img src="stereo_calibration_demo_02.png"><p>save intrinsic parameters</p><pre class="codeinput">fs = struct(<span class="string">'M1'</span>,S.cameraMatrix1, <span class="string">'D1'</span>,S.distCoeffs1, <span class="keyword">...</span>
    <span class="string">'M2'</span>,S.cameraMatrix2, <span class="string">'D2'</span>,S.distCoeffs2, <span class="keyword">...</span>
    <span class="string">'width'</span>,int32(imgSiz(1)), <span class="string">'height'</span>,int32(imgSiz(2)));
cv.FileStorage(fullfile(tempdir(), <span class="string">'stereo_intrinsic.yml'</span>), fs);</pre><h2 id="12">Rectification</h2>
         <p>Bouguet's algorithm or Hartley's algorithm</p><pre class="codeinput"><span class="keyword">if</span> useCalibrated
    <span class="comment">% calibrated stereo rectification:</span>
    <span class="comment">% compute rectification transforms for the two camera heads</span>
    <span class="comment">% (undistort + rectify)</span>
    tic
    RCT = cv.stereoRectify(S.cameraMatrix1, S.distCoeffs1,<span class="keyword">...</span>
        S.cameraMatrix2, S.distCoeffs2, imgSiz, S.R, S.T, <span class="keyword">...</span>
        <span class="string">'ZeroDisparity'</span>,true, <span class="string">'Alpha'</span>,-1); <span class="comment">%  'Alpha',1</span>
    toc

    <span class="comment">% OpenCV can handle left-right or up-down camera arrangements</span>
    isVerticalStereo = abs(RCT.P2(2,4)) &gt; abs(RCT.P2(1,4));
<span class="keyword">else</span>
    <span class="comment">% uncalibrated stereo rectification:</span>
    <span class="comment">% we use intrinsic parameters of each camera, but we compute the</span>
    <span class="comment">% rectification transformation directly from the fundamental matrix</span>
    <span class="comment">% (this method works best for images that have been undistorted previously</span>
    <span class="comment">% by independent single-camera calibrations, which we did while doing</span>
    <span class="comment">% the calibration quality check, see above)</span>
    S.F = cv.findFundamentalMat(points1, points2, <span class="string">'Method'</span>,<span class="string">'8Point'</span>);
    [H1, H2] = cv.stereoRectifyUncalibrated(points1, points2, S.F, imgSiz, <span class="keyword">...</span>
        <span class="string">'Threshold'</span>,3);

    RCT = struct();
    RCT.R1 = (S.cameraMatrix1 \ H1) * S.cameraMatrix1;
    RCT.R2 = (S.cameraMatrix2 \ H2) * S.cameraMatrix2;
    <span class="keyword">if</span> true
        RCT.P1 = cv.getDefaultNewCameraMatrix(S.cameraMatrix1, <span class="keyword">...</span>
            <span class="string">'ImgSize'</span>,imgSiz, <span class="string">'CenterPrincipalPoint'</span>,true);
        RCT.P2 = cv.getDefaultNewCameraMatrix(S.cameraMatrix2, <span class="keyword">...</span>
            <span class="string">'ImgSize'</span>,imgSiz, <span class="string">'CenterPrincipalPoint'</span>,true);
    <span class="keyword">else</span>
        RCT.P1 = [];
        RCT.P2 = [];
    <span class="keyword">end</span>
    RCT.Q = eye(4);           <span class="comment">% TODO: ?</span>
    RCT.roi1 = [0 0 imgSiz];  <span class="comment">% TODO: ?</span>
    RCT.roi2 = [0 0 imgSiz];  <span class="comment">% TODO: ?</span>
<span class="keyword">end</span>
<span class="keyword">if</span> ~mexopencv.isOctave(), display(RCT); <span class="keyword">end</span></pre><pre class="codeoutput">Elapsed time is 0.019961 seconds.
RCT = 
  struct with fields:

      R1: [3&times;3 double]
      R2: [3&times;3 double]
      P1: [3&times;4 double]
      P2: [3&times;4 double]
       Q: [4&times;4 double]
    roi1: [10 31 603 430]
    roi2: [24 20 605 430]
</pre><p>save extrinsic parameters</p><pre class="codeinput">fs = struct(<span class="string">'R'</span>,S.R, <span class="string">'T'</span>,S.T, <span class="keyword">...</span>
    <span class="string">'R1'</span>,RCT.R1, <span class="string">'R2'</span>,RCT.R2, <span class="string">'P1'</span>,RCT.P1, <span class="string">'P2'</span>,RCT.P2, <span class="string">'Q'</span>,RCT.Q);
cv.FileStorage(fullfile(tempdir(), <span class="string">'stereo_extrinsic.yml'</span>), fs);</pre><p>combined transformations to correct distortions and rectify images (precomputed maps, in fixed-point representation, for <tt>cv.remap</tt>)
         </p><pre class="codeinput">RM = struct(<span class="string">'map1'</span>,cell(1,2), <span class="string">'map2'</span>,cell(1,2));
tic
[RM(1).map1, RM(1).map2] = cv.initUndistortRectifyMap(<span class="keyword">...</span>
    S.cameraMatrix1, S.distCoeffs1, imgSiz, <span class="keyword">...</span>
    <span class="string">'P'</span>,RCT.P1, <span class="string">'R'</span>,RCT.R1, <span class="string">'M1Type'</span>,<span class="string">'int16'</span>);
[RM(2).map1, RM(2).map2] = cv.initUndistortRectifyMap(<span class="keyword">...</span>
    S.cameraMatrix2, S.distCoeffs2, imgSiz, <span class="keyword">...</span>
    <span class="string">'P'</span>,RCT.P2, <span class="string">'R'</span>,RCT.R2, <span class="string">'M1Type'</span>,<span class="string">'int16'</span>);
toc</pre><pre class="codeoutput">Elapsed time is 0.068360 seconds.
</pre><h2 id="15">Plot: apply and show rectified images</h2>
         <p>prepare image montage</p><pre class="codeinput">sf = 1;  <span class="comment">% scale factor, to avoid displaying images that are too big</span>
<span class="keyword">if</span> ~isVerticalStereo
    sf = min(sf, 600/max(imgSiz));
    w = round(imgSiz(1) * sf);
    h = round(imgSiz(2) * sf);
    im = zeros([h,w*2,3], <span class="string">'uint8'</span>);
<span class="keyword">else</span>
    sf = min(sf, 300/max(imgSiz));
    w = round(imgSiz(1) * sf);
    h = round(imgSiz(2) * sf);
    im = zeros([h*2,w,3], <span class="string">'uint8'</span>);
<span class="keyword">end</span></pre><p>prepare to draw epilines, shows how well rectified images are aligned. (epipolar lines are parallel scanlines in rectified
            image planes, passing through corresponding image regions)
         </p><pre class="codeinput">k = 30;
<span class="keyword">if</span> ~isVerticalStereo
    <span class="comment">% horizontal lines</span>
    Y = repmat(1:round(h/k):h, 2, 1);
    X = repmat([1; w*2], 1, size(Y,2));
<span class="keyword">else</span>
    <span class="comment">% vertical lines</span>
    X = repmat(1:round(w/k):w, 2, 1);
    Y = repmat([1; h*2], 1, size(X,2));
<span class="keyword">end</span>
X(3,:) = NaN;
Y(3,:) = NaN;</pre><p>prepare to draw valid ROIs (bounding boxes for valid pixels)</p><pre class="codeinput">roi1 = round(RCT.roi1 * sf);
roi2 = round(RCT.roi2 * sf);
<span class="keyword">if</span> ~isVerticalStereo
    roi2 = roi2 + [w 0 0 0];  <span class="comment">% shifted to right</span>
<span class="keyword">else</span>
    roi2 = roi2 + [0 h 0 0];  <span class="comment">% shifted to bottom</span>
<span class="keyword">end</span></pre><p>loop over image pairs, apply rectification, and show results</p><pre class="codeinput">figure
hImg = imshow(im);
rectangle(<span class="string">'Position'</span>,roi1, <span class="string">'EdgeColor'</span>,<span class="string">'g'</span>, <span class="string">'LineWidth'</span>,2)
rectangle(<span class="string">'Position'</span>,roi2, <span class="string">'EdgeColor'</span>,<span class="string">'g'</span>, <span class="string">'LineWidth'</span>,2)
line(X(:), Y(:), <span class="string">'Color'</span>,<span class="string">'r'</span>, <span class="string">'LineWidth'</span>,0.5)  <span class="comment">% 'AlignVertexCenters','on'</span>
<span class="keyword">for</span> i=1:N
    <span class="comment">% undistort+rectify image pair</span>
    im1 = cv.imread(files1{i}, <span class="string">'Color'</span>,true);
    im2 = cv.imread(files2{i}, <span class="string">'Color'</span>,true);
    <span class="keyword">if</span> false
        im1 = cv.drawChessboardCorners(im1, patternSize, pts1{i});
        im2 = cv.drawChessboardCorners(im2, patternSize, pts2{i});
    <span class="keyword">end</span>
    im1 = cv.remap(im1, RM(1).map1, RM(1).map2, <span class="string">'Interpolation'</span>,<span class="string">'Linear'</span>);
    im2 = cv.remap(im2, RM(2).map1, RM(2).map2, <span class="string">'Interpolation'</span>,<span class="string">'Linear'</span>);

    <span class="comment">% combine images side-by-side</span>
    im1 = cv.resize(im1, [w,h], <span class="string">'Interpolation'</span>,<span class="string">'Area'</span>);
    im2 = cv.resize(im2, [w,h], <span class="string">'Interpolation'</span>,<span class="string">'Area'</span>);
    <span class="keyword">if</span> ~isVerticalStereo
        im = cat(2, im1, im2);
    <span class="keyword">else</span>
        im = cat(1, im1, im2);
    <span class="keyword">end</span>

    <span class="comment">% show final image</span>
    set(hImg, <span class="string">'CData'</span>,im);
    title(sprintf(<span class="string">'Rectified: %02d / %02d'</span>, i, N));
    pause(1);
<span class="keyword">end</span></pre><img src="stereo_calibration_demo_03.png"><h2 id="19">Corrrespondence: Disparity Map</h2>
         <p>When the stereo camera is oriented vertically, Hartley method does not transpose the image, so the epipolar lines in the rectified
            images are vertical. Stereo correspondence function does not support such a case.
         </p><pre class="codeinput"><span class="keyword">if</span> isVerticalStereo &amp;&amp; ~useCalibrated
    <span class="keyword">return</span>;
<span class="keyword">end</span></pre><p>pick a pair of rectified images</p><pre class="codeinput">i = 6;
im1 = cv.imread(files1{i}, <span class="string">'Color'</span>,true);
im2 = cv.imread(files2{i}, <span class="string">'Color'</span>,true);
im1 = cv.remap(im1, RM(1).map1, RM(1).map2);
im2 = cv.remap(im2, RM(2).map1, RM(2).map2);
<span class="keyword">if</span> false
    <span class="comment">% crop (see also Alpha option of stereoRectify)</span>
    roi12 = cv.Rect.union(RCT.roi1, RCT.roi2);
    im1 = cv.Rect.crop(im1, roi12);
    im2 = cv.Rect.crop(im2, roi12);
<span class="keyword">end</span>
<span class="comment">%figure, imshow(cat(3, rgb2gray(im1), rgb2gray(im2), rgb2gray(im2))) % stereoAnaglyph</span></pre><p>compute disparity on the undistorted and rectified stereo image pair</p><pre class="codeinput"><span class="keyword">if</span> true
    bm = cv.StereoSGBM();
    bm.NumDisparities = 128;
    bm.BlockSize = 25;
    bm.SpeckleRange = 4;
    bm.SpeckleWindowSize = 200;
<span class="keyword">elseif</span> true
    bm = cv.StereoBM();
    bm.NumDisparities = 192;
    bm.BlockSize = 21;
<span class="keyword">else</span>
    bm = cv.StereoSGBM(<span class="string">'MinDisparity'</span>,-64, <span class="string">'NumDisparities'</span>,192, <span class="keyword">...</span>
        <span class="string">'BlockSize'</span>,11, <span class="string">'P1'</span>,100, <span class="string">'P2'</span>,1000, <span class="string">'Disp12MaxDiff'</span>,32, <span class="keyword">...</span>
        <span class="string">'PreFilterCap'</span>,0, <span class="string">'UniquenessRatio'</span>,15, <span class="keyword">...</span>
        <span class="string">'SpeckleWindowSize'</span>,1000, <span class="string">'SpeckleRange'</span>,16, <span class="string">'Mode'</span>,<span class="string">'HH'</span>);
<span class="keyword">end</span>
tic
D = bm.compute(rgb2gray(im1), rgb2gray(im2));
toc</pre><pre class="codeoutput">Elapsed time is 0.147792 seconds.
</pre><p>disparity map is stored in 16-bit fixed-point representation, with values scaled by 16. To get real disparity values, we divide
            by 16.
         </p><pre class="codeinput">DD = single(D) / 16;</pre><p>the minimal value in D correspond to the invalid disparity value, i.e: <tt>invalid_disp_scaled = (bm.MinDisparity - 1) * bitshift(1,4)</tt>, or in DD: <tt>invalid_disp = (bm.MinDisparity - 1)</tt> (these are outliers/missing-values where the disparity was not computed)
         </p><pre class="codeinput">DD(D == min(D(:))) = NaN;
fprintf(<span class="string">'min=%d, max=%d\n'</span>, min(DD(:)), max(DD(:)));</pre><pre class="codeoutput">min=0, max=127
</pre><p>show disparity map</p><pre class="codeinput">figure, imshow(DD, []) <span class="comment">% [bm.MinDisparity, bm.MinDisparity + bm.NumDisparities]</span>
colormap(<span class="string">'gray'</span>), colorbar
title(sprintf(<span class="string">'Disparity Map, %02d / %02d'</span>, i, N))</pre><img src="stereo_calibration_demo_04.png"><h2 id="25">3D Reconstruction</h2>
         <p>point cloud (XYZ-coords and corresponding colors)</p><pre class="codeinput"><span class="keyword">if</span> true
    <span class="comment">%TODO: something is wrong with the Q matrix, result seems always bad!</span>
    <span class="keyword">if</span> true
        Q = RCT.Q;
        Q(4,4) = 1/Q(4,3);  <span class="comment">% TODO: ??</span>
    <span class="keyword">else</span>
        Q = eye(4);
    <span class="keyword">end</span>
    XYZ = cv.reprojectImageTo3D(D, Q);  <span class="comment">% 'HandleMissingValues',true</span>
    XYZ = reshape(XYZ, [], 3);
<span class="keyword">else</span>
    [X,Y] = meshgrid(1:size(DD,1), 1:size(DD,2));
    XYZ = [X(:) Y(:) DD(:)];
<span class="keyword">end</span>
C = reshape(single(im1)/255, [], 3);</pre><p>remove invalid points (filter invalid disparities) which are set to infinite distances bigZ=10000 by reprojectImageTo3D when
            HandleMissingValues=true)
         </p><pre class="codeinput">mask = (D(:) == min(D(:)));
XYZ(mask,:) = [];
C(mask,:) = [];
whos <span class="string">XYZ</span> <span class="string">C</span></pre><pre class="codeoutput">  Name           Size              Bytes  Class     Attributes

  C         166233x3             1994796  single              
  XYZ       166233x3             1994796  single              

</pre><p>visualize point cloud</p><pre class="codeinput">figure, scatter3(XYZ(:,1), XYZ(:,2), XYZ(:,3), 6, C, <span class="string">'.'</span>)
title(<span class="string">'Point Cloud'</span>); xlabel(<span class="string">'X'</span>); ylabel(<span class="string">'Y'</span>); zlabel(<span class="string">'Z'</span>);
axis <span class="string">tight</span>
<span class="keyword">if</span> ~mexopencv.isOctave()
    axis <span class="string">vis3d</span>
<span class="keyword">else</span>
    <span class="comment">%HACK: vis3d mode not recognized in Octave</span>
    set(gca, <span class="string">'CameraViewAngle'</span>,   get(gca, <span class="string">'CameraViewAngle'</span>));
    set(gca, <span class="string">'PlotBoxAspectRatio'</span>,get(gca, <span class="string">'PlotBoxAspectRatio'</span>));
    set(gca, <span class="string">'DataAspectRatio'</span>,   get(gca, <span class="string">'DataAspectRatio'</span>));
<span class="keyword">end</span>
<span class="keyword">if</span> ~mexopencv.isOctave()
    <span class="comment">%HACK: CAM* functions not implemented in Octave</span>
    cameratoolbar
    cameratoolbar(<span class="string">'SetCoordSys'</span>,<span class="string">'y'</span>)
    <span class="comment">%cameramenu</span>
<span class="keyword">else</span>
    view(-37.5,-60)
    rotate3d <span class="string">on</span>
<span class="keyword">end</span></pre><img src="stereo_calibration_demo_05.png"><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div>
      <!--
##### SOURCE BEGIN #####
%% Stereo Calibration
% Demonstration of stereo calibration, rectification, and correspondence.
%
% You will learn how to use the following OpenCV functions and classes:
%
% * |cv.findChessboardCorners|, |cv.drawChessboardCorners|
% * |cv.cornerSubPix|
% * |cv.initCameraMatrix2D|
% * |cv.stereoCalibrate|
% * |cv.undistortPoints|
% * |cv.computeCorrespondEpilines|
% * |cv.stereoRectify|, |cv.stereoRectifyUncalibrated|
% * |cv.findFundamentalMat|
% * |cv.getDefaultNewCameraMatrix|
% * |cv.initUndistortRectifyMap|, |cv.remap|
% * |cv.StereoBM|, |cv.StereoSGBM|
% * |cv.reprojectImageTo3D|
%
% Sources:
%
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/stereo_calib.cpp>
% * <https://github.com/oreillymedia/Learning-OpenCV-3_examples/blob/master/example_19-03.cpp>
%
% See also: stereoCameraCalibrator
%

%% Options
squareSize = 30.0;         % square size in world units (mm)
isVerticalStereo = false;  % left-right or up-down stereo camera arrangement
useCalibrated = true;      % calibrated or uncalibrated stereo rectification
doCheck = true;            % calibration check

%% Stereo Images
% list of chessboard images and the number of chessboard corners
if true
    files1 = cv.glob(fullfile(mexopencv.root(),'test','left*.jpg'));
    files2 = cv.glob(fullfile(mexopencv.root(),'test','right*.jpg'));
    patternSize = [9,6];
elseif ~mexopencv.isOctave() && mexopencv.require('vision')
    fpath = fullfile(toolboxdir('vision'),'visiondata','calibration','stereo');
    files1 = cv.glob(fullfile(fpath, 'left', 'left*.png'));
    files2 = cv.glob(fullfile(fpath, 'right', 'right*.png'));
    patternSize = [7,6];
end
assert(~isempty(files1) && numel(files1) == numel(files2));
N = numel(files1);

%%
% images info (assumed all images are of same size)
finfo = imfinfo(files1{1});
imgSiz = [finfo.Width, finfo.Height];
fprintf('%d pairs of stereo images\n', N);
fprintf('Image size = %dx%d\n', imgSiz);
fprintf('Pattern size (nx,ny) = %dx%d\n', patternSize);

%% Object Points
% Prepare calibration patterns
% (points traversed row-wise, same order as findChessboardCorners)
[X,Y] = ndgrid(1:patternSize(1), 1:patternSize(2));
pts_o = ([X(:) Y(:)] - 1) * squareSize;
pts_o(:,3) = 0;                 % Z=0
pts_o = repmat({pts_o}, 1, N);  % same calibration coords used in all views

%% Image Points
% Find coordinates of chessboard corners in left/right images
%TODO: reject image pairs where detection fails (any of left or right)
%TODO: we could also detect corners on multiple scales in case detection fails
pts1 = cell(1,N);
pts2 = cell(1,N);
opts = {'WinSize',[11 11], ...
    'Criteria',struct('type','Count+EPS', 'maxCount',30, 'epsilon',0.01)};
tic
for i=1:N
    im = cv.imread(files1{i}, 'Grayscale',true);
    pts = cv.findChessboardCorners(im, patternSize);
    pts = cat(1, pts{:});
    pts1{i} = cv.cornerSubPix(im, pts, opts{:});

    im = cv.imread(files2{i}, 'Grayscale',true);
    pts = cv.findChessboardCorners(im, patternSize);
    pts = cat(1, pts{:});
    pts2{i} = cv.cornerSubPix(im, pts, opts{:});
end
toc

%%
% Show detected checkerboards in first pair of images
i = 1;
im1 = cv.imread(files1{i}, 'Color',true);
im2 = cv.imread(files2{i}, 'Color',true);
im1 = cv.drawChessboardCorners(im1, patternSize, pts1{i});
im2 = cv.drawChessboardCorners(im2, patternSize, pts2{i});
if ~isVerticalStereo
    im = cat(2, im1, im2);
else
    im = cat(1, im1, im2);
end
imshow(im), title(sprintf('Chessboard Corners, %02d / %02d', i, N))

%% Calibration
% calibrate the stereo camera, specifying the distortion model in the options.
% (we could have also calibrated each camera independently first)
if false
    M1 = cv.initCameraMatrix2D(pts_o, pts1, imgSiz);  % 'AspectRatio',0
    M2 = cv.initCameraMatrix2D(pts_o, pts2, imgSiz);  % 'AspectRatio',0
    guess = {'UseIntrinsicGuess',true, ...
        'CameraMatrix1',M1, 'CameraMatrix2',M2};
else
    guess = {};
end
tic
S = cv.stereoCalibrate(pts_o, pts1, pts2, imgSiz, ...
    'FixIntrinsic',false, guess{:}, ...
    'SameFocalLength',true, 'FixAspectRatio',true, ...
    'ZeroTangentDist',true, 'FixK3',true, ...
    'RationalModel',true, 'FixK4',true, 'FixK5',true, ...
    'ThinPrismModel',false, 'TiltedModel',false, ...
    'Criteria',struct('type','Count+EPS', 'maxCount',100, 'epsilon',1e-5));
    %'FixAspectRatio',false, 'ZeroTangentDist',false, 'RationalModel',false
toc
if ~mexopencv.isOctave(), display(S); end

%%
% calibration accuracy
assert(all(isfinite([S.cameraMatrix1(:); S.cameraMatrix2(:)])));
assert(all(isfinite([S.distCoeffs1(:); S.distCoeffs2(:)])));
fprintf('Total RMS reprojection error: %f\n', S.reprojErr);

%%
% calibration quality check:
% (check how nearly the points in image1 lie on the epipolar lines of image2)
if doCheck
    % because the output fundamental matrix implicitly includes all the output
    % information, we can check the quality of calibration using the epipolar
    % geometry constraint |m2'*F*m1=0| (for the undistorted points)
    points1 = cat(1, pts1{:});
    points2 = cat(1, pts2{:});
    points1 = cv.undistortPoints(points1, S.cameraMatrix1, S.distCoeffs1, ...
        'P',S.cameraMatrix1);
    points2 = cv.undistortPoints(points2, S.cameraMatrix2, S.distCoeffs2, ...
        'P',S.cameraMatrix2);
    lines1 = cv.computeCorrespondEpilines(points1, S.F, 'WhichImage',1);
    lines2 = cv.computeCorrespondEpilines(points2, S.F, 'WhichImage',2);

    % dot product of points with epilines (ideal is zero) and accumulate error
    err1 = abs(sum([points1 ones(size(points1,1),1)] .* lines2, 2));
    err2 = abs(sum([points2 ones(size(points2,1),1)] .* lines1, 2));
    err = err1 + err2;

    % mean error per stereo image pair
    G = repmat(1:N, prod(patternSize), 1);
    G = G(:);
    e1 = accumarray(G, err1, [N 1], @mean);
    e2 = accumarray(G, err2, [N 1], @mean);
    avgErr = mean(err)/2;  % (mean(e1) + mean(e2))/2

    % plot
    figure, bar(1:N, [e1 e2])
    line(xlim(), [1 1]*avgErr, 'LineStyle','REPLACE_WITH_DASH_DASH', 'Color','r')
    legend({'Camera 1', 'Camera 2', 'Overall Epipolar Error'})
    xlabel('Image Pairs'), ylabel('Mean Epipolar Error (in pixel)')
    title(sprintf('average epipolar error = %f', avgErr))
end

%%
% save intrinsic parameters
fs = struct('M1',S.cameraMatrix1, 'D1',S.distCoeffs1, ...
    'M2',S.cameraMatrix2, 'D2',S.distCoeffs2, ...
    'width',int32(imgSiz(1)), 'height',int32(imgSiz(2)));
cv.FileStorage(fullfile(tempdir(), 'stereo_intrinsic.yml'), fs);

%% Rectification
% Bouguet's algorithm or Hartley's algorithm
if useCalibrated
    % calibrated stereo rectification:
    % compute rectification transforms for the two camera heads
    % (undistort + rectify)
    tic
    RCT = cv.stereoRectify(S.cameraMatrix1, S.distCoeffs1,...
        S.cameraMatrix2, S.distCoeffs2, imgSiz, S.R, S.T, ...
        'ZeroDisparity',true, 'Alpha',-1); %  'Alpha',1
    toc

    % OpenCV can handle left-right or up-down camera arrangements
    isVerticalStereo = abs(RCT.P2(2,4)) > abs(RCT.P2(1,4));
else
    % uncalibrated stereo rectification:
    % we use intrinsic parameters of each camera, but we compute the
    % rectification transformation directly from the fundamental matrix
    % (this method works best for images that have been undistorted previously
    % by independent single-camera calibrations, which we did while doing
    % the calibration quality check, see above)
    S.F = cv.findFundamentalMat(points1, points2, 'Method','8Point');
    [H1, H2] = cv.stereoRectifyUncalibrated(points1, points2, S.F, imgSiz, ...
        'Threshold',3);

    RCT = struct();
    RCT.R1 = (S.cameraMatrix1 \ H1) * S.cameraMatrix1;
    RCT.R2 = (S.cameraMatrix2 \ H2) * S.cameraMatrix2;
    if true
        RCT.P1 = cv.getDefaultNewCameraMatrix(S.cameraMatrix1, ...
            'ImgSize',imgSiz, 'CenterPrincipalPoint',true);
        RCT.P2 = cv.getDefaultNewCameraMatrix(S.cameraMatrix2, ...
            'ImgSize',imgSiz, 'CenterPrincipalPoint',true);
    else
        RCT.P1 = [];
        RCT.P2 = [];
    end
    RCT.Q = eye(4);           % TODO: ?
    RCT.roi1 = [0 0 imgSiz];  % TODO: ?
    RCT.roi2 = [0 0 imgSiz];  % TODO: ?
end
if ~mexopencv.isOctave(), display(RCT); end

%%
% save extrinsic parameters
fs = struct('R',S.R, 'T',S.T, ...
    'R1',RCT.R1, 'R2',RCT.R2, 'P1',RCT.P1, 'P2',RCT.P2, 'Q',RCT.Q);
cv.FileStorage(fullfile(tempdir(), 'stereo_extrinsic.yml'), fs);

%%
% combined transformations to correct distortions and rectify images
% (precomputed maps, in fixed-point representation, for |cv.remap|)
RM = struct('map1',cell(1,2), 'map2',cell(1,2));
tic
[RM(1).map1, RM(1).map2] = cv.initUndistortRectifyMap(...
    S.cameraMatrix1, S.distCoeffs1, imgSiz, ...
    'P',RCT.P1, 'R',RCT.R1, 'M1Type','int16');
[RM(2).map1, RM(2).map2] = cv.initUndistortRectifyMap(...
    S.cameraMatrix2, S.distCoeffs2, imgSiz, ...
    'P',RCT.P2, 'R',RCT.R2, 'M1Type','int16');
toc

%% Plot: apply and show rectified images
% prepare image montage
sf = 1;  % scale factor, to avoid displaying images that are too big
if ~isVerticalStereo
    sf = min(sf, 600/max(imgSiz));
    w = round(imgSiz(1) * sf);
    h = round(imgSiz(2) * sf);
    im = zeros([h,w*2,3], 'uint8');
else
    sf = min(sf, 300/max(imgSiz));
    w = round(imgSiz(1) * sf);
    h = round(imgSiz(2) * sf);
    im = zeros([h*2,w,3], 'uint8');
end

%%
% prepare to draw epilines, shows how well rectified images are aligned.
% (epipolar lines are parallel scanlines in rectified image planes, passing
% through corresponding image regions)
k = 30;
if ~isVerticalStereo
    % horizontal lines
    Y = repmat(1:round(h/k):h, 2, 1);
    X = repmat([1; w*2], 1, size(Y,2));
else
    % vertical lines
    X = repmat(1:round(w/k):w, 2, 1);
    Y = repmat([1; h*2], 1, size(X,2));
end
X(3,:) = NaN;
Y(3,:) = NaN;

%%
% prepare to draw valid ROIs (bounding boxes for valid pixels)
roi1 = round(RCT.roi1 * sf);
roi2 = round(RCT.roi2 * sf);
if ~isVerticalStereo
    roi2 = roi2 + [w 0 0 0];  % shifted to right
else
    roi2 = roi2 + [0 h 0 0];  % shifted to bottom
end

%%
% loop over image pairs, apply rectification, and show results
figure
hImg = imshow(im);
rectangle('Position',roi1, 'EdgeColor','g', 'LineWidth',2)
rectangle('Position',roi2, 'EdgeColor','g', 'LineWidth',2)
line(X(:), Y(:), 'Color','r', 'LineWidth',0.5)  % 'AlignVertexCenters','on'
for i=1:N
    % undistort+rectify image pair
    im1 = cv.imread(files1{i}, 'Color',true);
    im2 = cv.imread(files2{i}, 'Color',true);
    if false
        im1 = cv.drawChessboardCorners(im1, patternSize, pts1{i});
        im2 = cv.drawChessboardCorners(im2, patternSize, pts2{i});
    end
    im1 = cv.remap(im1, RM(1).map1, RM(1).map2, 'Interpolation','Linear');
    im2 = cv.remap(im2, RM(2).map1, RM(2).map2, 'Interpolation','Linear');

    % combine images side-by-side
    im1 = cv.resize(im1, [w,h], 'Interpolation','Area');
    im2 = cv.resize(im2, [w,h], 'Interpolation','Area');
    if ~isVerticalStereo
        im = cat(2, im1, im2);
    else
        im = cat(1, im1, im2);
    end

    % show final image
    set(hImg, 'CData',im);
    title(sprintf('Rectified: %02d / %02d', i, N));
    pause(1);
end

%% Corrrespondence: Disparity Map
% When the stereo camera is oriented vertically, Hartley method does not
% transpose the image, so the epipolar lines in the rectified images are
% vertical. Stereo correspondence function does not support such a case.
if isVerticalStereo && ~useCalibrated
    return;
end

%%
% pick a pair of rectified images
i = 6;
im1 = cv.imread(files1{i}, 'Color',true);
im2 = cv.imread(files2{i}, 'Color',true);
im1 = cv.remap(im1, RM(1).map1, RM(1).map2);
im2 = cv.remap(im2, RM(2).map1, RM(2).map2);
if false
    % crop (see also Alpha option of stereoRectify)
    roi12 = cv.Rect.union(RCT.roi1, RCT.roi2);
    im1 = cv.Rect.crop(im1, roi12);
    im2 = cv.Rect.crop(im2, roi12);
end
%figure, imshow(cat(3, rgb2gray(im1), rgb2gray(im2), rgb2gray(im2))) % stereoAnaglyph

%%
% compute disparity on the undistorted and rectified stereo image pair
if true
    bm = cv.StereoSGBM();
    bm.NumDisparities = 128;
    bm.BlockSize = 25;
    bm.SpeckleRange = 4;
    bm.SpeckleWindowSize = 200;
elseif true
    bm = cv.StereoBM();
    bm.NumDisparities = 192;
    bm.BlockSize = 21;
else
    bm = cv.StereoSGBM('MinDisparity',-64, 'NumDisparities',192, ...
        'BlockSize',11, 'P1',100, 'P2',1000, 'Disp12MaxDiff',32, ...
        'PreFilterCap',0, 'UniquenessRatio',15, ...
        'SpeckleWindowSize',1000, 'SpeckleRange',16, 'Mode','HH');
end
tic
D = bm.compute(rgb2gray(im1), rgb2gray(im2));
toc

%%
% disparity map is stored in 16-bit fixed-point representation, with values
% scaled by 16. To get real disparity values, we divide by 16.
DD = single(D) / 16;

%%
% the minimal value in D correspond to the invalid disparity value, i.e:
% |invalid_disp_scaled = (bm.MinDisparity - 1) * bitshift(1,4)|, or in DD:
% |invalid_disp = (bm.MinDisparity - 1)|
% (these are outliers/missing-values where the disparity was not computed)
DD(D == min(D(:))) = NaN;
fprintf('min=%d, max=%d\n', min(DD(:)), max(DD(:)));

%%
% show disparity map
figure, imshow(DD, []) % [bm.MinDisparity, bm.MinDisparity + bm.NumDisparities]
colormap('gray'), colorbar
title(sprintf('Disparity Map, %02d / %02d', i, N))

%% 3D Reconstruction
% point cloud (XYZ-coords and corresponding colors)
if true
    %TODO: something is wrong with the Q matrix, result seems always bad!
    if true
        Q = RCT.Q;
        Q(4,4) = 1/Q(4,3);  % TODO: ??
    else
        Q = eye(4);
    end
    XYZ = cv.reprojectImageTo3D(D, Q);  % 'HandleMissingValues',true
    XYZ = reshape(XYZ, [], 3);
else
    [X,Y] = meshgrid(1:size(DD,1), 1:size(DD,2));
    XYZ = [X(:) Y(:) DD(:)];
end
C = reshape(single(im1)/255, [], 3);

%%
% remove invalid points (filter invalid disparities) which are set to infinite
% distances bigZ=10000 by reprojectImageTo3D when HandleMissingValues=true)
mask = (D(:) == min(D(:)));
XYZ(mask,:) = [];
C(mask,:) = [];
whos XYZ C

%%
% visualize point cloud
figure, scatter3(XYZ(:,1), XYZ(:,2), XYZ(:,3), 6, C, '.')
title('Point Cloud'); xlabel('X'); ylabel('Y'); zlabel('Z');
axis tight
if ~mexopencv.isOctave()
    axis vis3d
else
    %HACK: vis3d mode not recognized in Octave
    set(gca, 'CameraViewAngle',   get(gca, 'CameraViewAngle'));
    set(gca, 'PlotBoxAspectRatio',get(gca, 'PlotBoxAspectRatio'));
    set(gca, 'DataAspectRatio',   get(gca, 'DataAspectRatio'));
end
if ~mexopencv.isOctave()
    %HACK: CAM* functions not implemented in Octave
    cameratoolbar
    cameratoolbar('SetCoordSys','y')
    %cameramenu
else
    view(-37.5,-60)
    rotate3d on
end

##### SOURCE END #####
-->
   </body>
</html>