<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>OCR of hand-written digits using kNN</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="knn_ocr_digits_demo.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">OCR of hand-written digits using kNN</h1>
         <!--introduction-->
         <p>We will use kNN to build a basic OCR application.</p>
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://docs.opencv.org/3.2.0/d8/d4b/tutorial_py_knn_opencv.html">https://docs.opencv.org/3.2.0/d8/d4b/tutorial_py_knn_opencv.html</a></li>
            </ul>
         </div>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Hand-written Digits Dataset</a></li>
               <li><a href="#8">Train</a></li>
               <li><a href="#9">Test</a></li>
            </ul>
         </div>
         <h2 id="2">Hand-written Digits Dataset</h2>
         <p>Our goal is to build an application which can recognize handwritten digits. For this we need some train and test data. OpenCV
            comes with an image <tt>digits.png</tt> which has 5000 handwritten digits (500 for each digit). Each digit is a 20x20 image. So our first step is to split this image
            into 5000 different digits. For each digit, we flatten it into a single row with 400 pixels. That is our feature set, i.e
            intensity values of all pixels. It is the simplest feature set we can create. We split half the data for training, the other
            half for testing (2500 samples each).
         </p>
         <p>Load MNIST handwritten digits, one big image</p><pre class="codeinput">fname = fullfile(mexopencv.root(), <span class="string">'test'</span>, <span class="string">'digits.png'</span>);
<span class="keyword">if</span> exist(fname, <span class="string">'file'</span>) ~= 2
    disp(<span class="string">'Downloading image...'</span>)
    url = <span class="string">'https://cdn.rawgit.com/opencv/opencv/3.2.0/samples/data/digits.png'</span>;
    urlwrite(url, fname);
<span class="keyword">end</span>
img = cv.imread(fname, <span class="string">'Grayscale'</span>,true);</pre><p>split it into 5000 small images (500 from each 0:9 digits), each image is 20x20 pixels</p><pre class="codeinput">imgs = mat2cell(img, ones(1,5*10)*20, ones(1,100)*20);
imgs = reshape(imgs', 5*100, [])';  <span class="comment">% cell array of size 10x500</span>
labels = repmat((0:9)', 1, 5*100);  <span class="comment">% each row is one digit</span></pre><p>shuffle data by permuting columns of cell array</p><pre class="codeinput">idx = randperm(500);
imgs = imgs(:,idx);
labels = labels(:,idx);</pre><p>flatten each image pixels into a 1x400 feature vector</p><pre class="codeinput">imgs = cellfun(@(im) im(:)', imgs, <span class="string">'UniformOutput'</span>,false);</pre><p>Create training and test sets, 2500x400 matrices</p><pre class="codeinput">xtrain = single(cat(1, imgs{:,1:250}));
xtest = single(cat(1, imgs{:,251:500}));
ytrain = int32(reshape(labels(:,1:250), [], 1));
ytest = int32(reshape(labels(:,251:500), [], 1));
<span class="keyword">if</span> false
    <span class="comment">% save dataset as MAT-file</span>
    out = fullfile(tempdir(), <span class="string">'digits.mat'</span>);
    save(out, <span class="string">'xtrain'</span>, <span class="string">'xtest'</span>, <span class="string">'ytrain'</span>, <span class="string">'ytest'</span>);
<span class="keyword">end</span></pre><h2 id="8">Train</h2>
         <p>K-nearest neighbor classifier</p><pre class="codeinput">K = 5;
knn = cv.KNearest();
knn.DefaultK = K;
knn.train(xtrain, ytrain);</pre><h2 id="9">Test</h2>
         <p>Predict using 5 nearest neighbors</p><pre class="codeinput">yhat = knn.findNearest(xtest, K);</pre><p>Performance on test set</p><pre class="codeinput">confmat = accumarray([ytest, yhat]+1, 1);
display(confmat)
fprintf(<span class="string">'Accuracy = %.2f%%\n'</span>, sum(diag(confmat)) * 100 / sum(confmat(:)));</pre><pre class="codeoutput">confmat =
   244     1     0     0     0     0     3     1     1     0
     0   248     1     0     1     0     0     0     0     0
     4    10   217     3     2     1     2     5     6     0
     1     1     2   235     1     5     0     1     3     1
     0     4     0     1   225     0     1     0     0    19
     4     3     1     6     4   227     4     0     0     1
     2     1     1     0     1     2   243     0     0     0
     0     3     1     1     7     0     0   229     0     9
     3     4     0     8     0    10     2     3   216     4
     2     0     0     3     7     1     1     5     1   230
Accuracy = 92.56%
</pre><p>Show misclassifications in test set, highlighted in red</p><pre class="codeinput"><span class="keyword">if</span> mexopencv.require(<span class="string">'images'</span>)
    img = repmat(permute(reshape(uint8(xtest), [2500 20 20]), [2 3 4 1]), [1 1 3 1]);
    img(:,:,2:3,yhat ~= ytest) = 0;
    idx = reshape(1:2500, 10, 250)';  <span class="comment">% rearrange to show digits consecutively</span>
    montage(img(:,:,:,idx(:)), <span class="string">'Size'</span>,[50 50])
    title(sprintf(<span class="string">'KNN, K=%d, %d/2500 wrong predictions'</span>, K, nnz(yhat ~= ytest)))
<span class="keyword">end</span></pre><pre class="codeoutput">Warning: Image is too big to fit on screen; displaying at 67% 
</pre><img src="knn_ocr_digits_demo_01.png"><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div>
      <!--
##### SOURCE BEGIN #####
%% OCR of hand-written digits using kNN
%
% We will use kNN to build a basic OCR application.
%
% Sources:
%
% * <https://docs.opencv.org/3.2.0/d8/d4b/tutorial_py_knn_opencv.html>
%

%% Hand-written Digits Dataset
%
% Our goal is to build an application which can recognize handwritten digits.
% For this we need some train and test data. OpenCV comes with an image
% |digits.png| which has 5000 handwritten digits (500 for each digit). Each
% digit is a 20x20 image. So our first step is to split this image into 5000
% different digits. For each digit, we flatten it into a single row with 400
% pixels. That is our feature set, i.e intensity values of all pixels. It is
% the simplest feature set we can create. We split half the data for training,
% the other half for testing (2500 samples each).
%

%%
% Load MNIST handwritten digits, one big image
fname = fullfile(mexopencv.root(), 'test', 'digits.png');
if exist(fname, 'file') ~= 2
    disp('Downloading image...')
    url = 'https://cdn.rawgit.com/opencv/opencv/3.2.0/samples/data/digits.png';
    urlwrite(url, fname);
end
img = cv.imread(fname, 'Grayscale',true);

%%
% split it into 5000 small images (500 from each 0:9 digits),
% each image is 20x20 pixels
imgs = mat2cell(img, ones(1,5*10)*20, ones(1,100)*20);
imgs = reshape(imgs', 5*100, [])';  % cell array of size 10x500
labels = repmat((0:9)', 1, 5*100);  % each row is one digit

%%
% shuffle data by permuting columns of cell array
idx = randperm(500);
imgs = imgs(:,idx);
labels = labels(:,idx);

%%
% flatten each image pixels into a 1x400 feature vector
imgs = cellfun(@(im) im(:)', imgs, 'UniformOutput',false);

%%
% Create training and test sets, 2500x400 matrices
xtrain = single(cat(1, imgs{:,1:250}));
xtest = single(cat(1, imgs{:,251:500}));
ytrain = int32(reshape(labels(:,1:250), [], 1));
ytest = int32(reshape(labels(:,251:500), [], 1));
if false
    % save dataset as MAT-file
    out = fullfile(tempdir(), 'digits.mat');
    save(out, 'xtrain', 'xtest', 'ytrain', 'ytest');
end

%% Train
% K-nearest neighbor classifier
K = 5;
knn = cv.KNearest();
knn.DefaultK = K;
knn.train(xtrain, ytrain);

%% Test
% Predict using 5 nearest neighbors
yhat = knn.findNearest(xtest, K);

%%
% Performance on test set
confmat = accumarray([ytest, yhat]+1, 1);
display(confmat)
fprintf('Accuracy = %.2f%%\n', sum(diag(confmat)) * 100 / sum(confmat(:)));

%%
% Show misclassifications in test set, highlighted in red
if mexopencv.require('images')
    img = repmat(permute(reshape(uint8(xtest), [2500 20 20]), [2 3 4 1]), [1 1 3 1]);
    img(:,:,2:3,yhat ~= ytest) = 0;
    idx = reshape(1:2500, 10, 250)';  % rearrange to show digits consecutively
    montage(img(:,:,:,idx(:)), 'Size',[50 50])
    title(sprintf('KNN, K=%d, %d/2500 wrong predictions', K, nnz(yhat ~= ytest)))
end

##### SOURCE END #####
-->
   </body>
</html>