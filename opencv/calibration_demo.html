<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>Camera Calibration</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="calibration_demo.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">Camera Calibration</h1>
         <!--introduction-->
         <p>This example demonstrates camera calibration in OpenCV. It shows usage of the following functions:</p>
         <div>
            <ul>
               <li><tt>cv.findChessboardCorners</tt>, <tt>cv.findCirclesGrid</tt></li>
               <li><tt>cv.cornerSubPix</tt></li>
               <li><tt>cv.drawChessboardCorners</tt></li>
               <li><tt>cv.initCameraMatrix2D</tt></li>
               <li><tt>cv.calibrateCamera</tt></li>
               <li><tt>cv.projectPoints</tt></li>
               <li><tt>cv.getOptimalNewCameraMatrix</tt></li>
               <li><tt>cv.initUndistortRectifyMap</tt>, <tt>cv.remap</tt></li>
               <li><tt>cv.undistort</tt></li>
               <li><tt>cv.Rodrigues</tt></li>
            </ul>
         </div>
         <p>You can find more test images at these locations:</p>
         <div>
            <ul>
               <li><a href="https://github.com/opencv/opencv_extra/tree/3.2.0/learning_opencv_v2/calibration">https://github.com/opencv/opencv_extra/tree/3.2.0/learning_opencv_v2/calibration</a></li>
               <li><a href="https://github.com/opencv/opencv_extra/tree/3.2.0/learning_opencv_v2/stereoData">https://github.com/opencv/opencv_extra/tree/3.2.0/learning_opencv_v2/stereoData</a></li>
               <li><a href="https://github.com/opencv/opencv_extra/tree/3.2.0/testdata/cv/cameracalibration">https://github.com/opencv/opencv_extra/tree/3.2.0/testdata/cv/cameracalibration</a></li>
            </ul>
         </div>
         <p>Cameras have been around for a long-long time. However, with the introduction of the cheap pinhole cameras in the late 20th
            century, they became a common occurrence in our everyday life. Unfortunately, this cheapness comes with its price: significant
            distortion. Luckily, these are constants and with a calibration and some remapping we can correct this. Furthermore, with
            calibration you may also determine the relation between the camera's natural units (pixels) and the real world units (for
            example millimeters).
         </p>
         <p>In the sample, we will learn:</p>
         <div>
            <ul>
               <li>about distortions in camera, intrinsic and extrinsic parameters of camera</li>
               <li>how to find these parameters, undistort images, etc.</li>
            </ul>
         </div>
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/calibration.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/calibration.cpp</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/python/calibrate.py">https://github.com/opencv/opencv/blob/3.2.0/samples/python/calibrate.py</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/d4/d94/tutorial_camera_calibration.html">https://docs.opencv.org/3.2.0/d4/d94/tutorial_camera_calibration.html</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/dc/dbb/tutorial_py_calibration.html">https://docs.opencv.org/3.2.0/dc/dbb/tutorial_py_calibration.html</a></li>
            </ul>
         </div>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Theory</a></li>
               <li><a href="#3">Code</a></li>
            </ul>
         </div>
         <h2 id="2">Theory</h2>
         <p>Two major distortions OpenCV takes into account are radial distortion and tangential distortion. For the radial factor one
            uses the following formula:
         </p>
         <p><img src="calibration_demo_eq06771975778568603865.png" alt="$$\begin{array}{l}&#xA;x_{distorted} = x( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6) \cr&#xA;y_{distorted} = y( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6)&#xA;\end{array}$$" class="equation" width="229" height="34"></p>
         <p>So for an undistorted pixel point at <img src="calibration_demo_eq18047527249248817779.png" alt="$(x,y)$" class="equation" width="32" height="15"> coordinates, its position on the distorted image will be <img src="calibration_demo_eq09117600009590301758.png" alt="$(x_{distorted}, y_{distorted})$" class="equation" width="115" height="15">. The presence of the radial distortion manifests in form of the "barrel" or "fish-eye" effect.
         </p>
         <p>Due to radial distortion, straight lines will appear curved. Its effect is more as we move away from the center of image.
            For example, one image is shown below, where two edges of a chess board are marked with red lines. But you can see that border
            is not a straight line and doesn't match with the red line. All the expected straight lines are bulged out. See <a href="https://en.wikipedia.org/wiki/Distortion_%28optics%29">Distortion</a> for more details.
         </p>
         <p><img src="https://docs.opencv.org/3.2.0/calib_radial.jpg"></p>
         <p>Tangential distortion occurs because the image taking lenses are not perfectly parallel to the imaging plane. So some areas
            in image may look nearer than expected. It can be represented via the formulas:
         </p>
         <p><img src="calibration_demo_eq14226409297105884532.png" alt="$$\begin{array}{l}&#xA;x_{distorted} = x + [ 2p_1xy + p_2(r^2+2x^2)] \cr&#xA;y_{distorted} = y + [ p_1(r^2+ 2y^2)+ 2p_2xy]&#xA;\end{array}$$" class="equation" width="235" height="34"></p>
         <p>So we have five distortion parameters which in OpenCV are presented as one row matrix with 5 columns:</p>
         <p><img src="calibration_demo_eq16900747589579680754.png" alt="$$distortion\_coefficients = (k_1, k_2, p_1, p_2, k_3)$$" class="equation" width="275" height="15"></p>
         <p>In addition to this, we need to find a few more information, like intrinsic and extrinsic parameters of a camera. Intrinsic
            parameters are specific to a camera. Extrinsic parameters corresponds to rotation and translation vectors which translates
            a coordinates of a 3D point to a coordinate system.
         </p>
         <p>Now for the unit conversion we use the following formula:</p>
         <p><img src="calibration_demo_eq05361219101331794506.png" alt="$$\left[ {\matrix{ x \cr y \cr w }} \right] =&#xA;  \left[ {\matrix{ f_x &amp; 0 &amp; c_x \cr 0 &amp; f_y &amp; c_y \cr 0 &amp; 0 &amp; 1 }} \right]&#xA;  \left[ {\matrix{ X \cr Y \cr Z }} \right]$$" class="equation" width="180" height="53"></p>
         <p>Here the presence of <img src="calibration_demo_eq00125694759345388081.png" alt="$w$" class="equation" width="10" height="7"> is explained by the use of homography coordinate system (and <img src="calibration_demo_eq02706854608860150093.png" alt="$w=Z$" class="equation" width="41" height="11">). The unknown parameters are <img src="calibration_demo_eq13223538974671168557.png" alt="$f_x$" class="equation" width="13" height="14"> and <img src="calibration_demo_eq05403568010390334380.png" alt="$f_y$" class="equation" width="12" height="15"> (camera focal lengths) and <img src="calibration_demo_eq03908307232179778199.png" alt="$(c_x, c_y)$" class="equation" width="41" height="16"> which are the optical centers expressed in pixels coordinates. If for both axes a common focal length is used with a given
            <img src="calibration_demo_eq05508344529756732484.png" alt="$a$" class="equation" width="7" height="7"> aspect ratio (usually 1), then <img src="calibration_demo_eq15039692295831757369.png" alt="$f_y=f_x*a$" class="equation" width="68" height="15"> and in the upper formula we will have a single focal length <img src="calibration_demo_eq18096895394918367257.png" alt="$f$" class="equation" width="8" height="14">. The matrix containing these four parameters is referred to as the <i>camera matrix</i>. While the distortion coefficients are the same regardless of the camera resolutions used, these should be scaled along with
            the current resolution from the calibrated resolution.
         </p>
         <p>The process of determining these two matrices is the <b>calibration</b>. Calculation of these parameters is done through basic geometrical equations. The equations used depend on the chosen calibrating
            objects with well defined pattern. Currently OpenCV supports three types of objects for calibration:
         </p>
         <div>
            <ul>
               <li>Classical black-white chessboard</li>
               <li>Symmetrical circle pattern</li>
               <li>Asymmetrical circle pattern</li>
            </ul>
         </div>
         <p><img src="https://docs.opencv.org/3.2.0/asymetricalPattern.jpg"></p>
         <p>Basically, you need to take snapshots of these patterns with your camera and let OpenCV find them. Each found pattern results
            in a new equation (we know its coordinates in real world space and we know its coordinates found in image). To solve the equation
            you need at least a predetermined number of pattern snapshots to form a well-posed equation system. This number is higher
            for the chessboard pattern and less for the circle ones. For example, in theory the chessboard pattern requires at least two
            snapshots. However, in practice we have a good amount of noise present in our input images, so for good results you will probably
            need at least 10 good snapshots of the input pattern in different positions.
         </p>
         <p>We do the calibration with the help of the <tt>cv.calibrateCamera</tt> function. It has the following arguments:
         </p>
         <div>
            <ul>
               <li>The object points. This is a cell array of Nx3 points that for each input   image describes how should the pattern look. If
                  we have a planar pattern   (like a chessboard) then we can simply set all Z coordinates to zero. This   is a collection of
                  the points where these important points are present.   Because, we use a single pattern for all the input images we can calculate
                    this just once and repeat it for all the other input views. We calculate   the corner points with the <tt>calcBoardCorners</tt> function.
               </li>
               <li>The image points. This is a cell arrray of Nx2 points which for each input   image contains coordinates of the important points
                  (corners for chessboard   and centers of the circles for the circle pattern). We have already   collected this from <tt>cv.findChessboardCorners</tt> or <tt>cv.findCirclesGrid</tt>   function. We just need to pass it on.
               </li>
               <li>The size of the image.</li>
               <li>The camera matrix. If we used the fixed aspect ratio option we need to set   <img src="calibration_demo_eq13223538974671168557.png" alt="$f_x$" class="equation" width="13" height="14">.
               </li>
               <li>The distortion coefficient matrix, initialized with zeros.</li>
               <li>The final argument is the flag. You need to specify here options like fix   the aspect ratio for the focal length, assume
                  zero tangential distortion   or to fix the principal point.
               </li>
               <li>For all the views, the function will calculate rotation and translation   arrays which transform the object points (given
                  in the model coordinate   space) to the image points (given in the world coordinate space). The   output cell array of matrices
                  containing in the i-th position the rotation   and translation vector for the i-th object point to the i-th image point.
               </li>
               <li>The function returns the average re-projection error. This number gives a   good estimation of precision of the found parameters.
                  This should be as   close to zero as possible. Given the intrinsic, distortion, rotation and   translation matrices we may
                  calculate the error for one view by using the   <tt>cv.projectPoints</tt> to first transform the object point to image point.   Then we calculate the absolute norm between what we got with our  
                  transformation and the corner/circle finding algorithm. To find the   average error we calculate the arithmetical mean of
                  the errors calculated   for all the calibration images.
               </li>
            </ul>
         </div>
         <p>You may watch a video of the camera calibration on <a href="https://www.youtube.com/watch?v=ViPN810E0SU">YouTube</a>.
         </p>
         <p>Once calibration is done, we can undistort images and correct them for the lens distortion. For example, you can see in the
            result below that all the edges become straight.
         </p>
         <p><img src="https://docs.opencv.org/3.2.0/fileListImage.jpg"></p>
         <p><img src="https://docs.opencv.org/3.2.0/fileListImageUnDist.jpg"></p>
         <h2 id="3">Code</h2><pre class="codeinput"><span class="keyword">function</span> varargout = calibration_demo()</pre><p>Options and calibration flags (keep in mind that the number of images needed grows dramatically with the number of parameters
            we are solving for, i.e distortion coeffs)
         </p><pre class="codeinput">    opts = struct();
    opts.aspectRatio = 1;                 <span class="comment">% aspect ratio (ar = fx/fy)</span>
    opts.flags.UseIntrinsicGuess = false; <span class="comment">% how to initize camera matrix</span>
    opts.flags.FixAspectRatio = true;     <span class="comment">% fix aspect ratio (ar = fx/fy)</span>
    opts.flags.FixFocalLength = false;    <span class="comment">% fix fx and fy</span>
    opts.flags.FixPrincipalPoint = false; <span class="comment">% fix principal point at the center</span>
    opts.flags.ZeroTangentDist = false;   <span class="comment">% assume zero tangential distortion</span>
    opts.flags.RationalModel = false;     <span class="comment">% enable (k4,k5,k6)</span>
    opts.flags.ThinPrismModel = false;    <span class="comment">% enable (s1,s2,s3,s4)</span>
    opts.flags.TiltedModel = false;       <span class="comment">% enable (taux,tauy)</span>
    <span class="comment">%opts.flags.FixK3 = true;</span>
    <span class="comment">%opts.flags.FixK4 = true;</span>
    <span class="comment">%opts.flags.FixK5 = true;</span></pre><p>list of board images</p><pre class="codeinput">    opts.pattern = <span class="string">'chessboard'</span>; <span class="comment">% type of pattern grid: chessboard, acircles, circles</span>
    opts.boardSize = [9 6];      <span class="comment">% number of inner corners per board dimensions</span>
    opts.squareSize = 30.0;      <span class="comment">% board square size in millimeters</span>
    files = cv.glob(fullfile(mexopencv.root(), <span class="string">'test'</span>, <span class="string">'left*.jpg'</span>));
    finfo = imfinfo(files{1});
    opts.imageSize = [finfo.Width, finfo.Height];
    display(opts);
    display(files(:));</pre><pre class="codeoutput">opts = 
  struct with fields:

    aspectRatio: 1
          flags: [1&times;1 struct]
        pattern: 'chessboard'
      boardSize: [9 6]
     squareSize: 30
      imageSize: [640 480]
  13&times;1 cell array
    'C:\Users\Amro\Desktop\mexopencv\test\left01.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left02.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left03.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left04.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left05.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left06.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left07.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left08.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left09.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left11.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left12.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left13.jpg'
    'C:\Users\Amro\Desktop\mexopencv\test\left14.jpg'
</pre><p>load images</p><pre class="codeinput">    N = numel(files);
    imgs = cell(N,1);
    <span class="keyword">for</span> i=1:N
        imgs{i} = cv.imread(files{i}, <span class="string">'Color'</span>,true);
    <span class="keyword">end</span></pre><p>detect image points, and filter out views where detection failed</p><pre class="codeinput">    [imagePoints, found] = detectImageCorners(imgs, opts);
    <span class="keyword">if</span> ~all(found)
        files = files(found);
        imgs = imgs(found);
        imagePoints = imagePoints(found);
        found = found(found);
        N = nnz(found);
        assert(N &gt;= 2, <span class="string">'Not enough views'</span>);
    <span class="keyword">end</span></pre><p>show detected corners</p><pre class="codeinput">    <span class="keyword">for</span> i=1:N
        img = cv.drawChessboardCorners(imgs{i}, opts.boardSize, <span class="keyword">...</span>
            imagePoints{i}, <span class="string">'PatternWasFound'</span>,found(i));
        imshow(img), title(sprintf(<span class="string">'Detection, %d/%d'</span>, i, N))
        pause(1)
    <span class="keyword">end</span></pre><img src="calibration_demo_01.png"><p>create object points (we assume a fully visible calibration pattern, the same shown in each view)</p><pre class="codeinput">    objectPoints = calcBoardCorners(opts);
    objectPoints = repmat({objectPoints}, N, 1);</pre><p>run calibration</p><pre class="codeinput">    [calib, ok] = runCalibration(objectPoints, imagePoints, opts);
    <span class="keyword">if</span> ~ok
        disp(<span class="string">'calibration failed'</span>);
        <span class="keyword">return</span>;
    <span class="keyword">end</span>
    fprintf(<span class="string">'avg reprojection error = %f\n'</span>, calib.rms)

    <span class="comment">%</span>
    <span class="comment">% save intrinsic/extrinsic parameters</span>
    fname = fullfile(tempdir(), sprintf(<span class="string">'calibration_%s.yml'</span>, opts.pattern));
    saveCameraParams(fname, calib, opts);  <span class="comment">% ..., true, imagePoints</span>
    fprintf(<span class="string">'Saved to: %s\n'</span>, fname);</pre><pre class="codeoutput">avg reprojection error = 0.392591
Saved to: C:\Users\Amro\AppData\Local\Temp\calibration_chessboard.yml
</pre><p>display parameter estimation errors</p><pre class="codeinput">    displayErrorEstimates(calib);</pre><pre class="codeoutput">
			Standard Errors of Estimated Camera Parameters
			----------------------------------------------

Intrinsics
----------
Focal length (pixels):    [  535.9158 +/- 0.0000      535.9158 +/- 1.2919    ]
Principal Point (pixels): [  342.2831 +/- 1.3643      235.5708 +/- 1.4770    ]
Radial distortion:        [   -0.2664 +/- 0.0163       -0.0386 +/- 0.1271        0.2384 +/- 0.2763    ]
Tangential distortion:    [    0.0018 +/- 0.0003       -0.0003 +/- 0.0004    ]
Rational distortion:      [    0.0000 +/- 0.0000        0.0000 +/- 0.0000        0.0000 +/- 0.0000    ]
Thin Prism distortion:    [    0.0000 +/- 0.0000        0.0000 +/- 0.0000        0.0000 +/- 0.0000        0.0000 +/- 0.0000    ]
Tilt distortion:          [    0.0000 +/- 0.0000        0.0000 +/- 0.0000    ]

Extrinsics
----------
Rotation vectors:
	[    0.1687 +/- 0.0045        0.2757 +/- 0.0037        0.0135 +/- 0.0007    ]
	[    0.4133 +/- 0.0030        0.6499 +/- 0.0030       -1.3372 +/- 0.0011    ]
	[   -0.2770 +/- 0.0032        0.1869 +/- 0.0029        0.3549 +/- 0.0006    ]
	[   -0.1109 +/- 0.0035        0.2397 +/- 0.0031       -0.0021 +/- 0.0006    ]
	[   -0.2919 +/- 0.0032        0.4284 +/- 0.0031        1.3127 +/- 0.0008    ]
	[    0.4078 +/- 0.0045        0.3037 +/- 0.0048        1.6491 +/- 0.0010    ]
	[    0.1793 +/- 0.0043        0.3456 +/- 0.0042        1.8685 +/- 0.0011    ]
	[   -0.0910 +/- 0.0034        0.4798 +/- 0.0036        1.7534 +/- 0.0009    ]
	[    0.2030 +/- 0.0033       -0.4239 +/- 0.0029        0.1324 +/- 0.0008    ]
	[   -0.4191 +/- 0.0031       -0.4997 +/- 0.0031        1.3356 +/- 0.0011    ]
	[   -0.2385 +/- 0.0033        0.3479 +/- 0.0034        1.5308 +/- 0.0008    ]
	[    0.4640 +/- 0.0034       -0.2835 +/- 0.0032        1.2386 +/- 0.0009    ]
	[   -0.1700 +/- 0.0032       -0.4712 +/- 0.0033        1.3460 +/- 0.0009    ]
Translation vectors (world units):
	[  -90.2615 +/- 1.2416     -130.7513 +/- 1.3360      479.6425 +/- 1.2225    ]
	[  -70.2860 +/- 1.0905       99.5110 +/- 1.1628      424.5722 +/- 0.8268    ]
	[  -47.8158 +/- 0.9803     -120.4993 +/- 1.0490      381.7914 +/- 0.9091    ]
	[ -118.0928 +/- 1.0151      -80.7960 +/- 1.1010      397.0229 +/- 0.9889    ]
	[   70.1913 +/- 0.9831     -138.3804 +/- 1.0571      380.6232 +/- 0.8789    ]
	[  200.7249 +/- 1.1203      -78.6852 +/- 1.1897      403.7536 +/- 1.2704    ]
	[   23.4401 +/- 1.2035      -86.1863 +/- 1.2831      467.3153 +/- 1.2198    ]
	[   94.8605 +/- 0.9806     -105.5304 +/- 1.0515      379.9929 +/- 0.9313    ]
	[  -79.6155 +/- 0.8793      -97.2232 +/- 0.9395      333.9627 +/- 0.9948    ]
	[   56.2833 +/- 1.0458     -133.2075 +/- 1.1206      405.6676 +/- 0.9723    ]
	[   60.9174 +/- 0.9959     -123.1165 +/- 1.0639      386.6416 +/- 0.9060    ]
	[   40.4392 +/- 0.9075     -109.9407 +/- 0.9918      349.7354 +/- 1.0263    ]
	[   54.0186 +/- 0.9671     -129.8143 +/- 1.0406      374.9252 +/- 0.9582    ]
</pre><p>reprojection errors</p><pre class="codeinput">    [calib.rms, calib.rmsPerView, reprojErrs] = computeReprojectionErrors(<span class="keyword">...</span>
        objectPoints, imagePoints, calib);
    figure, visualizeReprojErrors(calib.rms, calib.rmsPerView, reprojErrs);</pre><img src="calibration_demo_02.png"><img src="calibration_demo_03.png"><p>visualize board locations (poses in camera centric view)</p><pre class="codeinput">    figure, visualizeExtrinsics(calib, opts);</pre><img src="calibration_demo_04.png"><p>visualize distortion model</p><pre class="codeinput">    figure, visualizeDistortion(calib, opts);</pre><img src="calibration_demo_05.png"><p>correct images for lens distortion, and show them</p><pre class="codeinput">    [undistortImage, roi] = buildUndistortFunction(calib, opts);
    figure
    <span class="keyword">for</span> i=1:N
        img = undistortImage(imgs{i});
        <span class="keyword">if</span> false
            img = cv.Rect.crop(img, roi);
        <span class="keyword">end</span>
        imshow(img), title(sprintf(<span class="string">'Undistortion, %d/%d'</span>, i, N))
        pause(1)
    <span class="keyword">end</span></pre><img src="calibration_demo_06.png"><p>output arguments</p><pre class="codeinput">    <span class="keyword">if</span> nargout &gt; 0, varargout{1} = calib; <span class="keyword">end</span>
    <span class="keyword">if</span> nargout &gt; 1, varargout{2} = opts; <span class="keyword">end</span></pre><pre class="codeinput"><span class="keyword">end</span></pre><pre class="codeinput"><span class="keyword">function</span> [imagePoints, founds] = detectImageCorners(imgs, opts)
    <span class="keyword">if</span> true
        blobOpts = {};
    <span class="keyword">else</span>
        <span class="comment">% customize blob detector used in findCirclesGrid</span>
        blobOpts = {<span class="string">'BlobDetector'</span>,{<span class="string">'SimpleBlobDetector'</span>, <span class="string">'MaxArea'</span>,1e4}};
    <span class="keyword">end</span>

    N = numel(imgs);
    imagePoints = cell(N,1);
    founds = false(N,1);
    <span class="keyword">for</span> i=1:N
        <span class="keyword">switch</span> opts.pattern
            <span class="keyword">case</span> <span class="string">'chessboard'</span>
                [pts,found] = cv.findChessboardCorners(<span class="keyword">...</span>
                    imgs{i}, opts.boardSize, <span class="string">'FastCheck'</span>,true);
                <span class="keyword">if</span> found
                    <span class="comment">% improve the found corners coordinate accuracy</span>
                    gray = cv.cvtColor(imgs{i}, <span class="string">'RGB2GRAY'</span>);
                    pts = cv.cornerSubPix(gray, pts, <span class="string">'WinSize'</span>,[11 11], <span class="keyword">...</span>
                        <span class="string">'Criteria'</span>,struct(<span class="string">'type'</span>,<span class="string">'Count+EPS'</span>, <span class="keyword">...</span>
                            <span class="string">'maxCount'</span>,30, <span class="string">'epsilon'</span>,0.1));
                <span class="keyword">end</span>
            <span class="keyword">case</span> <span class="string">'circles'</span>
                [pts,found] = cv.findCirclesGrid(imgs{i}, opts.boardSize, <span class="keyword">...</span>
                    <span class="string">'SymmetricGrid'</span>,true, blobOpts{:});
            <span class="keyword">case</span> <span class="string">'acircles'</span>
                [pts,found] = cv.findCirclesGrid(imgs{i}, opts.boardSize, <span class="keyword">...</span>
                    <span class="string">'SymmetricGrid'</span>,false, blobOpts{:});
            <span class="keyword">otherwise</span>
                pts = {};
                found = false;
        <span class="keyword">end</span>
        imagePoints{i} = cat(1, pts{:});
        founds(i) = found;
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> corners = calcBoardCorners(opts)
    <span class="comment">% planar calibration pattern (in model coordinate system)</span>
    [X,Y] = ndgrid(1:opts.boardSize(1), 1:opts.boardSize(2));
    <span class="keyword">switch</span> opts.pattern
        <span class="keyword">case</span> {<span class="string">'chessboard'</span>, <span class="string">'circles'</span>}
            corners = [X(:), Y(:)];
        <span class="keyword">case</span> <span class="string">'acircles'</span>
            corners = [2*X(:) + mod(Y(:),2), Y(:)];
        <span class="keyword">otherwise</span>
            corners = zeros(0,2);
    <span class="keyword">end</span>
    corners = (corners - 1) * opts.squareSize;
    corners(:,3) = 0;  <span class="comment">% Z = 0</span>
<span class="keyword">end</span>

<span class="keyword">function</span> [calib, ok] = runCalibration(objectPoints, imagePoints, opts)
    <span class="comment">% calibration flags</span>
    calib = struct();
    <span class="keyword">if</span> opts.flags.UseIntrinsicGuess
        <span class="keyword">if</span> opts.flags.FixAspectRatio
            params = {<span class="string">'AspectRatio'</span>,opts.aspectRatio};
        <span class="keyword">else</span>
            params = {<span class="string">'AspectRatio'</span>,0};
        <span class="keyword">end</span>
        calib.M = cv.initCameraMatrix2D(objectPoints, imagePoints, <span class="keyword">...</span>
            opts.imageSize, params{:});
    <span class="keyword">else</span>
        calib.M = eye(3);
        <span class="keyword">if</span> opts.flags.FixAspectRatio
            calib.M(1,1) = opts.aspectRatio;
        <span class="keyword">end</span>
    <span class="keyword">end</span>
    <span class="keyword">if</span> opts.flags.TiltedModel
        calib.D = zeros(1,14);
    <span class="keyword">elseif</span> opts.flags.ThinPrismModel
        calib.D = zeros(1,12);
    <span class="keyword">elseif</span> opts.flags.RationalModel
        calib.D = zeros(1,8);
    <span class="keyword">else</span>
        calib.D = zeros(1,5);
    <span class="keyword">end</span>
    params = st2kv(opts.flags);
    params = [params, <span class="string">'CameraMatrix'</span>,calib.M, <span class="string">'DistCoeffs'</span>,calib.D, <span class="keyword">...</span>
        <span class="string">'UseIntrinsicGuess'</span>,opts.flags.UseIntrinsicGuess];

    <span class="comment">% calibration: find intrinsic and extrinsic camera parameters</span>
    <span class="keyword">if</span> false
        <span class="comment">% we will later manually compute reprojection errors</span>
        [calib.M, calib.D, calib.rms, calib.R, calib.T] = cv.calibrateCamera(<span class="keyword">...</span>
            objectPoints, imagePoints, opts.imageSize, params{:});
        <span class="comment">% placeholder for standard deviations of estimates</span>
        calib.sdInt = nan(1, 18);
        calib.sdExt = nan(1, 6*numel(calib.R));
    <span class="keyword">else</span>
        <span class="comment">% returns reprojection errors (same as computeReprojectionErrors)</span>
        [calib.M, calib.D, calib.rms, calib.R, calib.T, <span class="keyword">...</span>
            calib.sdInt, calib.sdExt, calib.rmsPerView] = cv.calibrateCamera(<span class="keyword">...</span>
            objectPoints, imagePoints, opts.imageSize, params{:});
    <span class="keyword">end</span>
    ok = all(isfinite([calib.M(:); calib.D(:)]));
<span class="keyword">end</span>

<span class="keyword">function</span> saveCameraParams(filename, calib, opts, writeExtrinsics, imagePoints)
    <span class="keyword">if</span> nargin &lt; 4, writeExtrinsics = false; <span class="keyword">end</span>

    fs = struct();
    fs.calibration_time = datestr(now());
    <span class="keyword">if</span> writeExtrinsics
        fs.nframes = int32(numel(calib.R));
    <span class="keyword">end</span>
    fs.image_width = int32(opts.imageSize(1));
    fs.image_height = int32(opts.imageSize(2));
    fs.board_width = int32(opts.boardSize(1));
    fs.board_height = int32(opts.boardSize(2));
    fs.square_size = opts.squareSize;
    <span class="keyword">if</span> opts.flags.FixAspectRatio
        fs.aspectRatio = opts.aspectRatio;
    <span class="keyword">end</span>
    fs.flags = opts.flags;
    fs.camera_matrix = calib.M;
    fs.distortion_coefficients = calib.D;
    <span class="keyword">if</span> writeExtrinsics
        <span class="comment">% set of 6-tuples (rotation vector + translation vector) for each view</span>
        RT = cellfun(@(r,t) [r(:); t(:)]', calib.R, calib.T, <span class="keyword">...</span>
            <span class="string">'UniformOutput'</span>,false);
        RT = cat(1, RT{:});
        fs.extrinsic_parameters = RT;
    <span class="keyword">end</span>
    <span class="keyword">if</span> nargin &gt; 4
        fs.image_points = imagePoints;
    <span class="keyword">end</span>
    cv.FileStorage(filename, fs);
<span class="keyword">end</span>

<span class="keyword">function</span> kv = st2kv(st)
    <span class="comment">% convert struct to cell-array of key/value params</span>
    k = fieldnames(st);
    v = struct2cell(st);
    kv = [k(:) v(:)]';
    kv = kv(:)';
<span class="keyword">end</span>

<span class="keyword">function</span> displayErrorEstimates(calib)
    D = calib.D;
    <span class="keyword">if</span> numel(D) &lt; 14, D(14) = 0; <span class="keyword">end</span>
    sdInt = calib.sdInt;
    <span class="keyword">if</span> numel(sdInt) &lt; 18, sdInt(18) = NaN; <span class="keyword">end</span>
    sdExt = reshape(calib.sdExt, 3, 2, []);  <span class="comment">% 1/2/3, R/T, N</span>

    fmt = <span class="string">' %9.4f +/- %-9.4f '</span>;
    fprintf(<span class="string">'\n'</span>);
    fprintf(<span class="string">'\t\t\tStandard Errors of Estimated Camera Parameters\n'</span>);
    fprintf(<span class="string">'\t\t\t----------------------------------------------\n'</span>);
    fprintf(<span class="string">'\n'</span>);
    fprintf(<span class="string">'Intrinsics\n'</span>);
    fprintf(<span class="string">'----------\n'</span>);
    fprintf(<span class="string">'Focal length (pixels):    ['</span>);
    fprintf(fmt, calib.M(1,1), sdInt(1), calib.M(2,2), sdInt(2));
    fprintf(<span class="string">']\n'</span>);
    fprintf(<span class="string">'Principal Point (pixels): ['</span>);
    fprintf(fmt, calib.M(1,3), sdInt(3), calib.M(2,3), sdInt(4));
    fprintf(<span class="string">']\n'</span>);
    fprintf(<span class="string">'Radial distortion:        ['</span>);
    fprintf(fmt, D(1), sdInt(5), D(2), sdInt(6), D(5), sdInt(9));
    fprintf(<span class="string">']\n'</span>);
    fprintf(<span class="string">'Tangential distortion:    ['</span>);
    fprintf(fmt, D(3), sdInt(7), D(4), sdInt(8));
    fprintf(<span class="string">']\n'</span>);
    fprintf(<span class="string">'Rational distortion:      ['</span>);
    fprintf(fmt, D(6), sdInt(10), D(7), sdInt(11), D(8), sdInt(12));
    fprintf(<span class="string">']\n'</span>);
    fprintf(<span class="string">'Thin Prism distortion:    ['</span>);
    fprintf(fmt, D(9), sdInt(13), D(10), sdInt(14), D(11), sdInt(15), <span class="keyword">...</span>
        D(12), sdInt(16));
    fprintf(<span class="string">']\n'</span>);
    fprintf(<span class="string">'Tilt distortion:          ['</span>);
    fprintf(fmt, D(13), sdInt(17), D(14), sdInt(18));
    fprintf(<span class="string">']\n'</span>);
    fprintf(<span class="string">'\n'</span>);
    fprintf(<span class="string">'Extrinsics\n'</span>);
    fprintf(<span class="string">'----------\n'</span>);
    fprintf(<span class="string">'Rotation vectors:\n'</span>);
    <span class="keyword">for</span> i=1:numel(calib.R)
        fprintf(<span class="string">'\t['</span>);
        fprintf(fmt, calib.R{i}(1), sdExt(1,1,i), <span class="keyword">...</span>
            calib.R{i}(2), sdExt(2,1,i), calib.R{i}(3), sdExt(3,1,i));
        fprintf(<span class="string">']\n'</span>);
    <span class="keyword">end</span>
    fprintf(<span class="string">'Translation vectors (world units):\n'</span>);
    <span class="keyword">for</span> i=1:numel(calib.T)
        fprintf(<span class="string">'\t['</span>);
        fprintf(fmt, calib.T{i}(1), sdExt(1,2,i), <span class="keyword">...</span>
            calib.T{i}(2), sdExt(2,2,i), calib.T{i}(3), sdExt(3,2,i));
        fprintf(<span class="string">']\n'</span>);
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> [rmseAvg, rmsePerView, err] = computeReprojectionErrors(objectPoints, imagePoints, calib)
    <span class="comment">% 3D points projection using camera calibration params</span>
    N = numel(objectPoints);
    imagePoints2 = cell(N,1);
    <span class="keyword">for</span> i=1:N
        imagePoints2{i} = cv.projectPoints(objectPoints{i}, <span class="keyword">...</span>
            calib.R{i}, calib.T{i}, calib.M, <span class="string">'DistCoeffs'</span>,calib.D);
    <span class="keyword">end</span>

    <span class="comment">% compute difference (reprojection errors)</span>
    err = cellfun(@minus, imagePoints, imagePoints2, <span class="string">'UniformOutput'</span>,false);

    <span class="comment">% total RMSE from all points, and RMSE per view</span>
    <span class="comment">% (same as calib.rms and calib.rmsPerView computed by calibrateCamera)</span>
    <span class="keyword">if</span> true
        fcnRMSE = @(e) sqrt(mean(sum(e.^2, 2)));
        rmseAvg = fcnRMSE(cat(1, err{:}));
        rmsePerView = cellfun(fcnRMSE, err);
    <span class="keyword">else</span>
        e = cellfun(@(e) norm(e(:)), err).^2;
        n = cellfun(@(e) size(e,1), err);
        rmseAvg = sqrt(sum(e) / sum(n));
        rmsePerView = sqrt(e ./ n);
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> [fcn, roi] = buildUndistortFunction(calib, opts)
    <span class="comment">% when the scaling parameter Alpha=0, it returns undistorted image</span>
    <span class="comment">% with minimum unwanted pixels. So it may even remove some pixels at</span>
    <span class="comment">% image corners.</span>
    <span class="comment">% When Alpha=1, all pixels are retained with some extra black images.</span>
    <span class="comment">% It also returns an image ROI which can be used to crop the result.</span>
    [newM, roi] = cv.getOptimalNewCameraMatrix(calib.M, calib.D, <span class="keyword">...</span>
        opts.imageSize, <span class="string">'Alpha'</span>,1);
    <span class="keyword">if</span> true
        [map1, map2] = cv.initUndistortRectifyMap(calib.M, calib.D, <span class="keyword">...</span>
            opts.imageSize, <span class="string">'NewCameraMatrix'</span>,newM);
        fcn = @(img) cv.remap(img, map1, map2, <span class="string">'Interpolation'</span>,<span class="string">'Linear'</span>);
    <span class="keyword">elseif</span> true
        fcn = @(img) cv.undistort(img, calib.M, calib.D, <span class="string">'NewCameraMatrix'</span>,newM);
    <span class="keyword">else</span>
        fcn = @(img) cv.undistort(img, calib.M, calib.D, <span class="string">'NewCameraMatrix'</span>,calib.M);
        roi = [0 0 opts.imageSize];
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> visualizeReprojErrors(totalAvgErr, perViewErrors, reprojErrs)
    N = numel(reprojErrs);

    <span class="comment">% visualize reprojection errors</span>
    re = cat(2, reprojErrs{:});
    plot(re(:,1:2:end), re(:,2:2:end), <span class="string">'+'</span>)
    legend(num2str((1:N)', <span class="string">'image %d'</span>)), grid <span class="string">on</span>
    xlabel(<span class="string">'X'</span>), ylabel(<span class="string">'Y'</span>)
    title(sprintf(<span class="string">'Reprojection Error (in pixel), RMSE = %f'</span>, totalAvgErr))

    <span class="comment">% visualize RMSE</span>
    figure, bar(1:N, perViewErrors)
    hLin = line(xlim(), [1 1]*totalAvgErr, <span class="string">'LineStyle'</span>,<span class="string">'--'</span>, <span class="string">'Color'</span>,<span class="string">'r'</span>);
    legend(hLin, <span class="string">'Overall Mean error'</span>)
    xlabel(<span class="string">'Images'</span>), ylabel(<span class="string">'Mean Error (in pixels)'</span>)
    title(<span class="string">'Mean Reprojection Error per Image'</span>)
<span class="keyword">end</span>

<span class="keyword">function</span> visualizeExtrinsics(calib, opts)
    N = numel(calib.R);
    clr = lines(N);
    w = (opts.boardSize(1) - 1) * opts.squareSize;
    h = (opts.boardSize(2) - 1) * opts.squareSize;
    s = max(w,h);  <span class="comment">% scale in terms of width/height</span>

    <span class="comment">% board corner points (in model coordinate system, i.e objectPoints)</span>
    XYZ = [0 0 0; w 0 0; w h 0; 0 h 0; 0 0 0]';

    <span class="comment">% axis vector points at origin of world coordinates (camera frame)</span>
    ax = [0 0 0; 1 0 0; 0 0 0; 0 1 0; 0 0 0; 0 0 1]' * (0.6*s);

    <span class="comment">% plot axis vectors at the origin</span>
    plot3(ax(1,:), ax(2,:), ax(3,:), <span class="string">'k'</span>, <span class="string">'LineWidth'</span>,2)
    hold <span class="string">on</span>
    text(0.8*s, 0, 0, <span class="string">'X_c'</span>)
    text(0, 0.8*s, 0, <span class="string">'Y_c'</span>)
    text(0, 0, 0.8*s, <span class="string">'Z_c'</span>)
    <span class="comment">% for each board</span>
    <span class="keyword">for</span> i=1:N
        <span class="comment">% transformation from model coordinates to real world coordinates</span>
        R = cv.Rodrigues(calib.R{i});
        T = calib.T{i};
        xyz = bsxfun(@plus, R * XYZ, T);
        <span class="comment">% plot board and label it</span>
        patch(xyz(1,:), xyz(2,:), xyz(3,:), clr(i,:), <span class="string">'LineWidth'</span>,1, <span class="keyword">...</span>
            <span class="string">'FaceColor'</span>,clr(i,:), <span class="string">'EdgeColor'</span>,clr(i,:), <span class="string">'FaceAlpha'</span>,0.2);
        text(T(1), T(2), T(3), num2str(i), <span class="string">'FontSize'</span>,12, <span class="string">'Color'</span>,clr(i,:));
    <span class="keyword">end</span>
    hold <span class="string">off</span>, axis <span class="string">equal</span>, grid <span class="string">on</span>, box <span class="string">on</span>
    title(<span class="string">'Extrinsic Parameters Visualization'</span>)
    xlabel(<span class="string">'X'</span>), ylabel(<span class="string">'Y'</span>), zlabel(<span class="string">'Z'</span>)  <span class="comment">% world units (mm)</span>
    <span class="keyword">if</span> ~mexopencv.isOctave()
        cameratoolbar
        cameratoolbar(<span class="string">'SetCoordSys'</span>,<span class="string">'y'</span>)
    <span class="keyword">else</span>
        <span class="comment">%HACK: CAM* functions not implemented in Octave</span>
        rotate3d <span class="string">on</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> visualizeDistortion(calib, opts)
    <span class="comment">% cameraMatrix = [fx 0 cx; 0 fy cy; 0 0 1]</span>
    <span class="comment">%</span>
    <span class="comment">% * focal lengths   : fx, fy</span>
    <span class="comment">% * aspect ratio    : a = fy/fx</span>
    <span class="comment">% * principal point : cx, cy</span>
    <span class="comment">%</span>
    M = calib.M;

    <span class="comment">% distCoeffs = [k1,k2,p1,p2,k3,k4,k5,k6,s1,s2,s3,s4,taux,tauy]</span>
    <span class="comment">%</span>
    <span class="comment">% * radial distortion     : k1, k2, k3</span>
    <span class="comment">% * tangential distortion : p1, p2</span>
    <span class="comment">% * rational distortion   : k4, k5, k6</span>
    <span class="comment">% * thin prism distortion : s1, s2, s3, s4</span>
    <span class="comment">% * tilted distortion     : taux, tauy (ignored here)</span>
    <span class="comment">%</span>
    D = calib.D;
    <span class="keyword">if</span> numel(D) &lt; 14, D(14) = 0; <span class="keyword">end</span>

    <span class="comment">% https://docs.opencv.org/3.2.0/d9/d0c/group__calib3d.html#details</span>
    nstep = 20;
    [u,v] = meshgrid(linspace(0,opts.imageSize(1)-1,nstep), <span class="keyword">...</span>
        linspace(0,opts.imageSize(2)-1,nstep));
    xyz = M \ [u(:) v(:) ones(numel(u),1)].';
    xp = xyz(1,:) ./ xyz(3,:);
    yp = xyz(2,:) ./ xyz(3,:);
    r2 = xp.^2 + yp.^2;
    r4 = r2.^2;
    r6 = r2.^3;
    coef = (1 + D(1)*r2 + D(2)*r4 + D(5)*r6) ./ (1 + D(6)*r2 + D(7)*r4 + D(8)*r6);
    xpp = xp.*coef + 2*D(3)*(xp.*yp) + D(4)*(r2 + 2*xp.^2) + D(9)*r2 + D(10)*r4;
    ypp = yp.*coef + D(3)*(r2 + 2*yp.^2) + 2*D(4)*(xp.*yp) + D(11)*r2 + D(12)*r4;
    u2 = M(1,1)*xpp + M(1,3);
    v2 = M(2,2)*ypp + M(2,3);
    du = u2(:) - u(:);
    dv = v2(:) - v(:);
    dr = reshape(hypot(du,dv), size(u));

    <span class="comment">% plot</span>
    quiver(u(:)+1, v(:)+1, du, dv)
    hold <span class="string">on</span>
    plot(opts.imageSize(1)/2, opts.imageSize(2)/2, <span class="string">'x'</span>, M(1,3), M(2,3), <span class="string">'o'</span>)
    [C, hC] = contour(u(1,:)+1, v(:,1)+1, dr, <span class="string">'k'</span>);
    clabel(C, hC)
    hold <span class="string">off</span>, axis <span class="string">ij</span> <span class="string">equal</span> <span class="string">tight</span>
    title(<span class="string">'Distortion Model'</span>), xlabel(<span class="string">'u'</span>), ylabel(<span class="string">'v'</span>)
<span class="keyword">end</span></pre><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div><script type="text/x-mathjax-config">
  // https://stackoverflow.com/a/14631703/97160
  MathJax.Extension.myImg2jax = {
    version: "1.0",
    PreProcess: function (element) {
      var images = element.getElementsByTagName("img");
      for (var i = images.length - 1; i >= 0; i--) {
        var img = images[i];
        if (img.className === "equation") {
          var match = img.alt.match(/^(\$\$?)([\s\S]*)\1$/m);
          if (!match) continue;
          var script = document.createElement("script");
          script.type = "math/tex";
          if (match[1] === "$$") {script.type += ";mode=display"}
          MathJax.HTML.setScript(script, match[2]);
          img.parentNode.replaceChild(script, img);
        }
      }
    }
  };
  MathJax.Hub.Register.PreProcessor(["PreProcess", MathJax.Extension.myImg2jax]);
  </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
      <!--
##### SOURCE BEGIN #####
%% Camera Calibration
%
% This example demonstrates camera calibration in OpenCV. It shows usage of
% the following functions:
%
% * |cv.findChessboardCorners|, |cv.findCirclesGrid|
% * |cv.cornerSubPix|
% * |cv.drawChessboardCorners|
% * |cv.initCameraMatrix2D|
% * |cv.calibrateCamera|
% * |cv.projectPoints|
% * |cv.getOptimalNewCameraMatrix|
% * |cv.initUndistortRectifyMap|, |cv.remap|
% * |cv.undistort|
% * |cv.Rodrigues|
%
% You can find more test images at these locations:
%
% * <https://github.com/opencv/opencv_extra/tree/3.2.0/learning_opencv_v2/calibration>
% * <https://github.com/opencv/opencv_extra/tree/3.2.0/learning_opencv_v2/stereoData>
% * <https://github.com/opencv/opencv_extra/tree/3.2.0/testdata/cv/cameracalibration>
%
% Cameras have been around for a long-long time. However, with the
% introduction of the cheap pinhole cameras in the late 20th century, they
% became a common occurrence in our everyday life. Unfortunately, this
% cheapness comes with its price: significant distortion. Luckily, these are
% constants and with a calibration and some remapping we can correct this.
% Furthermore, with calibration you may also determine the relation between
% the camera's natural units (pixels) and the real world units (for example
% millimeters).
%
% In the sample, we will learn:
%
% * about distortions in camera, intrinsic and extrinsic parameters of camera
% * how to find these parameters, undistort images, etc.
%
% Sources:
%
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/calibration.cpp>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/python/calibrate.py>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp>
% * <https://docs.opencv.org/3.2.0/d4/d94/tutorial_camera_calibration.html>
% * <https://docs.opencv.org/3.2.0/dc/dbb/tutorial_py_calibration.html>
%

%% Theory
%
% Two major distortions OpenCV takes into account are radial distortion and
% tangential distortion. For the radial factor one uses the following formula:
%
% $$\begin{array}{l}
% x_{distorted} = x( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6) \cr
% y_{distorted} = y( 1 + k_1 r^2 + k_2 r^4 + k_3 r^6)
% \end{array}$$
%
% So for an undistorted pixel point at $(x,y)$ coordinates, its position on
% the distorted image will be $(x_{distorted}, y_{distorted})$. The presence
% of the radial distortion manifests in form of the "barrel" or "fish-eye"
% effect.
%
% Due to radial distortion, straight lines will appear curved. Its effect is
% more as we move away from the center of image. For example, one image is
% shown below, where two edges of a chess board are marked with red lines. But
% you can see that border is not a straight line and doesn't match with the
% red line. All the expected straight lines are bulged out. See
% <https://en.wikipedia.org/wiki/Distortion_%28optics%29 Distortion> for more
% details.
%
% <<https://docs.opencv.org/3.2.0/calib_radial.jpg>>
%
% Tangential distortion occurs because the image taking lenses are not
% perfectly parallel to the imaging plane. So some areas in image may look
% nearer than expected. It can be represented via the formulas:
%
% $$\begin{array}{l}
% x_{distorted} = x + [ 2p_1xy + p_2(r^2+2x^2)] \cr
% y_{distorted} = y + [ p_1(r^2+ 2y^2)+ 2p_2xy]
% \end{array}$$
%
% So we have five distortion parameters which in OpenCV are presented as one
% row matrix with 5 columns:
%
% $$distortion\_coefficients = (k_1, k_2, p_1, p_2, k_3)$$
%
% In addition to this, we need to find a few more information, like intrinsic
% and extrinsic parameters of a camera. Intrinsic parameters are specific to a
% camera. Extrinsic parameters corresponds to rotation and translation vectors
% which translates a coordinates of a 3D point to a coordinate system.
%
% Now for the unit conversion we use the following formula:
%
% $$\left[ {\matrix{ x \cr y \cr w }} \right] =
%   \left[ {\matrix{ f_x & 0 & c_x \cr 0 & f_y & c_y \cr 0 & 0 & 1 }} \right]
%   \left[ {\matrix{ X \cr Y \cr Z }} \right]$$
%
% Here the presence of $w$ is explained by the use of homography coordinate
% system (and $w=Z$). The unknown parameters are $f_x$ and $f_y$ (camera focal
% lengths) and $(c_x, c_y)$ which are the optical centers expressed in pixels
% coordinates. If for both axes a common focal length is used with a given $a$
% aspect ratio (usually 1), then $f_y=f_x*a$ and in the upper formula we will
% have a single focal length $f$. The matrix containing these four parameters
% is referred to as the _camera matrix_. While the distortion coefficients are
% the same regardless of the camera resolutions used, these should be scaled
% along with the current resolution from the calibrated resolution.
%
% The process of determining these two matrices is the *calibration*.
% Calculation of these parameters is done through basic geometrical equations.
% The equations used depend on the chosen calibrating objects with well
% defined pattern. Currently OpenCV supports three types of objects for
% calibration:
%
% * Classical black-white chessboard
% * Symmetrical circle pattern
% * Asymmetrical circle pattern
%
% <<https://docs.opencv.org/3.2.0/asymetricalPattern.jpg>>
%
% Basically, you need to take snapshots of these patterns with your camera and
% let OpenCV find them. Each found pattern results in a new equation (we know
% its coordinates in real world space and we know its coordinates found in
% image). To solve the equation you need at least a predetermined number of
% pattern snapshots to form a well-posed equation system. This number is
% higher for the chessboard pattern and less for the circle ones. For example,
% in theory the chessboard pattern requires at least two snapshots. However,
% in practice we have a good amount of noise present in our input images, so
% for good results you will probably need at least 10 good snapshots of the
% input pattern in different positions.
%
% We do the calibration with the help of the |cv.calibrateCamera| function. It
% has the following arguments:
%
% * The object points. This is a cell array of Nx3 points that for each input
%   image describes how should the pattern look. If we have a planar pattern
%   (like a chessboard) then we can simply set all Z coordinates to zero. This
%   is a collection of the points where these important points are present.
%   Because, we use a single pattern for all the input images we can calculate
%   this just once and repeat it for all the other input views. We calculate
%   the corner points with the |calcBoardCorners| function.
% * The image points. This is a cell arrray of Nx2 points which for each input
%   image contains coordinates of the important points (corners for chessboard
%   and centers of the circles for the circle pattern). We have already
%   collected this from |cv.findChessboardCorners| or |cv.findCirclesGrid|
%   function. We just need to pass it on.
% * The size of the image.
% * The camera matrix. If we used the fixed aspect ratio option we need to set
%   $f_x$.
% * The distortion coefficient matrix, initialized with zeros.
% * The final argument is the flag. You need to specify here options like fix
%   the aspect ratio for the focal length, assume zero tangential distortion
%   or to fix the principal point.
% * For all the views, the function will calculate rotation and translation
%   arrays which transform the object points (given in the model coordinate
%   space) to the image points (given in the world coordinate space). The
%   output cell array of matrices containing in the i-th position the rotation
%   and translation vector for the i-th object point to the i-th image point.
% * The function returns the average re-projection error. This number gives a
%   good estimation of precision of the found parameters. This should be as
%   close to zero as possible. Given the intrinsic, distortion, rotation and
%   translation matrices we may calculate the error for one view by using the
%   |cv.projectPoints| to first transform the object point to image point.
%   Then we calculate the absolute norm between what we got with our
%   transformation and the corner/circle finding algorithm. To find the
%   average error we calculate the arithmetical mean of the errors calculated
%   for all the calibration images.
%
% You may watch a video of the camera calibration on
% <https://www.youtube.com/watch?v=ViPN810E0SU YouTube>.
%
% Once calibration is done, we can undistort images and correct them for the
% lens distortion. For example, you can see in the result below that all the
% edges become straight.
%
% <<https://docs.opencv.org/3.2.0/fileListImage.jpg>>
%
% <<https://docs.opencv.org/3.2.0/fileListImageUnDist.jpg>>
%

%% Code

function varargout = calibration_demo()
    %%
    % Options and calibration flags
    % (keep in mind that the number of images needed grows dramatically with
    % the number of parameters we are solving for, i.e distortion coeffs)
    opts = struct();
    opts.aspectRatio = 1;                 % aspect ratio (ar = fx/fy)
    opts.flags.UseIntrinsicGuess = false; % how to initize camera matrix
    opts.flags.FixAspectRatio = true;     % fix aspect ratio (ar = fx/fy)
    opts.flags.FixFocalLength = false;    % fix fx and fy
    opts.flags.FixPrincipalPoint = false; % fix principal point at the center
    opts.flags.ZeroTangentDist = false;   % assume zero tangential distortion
    opts.flags.RationalModel = false;     % enable (k4,k5,k6)
    opts.flags.ThinPrismModel = false;    % enable (s1,s2,s3,s4)
    opts.flags.TiltedModel = false;       % enable (taux,tauy)
    %opts.flags.FixK3 = true;
    %opts.flags.FixK4 = true;
    %opts.flags.FixK5 = true;

    %%
    % list of board images
    opts.pattern = 'chessboard'; % type of pattern grid: chessboard, acircles, circles
    opts.boardSize = [9 6];      % number of inner corners per board dimensions
    opts.squareSize = 30.0;      % board square size in millimeters
    files = cv.glob(fullfile(mexopencv.root(), 'test', 'left*.jpg'));
    finfo = imfinfo(files{1});
    opts.imageSize = [finfo.Width, finfo.Height];
    display(opts);
    display(files(:));

    %%
    % load images
    N = numel(files);
    imgs = cell(N,1);
    for i=1:N
        imgs{i} = cv.imread(files{i}, 'Color',true);
    end

    %%
    % detect image points, and filter out views where detection failed
    [imagePoints, found] = detectImageCorners(imgs, opts);
    if ~all(found)
        files = files(found);
        imgs = imgs(found);
        imagePoints = imagePoints(found);
        found = found(found);
        N = nnz(found);
        assert(N >= 2, 'Not enough views');
    end

    %%
    % show detected corners
    for i=1:N
        img = cv.drawChessboardCorners(imgs{i}, opts.boardSize, ...
            imagePoints{i}, 'PatternWasFound',found(i));
        imshow(img), title(sprintf('Detection, %d/%d', i, N))
        pause(1)
    end

    %%
    % create object points (we assume a fully visible calibration pattern,
    % the same shown in each view)
    objectPoints = calcBoardCorners(opts);
    objectPoints = repmat({objectPoints}, N, 1);

    %%
    % run calibration
    [calib, ok] = runCalibration(objectPoints, imagePoints, opts);
    if ~ok
        disp('calibration failed');
        return;
    end
    fprintf('avg reprojection error = %f\n', calib.rms)

    %
    % save intrinsic/extrinsic parameters
    fname = fullfile(tempdir(), sprintf('calibration_%s.yml', opts.pattern));
    saveCameraParams(fname, calib, opts);  % ..., true, imagePoints
    fprintf('Saved to: %s\n', fname);

    %%
    % display parameter estimation errors
    displayErrorEstimates(calib);

    %%
    % reprojection errors
    [calib.rms, calib.rmsPerView, reprojErrs] = computeReprojectionErrors(...
        objectPoints, imagePoints, calib);
    figure, visualizeReprojErrors(calib.rms, calib.rmsPerView, reprojErrs);

    %%
    % visualize board locations (poses in camera centric view)
    figure, visualizeExtrinsics(calib, opts);

    %%
    % visualize distortion model
    figure, visualizeDistortion(calib, opts);

    %%
    % correct images for lens distortion, and show them
    [undistortImage, roi] = buildUndistortFunction(calib, opts);
    figure
    for i=1:N
        img = undistortImage(imgs{i});
        if false
            img = cv.Rect.crop(img, roi);
        end
        imshow(img), title(sprintf('Undistortion, %d/%d', i, N))
        pause(1)
    end

    %%
    % output arguments
    if nargout > 0, varargout{1} = calib; end
    if nargout > 1, varargout{2} = opts; end
end

%%

function [imagePoints, founds] = detectImageCorners(imgs, opts)
    if true
        blobOpts = {};
    else
        % customize blob detector used in findCirclesGrid
        blobOpts = {'BlobDetector',{'SimpleBlobDetector', 'MaxArea',1e4}};
    end

    N = numel(imgs);
    imagePoints = cell(N,1);
    founds = false(N,1);
    for i=1:N
        switch opts.pattern
            case 'chessboard'
                [pts,found] = cv.findChessboardCorners(...
                    imgs{i}, opts.boardSize, 'FastCheck',true);
                if found
                    % improve the found corners coordinate accuracy
                    gray = cv.cvtColor(imgs{i}, 'RGB2GRAY');
                    pts = cv.cornerSubPix(gray, pts, 'WinSize',[11 11], ...
                        'Criteria',struct('type','Count+EPS', ...
                            'maxCount',30, 'epsilon',0.1));
                end
            case 'circles'
                [pts,found] = cv.findCirclesGrid(imgs{i}, opts.boardSize, ...
                    'SymmetricGrid',true, blobOpts{:});
            case 'acircles'
                [pts,found] = cv.findCirclesGrid(imgs{i}, opts.boardSize, ...
                    'SymmetricGrid',false, blobOpts{:});
            otherwise
                pts = {};
                found = false;
        end
        imagePoints{i} = cat(1, pts{:});
        founds(i) = found;
    end
end

function corners = calcBoardCorners(opts)
    % planar calibration pattern (in model coordinate system)
    [X,Y] = ndgrid(1:opts.boardSize(1), 1:opts.boardSize(2));
    switch opts.pattern
        case {'chessboard', 'circles'}
            corners = [X(:), Y(:)];
        case 'acircles'
            corners = [2*X(:) + mod(Y(:),2), Y(:)];
        otherwise
            corners = zeros(0,2);
    end
    corners = (corners - 1) * opts.squareSize;
    corners(:,3) = 0;  % Z = 0
end

function [calib, ok] = runCalibration(objectPoints, imagePoints, opts)
    % calibration flags
    calib = struct();
    if opts.flags.UseIntrinsicGuess
        if opts.flags.FixAspectRatio
            params = {'AspectRatio',opts.aspectRatio};
        else
            params = {'AspectRatio',0};
        end
        calib.M = cv.initCameraMatrix2D(objectPoints, imagePoints, ...
            opts.imageSize, params{:});
    else
        calib.M = eye(3);
        if opts.flags.FixAspectRatio
            calib.M(1,1) = opts.aspectRatio;
        end
    end
    if opts.flags.TiltedModel
        calib.D = zeros(1,14);
    elseif opts.flags.ThinPrismModel
        calib.D = zeros(1,12);
    elseif opts.flags.RationalModel
        calib.D = zeros(1,8);
    else
        calib.D = zeros(1,5);
    end
    params = st2kv(opts.flags);
    params = [params, 'CameraMatrix',calib.M, 'DistCoeffs',calib.D, ...
        'UseIntrinsicGuess',opts.flags.UseIntrinsicGuess];

    % calibration: find intrinsic and extrinsic camera parameters
    if false
        % we will later manually compute reprojection errors
        [calib.M, calib.D, calib.rms, calib.R, calib.T] = cv.calibrateCamera(...
            objectPoints, imagePoints, opts.imageSize, params{:});
        % placeholder for standard deviations of estimates
        calib.sdInt = nan(1, 18);
        calib.sdExt = nan(1, 6*numel(calib.R));
    else
        % returns reprojection errors (same as computeReprojectionErrors)
        [calib.M, calib.D, calib.rms, calib.R, calib.T, ...
            calib.sdInt, calib.sdExt, calib.rmsPerView] = cv.calibrateCamera(...
            objectPoints, imagePoints, opts.imageSize, params{:});
    end
    ok = all(isfinite([calib.M(:); calib.D(:)]));
end

function saveCameraParams(filename, calib, opts, writeExtrinsics, imagePoints)
    if nargin < 4, writeExtrinsics = false; end

    fs = struct();
    fs.calibration_time = datestr(now());
    if writeExtrinsics
        fs.nframes = int32(numel(calib.R));
    end
    fs.image_width = int32(opts.imageSize(1));
    fs.image_height = int32(opts.imageSize(2));
    fs.board_width = int32(opts.boardSize(1));
    fs.board_height = int32(opts.boardSize(2));
    fs.square_size = opts.squareSize;
    if opts.flags.FixAspectRatio
        fs.aspectRatio = opts.aspectRatio;
    end
    fs.flags = opts.flags;
    fs.camera_matrix = calib.M;
    fs.distortion_coefficients = calib.D;
    if writeExtrinsics
        % set of 6-tuples (rotation vector + translation vector) for each view
        RT = cellfun(@(r,t) [r(:); t(:)]', calib.R, calib.T, ...
            'UniformOutput',false);
        RT = cat(1, RT{:});
        fs.extrinsic_parameters = RT;
    end
    if nargin > 4
        fs.image_points = imagePoints;
    end
    cv.FileStorage(filename, fs);
end

function kv = st2kv(st)
    % convert struct to cell-array of key/value params
    k = fieldnames(st);
    v = struct2cell(st);
    kv = [k(:) v(:)]';
    kv = kv(:)';
end

function displayErrorEstimates(calib)
    D = calib.D;
    if numel(D) < 14, D(14) = 0; end
    sdInt = calib.sdInt;
    if numel(sdInt) < 18, sdInt(18) = NaN; end
    sdExt = reshape(calib.sdExt, 3, 2, []);  % 1/2/3, R/T, N

    fmt = ' %9.4f +/- %-9.4f ';
    fprintf('\n');
    fprintf('\t\t\tStandard Errors of Estimated Camera Parameters\n');
    fprintf('\t\t\tREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH\n');
    fprintf('\n');
    fprintf('Intrinsics\n');
    fprintf('REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH\n');
    fprintf('Focal length (pixels):    [');
    fprintf(fmt, calib.M(1,1), sdInt(1), calib.M(2,2), sdInt(2));
    fprintf(']\n');
    fprintf('Principal Point (pixels): [');
    fprintf(fmt, calib.M(1,3), sdInt(3), calib.M(2,3), sdInt(4));
    fprintf(']\n');
    fprintf('Radial distortion:        [');
    fprintf(fmt, D(1), sdInt(5), D(2), sdInt(6), D(5), sdInt(9));
    fprintf(']\n');
    fprintf('Tangential distortion:    [');
    fprintf(fmt, D(3), sdInt(7), D(4), sdInt(8));
    fprintf(']\n');
    fprintf('Rational distortion:      [');
    fprintf(fmt, D(6), sdInt(10), D(7), sdInt(11), D(8), sdInt(12));
    fprintf(']\n');
    fprintf('Thin Prism distortion:    [');
    fprintf(fmt, D(9), sdInt(13), D(10), sdInt(14), D(11), sdInt(15), ...
        D(12), sdInt(16));
    fprintf(']\n');
    fprintf('Tilt distortion:          [');
    fprintf(fmt, D(13), sdInt(17), D(14), sdInt(18));
    fprintf(']\n');
    fprintf('\n');
    fprintf('Extrinsics\n');
    fprintf('REPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASHREPLACE_WITH_DASH_DASH\n');
    fprintf('Rotation vectors:\n');
    for i=1:numel(calib.R)
        fprintf('\t[');
        fprintf(fmt, calib.R{i}(1), sdExt(1,1,i), ...
            calib.R{i}(2), sdExt(2,1,i), calib.R{i}(3), sdExt(3,1,i));
        fprintf(']\n');
    end
    fprintf('Translation vectors (world units):\n');
    for i=1:numel(calib.T)
        fprintf('\t[');
        fprintf(fmt, calib.T{i}(1), sdExt(1,2,i), ...
            calib.T{i}(2), sdExt(2,2,i), calib.T{i}(3), sdExt(3,2,i));
        fprintf(']\n');
    end
end

function [rmseAvg, rmsePerView, err] = computeReprojectionErrors(objectPoints, imagePoints, calib)
    % 3D points projection using camera calibration params
    N = numel(objectPoints);
    imagePoints2 = cell(N,1);
    for i=1:N
        imagePoints2{i} = cv.projectPoints(objectPoints{i}, ...
            calib.R{i}, calib.T{i}, calib.M, 'DistCoeffs',calib.D);
    end

    % compute difference (reprojection errors)
    err = cellfun(@minus, imagePoints, imagePoints2, 'UniformOutput',false);

    % total RMSE from all points, and RMSE per view
    % (same as calib.rms and calib.rmsPerView computed by calibrateCamera)
    if true
        fcnRMSE = @(e) sqrt(mean(sum(e.^2, 2)));
        rmseAvg = fcnRMSE(cat(1, err{:}));
        rmsePerView = cellfun(fcnRMSE, err);
    else
        e = cellfun(@(e) norm(e(:)), err).^2;
        n = cellfun(@(e) size(e,1), err);
        rmseAvg = sqrt(sum(e) / sum(n));
        rmsePerView = sqrt(e ./ n);
    end
end

function [fcn, roi] = buildUndistortFunction(calib, opts)
    % when the scaling parameter Alpha=0, it returns undistorted image
    % with minimum unwanted pixels. So it may even remove some pixels at
    % image corners.
    % When Alpha=1, all pixels are retained with some extra black images.
    % It also returns an image ROI which can be used to crop the result.
    [newM, roi] = cv.getOptimalNewCameraMatrix(calib.M, calib.D, ...
        opts.imageSize, 'Alpha',1);
    if true
        [map1, map2] = cv.initUndistortRectifyMap(calib.M, calib.D, ...
            opts.imageSize, 'NewCameraMatrix',newM);
        fcn = @(img) cv.remap(img, map1, map2, 'Interpolation','Linear');
    elseif true
        fcn = @(img) cv.undistort(img, calib.M, calib.D, 'NewCameraMatrix',newM);
    else
        fcn = @(img) cv.undistort(img, calib.M, calib.D, 'NewCameraMatrix',calib.M);
        roi = [0 0 opts.imageSize];
    end
end

function visualizeReprojErrors(totalAvgErr, perViewErrors, reprojErrs)
    N = numel(reprojErrs);

    % visualize reprojection errors
    re = cat(2, reprojErrs{:});
    plot(re(:,1:2:end), re(:,2:2:end), '+')
    legend(num2str((1:N)', 'image %d')), grid on
    xlabel('X'), ylabel('Y')
    title(sprintf('Reprojection Error (in pixel), RMSE = %f', totalAvgErr))

    % visualize RMSE
    figure, bar(1:N, perViewErrors)
    hLin = line(xlim(), [1 1]*totalAvgErr, 'LineStyle','REPLACE_WITH_DASH_DASH', 'Color','r');
    legend(hLin, 'Overall Mean error')
    xlabel('Images'), ylabel('Mean Error (in pixels)')
    title('Mean Reprojection Error per Image')
end

function visualizeExtrinsics(calib, opts)
    N = numel(calib.R);
    clr = lines(N);
    w = (opts.boardSize(1) - 1) * opts.squareSize;
    h = (opts.boardSize(2) - 1) * opts.squareSize;
    s = max(w,h);  % scale in terms of width/height

    % board corner points (in model coordinate system, i.e objectPoints)
    XYZ = [0 0 0; w 0 0; w h 0; 0 h 0; 0 0 0]';

    % axis vector points at origin of world coordinates (camera frame)
    ax = [0 0 0; 1 0 0; 0 0 0; 0 1 0; 0 0 0; 0 0 1]' * (0.6*s);

    % plot axis vectors at the origin
    plot3(ax(1,:), ax(2,:), ax(3,:), 'k', 'LineWidth',2)
    hold on
    text(0.8*s, 0, 0, 'X_c')
    text(0, 0.8*s, 0, 'Y_c')
    text(0, 0, 0.8*s, 'Z_c')
    % for each board
    for i=1:N
        % transformation from model coordinates to real world coordinates
        R = cv.Rodrigues(calib.R{i});
        T = calib.T{i};
        xyz = bsxfun(@plus, R * XYZ, T);
        % plot board and label it
        patch(xyz(1,:), xyz(2,:), xyz(3,:), clr(i,:), 'LineWidth',1, ...
            'FaceColor',clr(i,:), 'EdgeColor',clr(i,:), 'FaceAlpha',0.2);
        text(T(1), T(2), T(3), num2str(i), 'FontSize',12, 'Color',clr(i,:));
    end
    hold off, axis equal, grid on, box on
    title('Extrinsic Parameters Visualization')
    xlabel('X'), ylabel('Y'), zlabel('Z')  % world units (mm)
    if ~mexopencv.isOctave()
        cameratoolbar
        cameratoolbar('SetCoordSys','y')
    else
        %HACK: CAM* functions not implemented in Octave
        rotate3d on
    end
end

function visualizeDistortion(calib, opts)
    % cameraMatrix = [fx 0 cx; 0 fy cy; 0 0 1]
    %
    % * focal lengths   : fx, fy
    % * aspect ratio    : a = fy/fx
    % * principal point : cx, cy
    %
    M = calib.M;

    % distCoeffs = [k1,k2,p1,p2,k3,k4,k5,k6,s1,s2,s3,s4,taux,tauy]
    %
    % * radial distortion     : k1, k2, k3
    % * tangential distortion : p1, p2
    % * rational distortion   : k4, k5, k6
    % * thin prism distortion : s1, s2, s3, s4
    % * tilted distortion     : taux, tauy (ignored here)
    %
    D = calib.D;
    if numel(D) < 14, D(14) = 0; end

    % https://docs.opencv.org/3.2.0/d9/d0c/group__calib3d.html#details
    nstep = 20;
    [u,v] = meshgrid(linspace(0,opts.imageSize(1)-1,nstep), ...
        linspace(0,opts.imageSize(2)-1,nstep));
    xyz = M \ [u(:) v(:) ones(numel(u),1)].';
    xp = xyz(1,:) ./ xyz(3,:);
    yp = xyz(2,:) ./ xyz(3,:);
    r2 = xp.^2 + yp.^2;
    r4 = r2.^2;
    r6 = r2.^3;
    coef = (1 + D(1)*r2 + D(2)*r4 + D(5)*r6) ./ (1 + D(6)*r2 + D(7)*r4 + D(8)*r6);
    xpp = xp.*coef + 2*D(3)*(xp.*yp) + D(4)*(r2 + 2*xp.^2) + D(9)*r2 + D(10)*r4;
    ypp = yp.*coef + D(3)*(r2 + 2*yp.^2) + 2*D(4)*(xp.*yp) + D(11)*r2 + D(12)*r4;
    u2 = M(1,1)*xpp + M(1,3);
    v2 = M(2,2)*ypp + M(2,3);
    du = u2(:) - u(:);
    dv = v2(:) - v(:);
    dr = reshape(hypot(du,dv), size(u));

    % plot
    quiver(u(:)+1, v(:)+1, du, dv)
    hold on
    plot(opts.imageSize(1)/2, opts.imageSize(2)/2, 'x', M(1,3), M(2,3), 'o')
    [C, hC] = contour(u(1,:)+1, v(:,1)+1, dr, 'k');
    clabel(C, hC)
    hold off, axis ij equal tight
    title('Distortion Model'), xlabel('u'), ylabel('v')
end

##### SOURCE END #####
--></body>
</html>