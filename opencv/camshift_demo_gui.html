<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>CAMShift</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="camshift_demo_gui.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">CAMShift</h1>
         <!--introduction-->
         <p>In this demo, we learn about Meanshift and Camshift algorithms to find and track objects in videos.</p>
         <p>This is a demo that shows mean-shift based tracking. You select a color objects such as your face and it tracks it. It reads
            from video camera by default.
         </p>
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/camshiftdemo.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/camshiftdemo.cpp</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/tapi/camshift.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/tapi/camshift.cpp</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/python/camshift.py">https://github.com/opencv/opencv/blob/3.2.0/samples/python/camshift.py</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/db/df8/tutorial_py_meanshift.html">https://docs.opencv.org/3.2.0/db/df8/tutorial_py_meanshift.html</a></li>
            </ul>
         </div>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Meanshift</a></li>
               <li><a href="#3">Camshift</a></li>
               <li><a href="#4">Code</a></li>
               <li><a href="#6">Callback functions</a></li>
               <li><a href="#8">Helper functions</a></li>
            </ul>
         </div>
         <h2 id="2">Meanshift</h2>
         <p>The intuition behind the meanshift is simple. Consider you have a set of points. (It can be a pixel distribution like histogram
            backprojection). You are given a small window (may be a circle) and you have to move that window to the area of maximum pixel
            density (or maximum number of points). It is illustrated in the simple image given below:
         </p>
         <p><img src="https://docs.opencv.org/3.2.0/meanshift_basics.jpg"></p>
         <p>The initial window is shown in blue circle with the name "C1". Its original center is marked in blue rectangle, named "C1_o".
            But if you find the centroid of the points inside that window, you will get the point "C1_r" (marked in small blue circle)
            which is the real centroid of window. Surely they don't match. So move your window such that circle of the new window matches
            with previous centroid. Again find the new centroid. Most probably, it won't match. So move it again, and continue the iterations
            such that center of window and its centroid falls on the same location (or with a small desired error). So finally what you
            obtain is a window with maximum pixel distribution. It is marked with green circle, named "C2". As you can see in image, it
            has maximum number of points. The whole process is demonstrated on a static image below:
         </p>
         <p><img src="https://docs.opencv.org/3.2.0/meanshift_face.gif"></p>
         <p>So we normally pass the histogram backprojected image and initial target location. When the object moves, obviously the movement
            is reflected in histogram backprojected image. As a result, meanshift algorithm moves our window to the new location with
            maximum density.
         </p>
         <p>To use meanshift in OpenCV, first we need to setup the target, find its histogram so that we can backproject the target on
            each frame for calculation of meanshift. We also need to provide initial location of window. For histogram, only Hue is considered
            here. Also, to avoid false values due to low light, low light values are discarded using <tt>cv.inRange</tt> function.
         </p>
         <h2 id="3">Camshift</h2>
         <p>There is a problem with the approach described above. The window always has the same size even when the tracked object moves
            farther away or very close to the camera. That is not good. We need to adapt the window size with size and rotation of the
            target. Once again, the solution came from "OpenCV Labs" and it is called <b>CAMshift (Continuously Adaptive Meanshift)</b> published by Gary Bradsky in his paper "Computer Vision Face Tracking for Use in a Perceptual User Interface" in 1988.
         </p>
         <p>It applies meanshift first. Once meanshift converges, it updates the size of the window as, <img src="camshift_demo_gui_eq11891530601058349568.png" alt="$s = 2 \times \sqrt{\frac{M_{00}}{256}}$" class="equation" width="88" height="27">. It also calculates the orientation of best fitting ellipse to it. Again it applies the meanshift with new scaled search
            window and previous window location. The process is continued until required accuracy is met.
         </p>
         <p><img src="https://docs.opencv.org/3.2.0/camshift_face.gif"></p>
         <p>In OpenCV, camshift is almost same as meanshift, but it returns a rotated rectangle (that is our result) and box parameters
            (used to be passed as search window in next iteration).
         </p>
         <p>For additional resources, see:</p>
         <div>
            <ul>
               <li>French Wikipedia page on <a href="https://fr.wikipedia.org/wiki/Camshift">Camshift</a>.   (The two animations are taken from there)
               </li>
               <li>Bradski, G.R., "Real time face and object tracking as a component of a   perceptual user interface," Applications of Computer
                  Vision, 1998.   WACV '98. Proceedings., Fourth IEEE Workshop on , pp.214,219, Oct 1998
               </li>
            </ul>
         </div>
         <h2 id="4">Code</h2><pre class="codeinput"><span class="keyword">function</span> varargout = camshift_demo_gui(varargin)</pre><pre class="codeinput">    <span class="comment">% setup video capture</span>
    cap = createVideoCapture([], <span class="string">'cube'</span>);
    assert(cap.isOpened(), <span class="string">'Could not initialize capturing'</span>);
    frame = cap.read();
    assert(~isempty(frame) &amp;&amp; size(frame,3)==3 &amp;&amp; isa(frame,<span class="string">'uint8'</span>));

    <span class="comment">% program state</span>
    app = appState();
    app.sz = size(frame);
    app.hsz = [200 app.sz(2) 3];

    <span class="comment">% create the UI, and hook event handlers</span>
    h = buildGUI(frame, app);
    opts = {<span class="string">'Interruptible'</span>,<span class="string">'off'</span>, <span class="string">'BusyAction'</span>,<span class="string">'cancel'</span>};
    set(h.slid, <span class="string">'Callback'</span>,@onChange, opts{:});
    set(h.fig, <span class="string">'WindowKeyPressFcn'</span>,@onType, <span class="keyword">...</span>
        <span class="string">'WindowButtonDownFcn'</span>,@onMouseDown, opts{:});
    onType([], struct(<span class="string">'Key'</span>,<span class="string">'e'</span>));

    <span class="keyword">if</span> nargout &gt; 0, varargout{1} = h; <span class="keyword">end</span>
    <span class="keyword">if</span> nargout &gt; 1, varargout{2} = app; <span class="keyword">end</span>

    <span class="comment">% main loop</span>
    <span class="keyword">while</span> ishghandle(h.fig)
        <span class="comment">% get next frame</span>
        frame = cap.read();
        <span class="keyword">if</span> isempty(frame), <span class="keyword">break</span>; <span class="keyword">end</span>
        out = frame;

        <span class="comment">% extract hue channel, and range-threshold in HSV colorspace</span>
        frameHSV = cv.cvtColor(frame, <span class="string">'RGB2HSV'</span>);
        hue = frameHSV(:,:,1);
        mask = cv.inRange(frameHSV, <span class="keyword">...</span>
            [0 app.smin min(app.vmin,app.vmax)], <span class="keyword">...</span>
            [180 255 max(app.vmin,app.vmax)]);
        mask = uint8(mask * 255);  <span class="comment">% logical -&gt; uint8 (for bitwise ops)</span>

        <span class="comment">% process mouse selection (during onMouseMove and onMouseUp)</span>
        <span class="keyword">if</span> ~isempty(app.rct) &amp;&amp; cv.Rect.area(app.rct) &gt; 0
            <span class="comment">% compute and display hue histogram of selection</span>
            [app.histo, histimg] = computeHistogram(hue, mask, app.rct, app);
            set(h.img(1), <span class="string">'CData'</span>,histimg);

            <span class="comment">% highlight selection region</span>
            out = drawSelection(out, app.rct);
        <span class="keyword">end</span>

        <span class="comment">% mask-out output using HSV thresholding result</span>
        <span class="keyword">if</span> app.threshView || ~isempty(app.rct)
            out = cv.bitwise_and(out, uint8(255), <span class="string">'Mask'</span>,mask);
        <span class="keyword">end</span>

        <span class="comment">% check if the rectangle selection was fully made</span>
        <span class="keyword">if</span> ~isempty(app.win)
            <span class="comment">% clear mouse selection once onMouseUp is triggered</span>
            app.rct = [];

            <span class="comment">% perform CAMShift to track object using its histogram</span>
            backproj = cv.calcBackProject(hue, app.histo, {[0 180]}, <span class="string">'Uniform'</span>,true);
            backproj = cv.bitwise_and(backproj, mask);
            [rbox, app.win] = cv.CamShift(backproj, app.win, <span class="string">'Criteria'</span>,app.crit);

            <span class="comment">% expand search window if it gets too small</span>
            <span class="keyword">if</span> cv.Rect.area(app.win) &lt;= 1
                r = (min(app.sz(1:2)) + 5) / 6;
                app.win = cv.Rect.from2points(app.win(1:2) - r, app.win(1:2) + r);
                app.win = cv.Rect.intersect(app.win, [0 0 app.sz(2) app.sz(1)]);
            <span class="keyword">end</span>

            <span class="comment">% switch to backproject probability instead of frame as output</span>
            <span class="keyword">if</span> app.backprojView
                out = cv.cvtColor(backproj, <span class="string">'GRAY2RGB'</span>);
            <span class="keyword">end</span>

            <span class="comment">% draw location of tracked object</span>
            out = cv.ellipse(out, rbox, <span class="keyword">...</span>
                <span class="string">'Color'</span>,[0 0 255], <span class="string">'Thickness'</span>,3, <span class="string">'LineType'</span>,<span class="string">'AA'</span>);
        <span class="keyword">end</span>

        <span class="comment">% show output</span>
        set(h.img(2), <span class="string">'CData'</span>,out);
        drawnow <span class="string">limitrate</span>;
    <span class="keyword">end</span>
    cap.release();  <span class="comment">% release video source</span></pre><img src="camshift_demo_gui_01.png"><h2 id="6">Callback functions</h2>
         <p>User draws box around object to track. This triggers CAMShift to start tracking</p><pre class="codeinput">    <span class="keyword">function</span> onMouseDown(~,~)
        <span class="comment">%ONMOUSEDOWN  Event handler for mouse down on figure</span>

        <span class="comment">% start selection</span>
        onClear();   <span class="comment">% clear any previous trackig</span>
        app.pt0 = getCurrentPoint(h.ax(2));
        app.rct = [app.pt0 0 0];

        <span class="comment">% attach event handlers, and change mouse pointer</span>
        set(h.fig, <span class="string">'Pointer'</span>,<span class="string">'cross'</span>, <span class="keyword">...</span>
            <span class="string">'WindowButtonMotionFcn'</span>,@onMouseMove, <span class="keyword">...</span>
            <span class="string">'WindowButtonUpFcn'</span>,@onMouseUp);
    <span class="keyword">end</span>

    <span class="keyword">function</span> onMouseMove(~,~)
        <span class="comment">%ONMOUSEMOVE  Event handler for mouse move on figure</span>

        <span class="comment">% update selection rectangle</span>
        p = getCurrentPoint(h.ax(2));
        app.rct = cv.Rect.from2points(app.pt0, p);
        app.rct = cv.Rect.intersect(app.rct, [0 0 app.sz(2) app.sz(1)]);
    <span class="keyword">end</span>

    <span class="keyword">function</span> onMouseUp(~,~)
        <span class="comment">%ONMOUSEUP  Event handler for mouse up on figure</span>

        <span class="comment">% detach event handlers, and restore mouse pointer</span>
        set(h.fig, <span class="string">'Pointer'</span>,<span class="string">'arrow'</span>, <span class="keyword">...</span>
            <span class="string">'WindowButtonMotionFcn'</span>,<span class="string">''</span>, <span class="keyword">...</span>
            <span class="string">'WindowButtonUpFcn'</span>,<span class="string">''</span>);

        <span class="comment">% finish selection</span>
        app.pt0 = [];
        <span class="keyword">if</span> cv.Rect.area(app.rct) &gt; 0
            <span class="comment">% tracking is now activate in main loop</span>
            app.win = app.rct;
        <span class="keyword">else</span>
            <span class="comment">% ignore selection</span>
            app.rct = [];
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="keyword">function</span> onChange(~,~)
        <span class="comment">%ONCHANGE  Event handler for UI controls</span>

        <span class="comment">% retrieve current values from UI controls</span>
        app.vmin = round(get(h.slid(1), <span class="string">'Value'</span>));
        app.vmax = round(get(h.slid(2), <span class="string">'Value'</span>));
        app.smin = round(get(h.slid(3), <span class="string">'Value'</span>));
        set(h.txt(1), <span class="string">'String'</span>,sprintf(<span class="string">'Vmin: %3d'</span>,app.vmin));
        set(h.txt(2), <span class="string">'String'</span>,sprintf(<span class="string">'Vmax: %3d'</span>,app.vmax));
        set(h.txt(3), <span class="string">'String'</span>,sprintf(<span class="string">'Smin: %3d'</span>,app.smin));
        drawnow;
    <span class="keyword">end</span>

    <span class="keyword">function</span> onType(~,e)
        <span class="comment">%ONTYPE  Event handler for key press on figure</span>

        <span class="comment">% handle keys</span>
        <span class="keyword">switch</span> e.Key
            <span class="keyword">case</span> <span class="string">'h'</span>
                helpdlg({
                    <span class="string">'To initialize tracking, select the object with mouse.'</span>
                    <span class="string">'Hot keys:'</span>
                    <span class="string">'h - this help dialog'</span>
                    <span class="string">'q - quit the program'</span>
                    <span class="string">'f - initialize tracking by auto-detecting face'</span>
                    <span class="string">'c - clear the tracking'</span>
                    <span class="string">'b - toggle backprojection probability view'</span>
                    <span class="string">'t - toggle threshold mask view'</span>
                });

            <span class="keyword">case</span> {<span class="string">'q'</span>, <span class="string">'escape'</span>}
                close(h.fig);

            <span class="keyword">case</span> <span class="string">'f'</span>
                img = get(h.img(2), <span class="string">'CData'</span>);  <span class="comment">%TODO</span>
                rct = findFace(img);
                <span class="keyword">if</span> ~isempty(rct)
                    app.rct = rct;
                    app.win = rct;
                <span class="keyword">else</span>
                    disp(<span class="string">'No face detected'</span>)
                <span class="keyword">end</span>

            <span class="keyword">case</span> {<span class="string">'c'</span>, <span class="string">'add'</span>, <span class="string">'subtract'</span>}
                <span class="keyword">if</span> strcmp(e.Character, <span class="string">'+'</span>)
                    app.nbins = min(app.nbins + 1, 180);
                <span class="keyword">elseif</span> strcmp(e.Character, <span class="string">'-'</span>)
                    app.nbins = max(app.nbins - 1, 2);
                <span class="keyword">end</span>
                onClear();

            <span class="keyword">case</span> <span class="string">'b'</span>
                app.backprojView = ~app.backprojView;

            <span class="keyword">case</span> <span class="string">'t'</span>
                app.threshView = ~app.threshView;
        <span class="keyword">end</span>
    <span class="keyword">end</span>

    <span class="keyword">function</span> onClear()
        <span class="comment">%ONCLEAR  Clear tracking</span>

        <span class="comment">% clear tracked object</span>
        app.rct = [];
        app.win = [];
        app.histo = zeros([app.nbins 1], <span class="string">'single'</span>);

        <span class="comment">% redraw histogram</span>
        histimg = drawHistogram(app.histo, app.hsz);
        set(h.img(1), <span class="string">'CData'</span>,histimg);
    <span class="keyword">end</span></pre><pre class="codeinput"><span class="keyword">end</span></pre><h2 id="8">Helper functions</h2><pre class="codeinput"><span class="keyword">function</span> app = appState()
    <span class="comment">%APPSTATE  Returns initial program state</span>

    app = struct();
    app.pt0 = [];              <span class="comment">% mouse selection origin point</span>
    app.rct = [];              <span class="comment">% mouse selection rectangle</span>
    app.win = [];              <span class="comment">% camshift search window</span>
    app.crit = struct(<span class="string">'type'</span>,<span class="string">'Count+EPS'</span>, <span class="string">'maxCount'</span>,10, <span class="string">'epsilon'</span>,1);  <span class="comment">% camshift termination</span>
    app.smin = 60;             <span class="comment">% lower saturation threshold (HSV)</span>
    app.vmin = 32;             <span class="comment">% lower value threshold (HSV)</span>
    app.vmax = 255;            <span class="comment">% upper value threshold (HSV)</span>
    app.nbins = 16;            <span class="comment">% histogram size (number of bins)</span>
    app.histo = zeros([app.nbins 1], <span class="string">'single'</span>);  <span class="comment">% hue histogram of tracked object</span>
    app.backprojView = false;  <span class="comment">% whether to display frame or backproj</span>
    app.threshView = true;     <span class="comment">% whether to display thresholded frame</span>
<span class="keyword">end</span>

<span class="keyword">function</span> rct = findFace(img)
    <span class="comment">%FINDFACE  Detect biggest face in image</span>

    xmlfile = fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'haarcascade_frontalface_alt2.xml'</span>);
    classifier = cv.CascadeClassifier(xmlfile);
    gray = cv.cvtColor(img, <span class="string">'RGB2GRAY'</span>);
    gray = cv.equalizeHist(gray);
    boxes = classifier.detect(gray);
    <span class="keyword">if</span> ~isempty(boxes)
        <span class="comment">%TODO: we can further improve this by detecting nose within face,</span>
        <span class="comment">% as it provides more accurate measure of skin tone with less</span>
        <span class="comment">% background pixels</span>
        [~,idx] = max(cellfun(@(b) cv.Rect.area(b), boxes));
        rct = boxes{idx};
    <span class="keyword">else</span>
        rct = [];
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> [histo, histimg] = computeHistogram(hue, mask, rct, app)
    <span class="comment">%COMPUTEHISTOGRAM  Compute hue channel histogram</span>

    <span class="comment">% crop to selection rectangle</span>
    roi = cv.Rect.crop(hue, rct);
    maskroi = cv.Rect.crop(mask, rct);

    <span class="comment">% compute normalized hue histogram</span>
    histo = cv.calcHist(roi, {[0 180]}, <span class="string">'HistSize'</span>,app.nbins, <span class="keyword">...</span>
        <span class="string">'Uniform'</span>,true, <span class="string">'Mask'</span>,maskroi);
    histo = cv.normalize(histo, <span class="string">'Alpha'</span>,0, <span class="string">'Beta'</span>,255, <span class="string">'NormType'</span>,<span class="string">'MinMax'</span>);

    <span class="keyword">if</span> nargout &gt; 1
        <span class="comment">% draw histogram (bar chart)</span>
        histimg = drawHistogram(histo, app.hsz);
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> histimg = drawHistogram(histo, hsz)
    <span class="comment">%DRAWHISTORGRAM  Draw 1D histogram</span>

    <span class="comment">% output image</span>
    histimg = zeros(hsz, <span class="string">'uint8'</span>);
    nbins = numel(histo);
    binW = hsz(2) / nbins;

    <span class="comment">%clr = uint8(hsv(nbins) * 255);</span>
    clr = zeros([nbins 1 3], <span class="string">'uint8'</span>);
    clr(:,1) = uint8(linspace(0,180,nbins));
    clr(:,2:3) = 255;
    clr = cv.cvtColor(clr, <span class="string">'HSV2RGB'</span>);
    clr = permute(clr, [1 3 2]);

    <span class="comment">% draw bars</span>
    <span class="keyword">for</span> i=1:nbins
        val = round(histo(i)/255 * hsz(1));
        histimg = cv.rectangle(histimg, <span class="keyword">...</span>
            [(i-1)*binW, hsz(1)], [i*binW, hsz(1) - val], <span class="keyword">...</span>
            <span class="string">'Color'</span>,clr(i,:), <span class="string">'Thickness'</span>,<span class="string">'Filled'</span>);
    <span class="keyword">end</span>

    <span class="comment">% show number of bins</span>
    histimg = cv.putText(histimg, sprintf(<span class="string">'nbins = %2d'</span>, nbins), [10 20], <span class="keyword">...</span>
        <span class="string">'FontScale'</span>,0.5, <span class="string">'Color'</span>,[255 255 255], <span class="string">'LineType'</span>,<span class="string">'AA'</span>);
<span class="keyword">end</span>

<span class="keyword">function</span> out = drawSelection(out, rct)
    <span class="comment">%DRAWSELECTION  Draw selection rectangle</span>

    <span class="keyword">if</span> true
        <span class="comment">% invert selection region</span>
        rctmask = zeros(size(out,1), size(out,2), <span class="string">'uint8'</span>);
        rctmask = cv.rectangle(rctmask, rct, <span class="string">'Color'</span>,255, <span class="string">'Thickness'</span>,<span class="string">'Filled'</span>);
        out = cv.bitwise_not(out, <span class="string">'Dest'</span>,out, <span class="string">'Mask'</span>,rctmask);
    <span class="keyword">else</span>
        <span class="comment">% draw rectangle around selection region</span>
        out = cv.rectangle(out, rct, <span class="string">'Color'</span>,[0 255 0], <span class="string">'Thickness'</span>,2);
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> p = getCurrentPoint(ax)
    <span class="comment">%GETCURRENTPOINT  Retrieve current mouse location</span>

    p = get(ax, <span class="string">'CurrentPoint'</span>);
    p = p(1,1:2) - 1;
<span class="keyword">end</span>

<span class="keyword">function</span> h = buildGUI(img, app)
    <span class="comment">%BUILDGUI  Creates the UI</span>

    <span class="comment">% parameters</span>
    histimg = drawHistogram(app.histo, app.hsz);
    hsz = app.hsz;
    sz = app.sz;
    sz(2) = max(sz(2), 250);  <span class="comment">% minimum figure width</span>
    hsz(2) = sz(2);

    <span class="comment">% build the user interface (no resizing to keep it simple)</span>
    h = struct();
    h.fig = figure(<span class="string">'Name'</span>,<span class="string">'CAMShift'</span>, <span class="string">'NumberTitle'</span>,<span class="string">'off'</span>, <span class="string">'Menubar'</span>,<span class="string">'none'</span>, <span class="keyword">...</span>
        <span class="string">'Resize'</span>,<span class="string">'off'</span>, <span class="string">'Position'</span>,[200 200 sz(2) sz(1)+hsz(1)+80-1]);
    <span class="keyword">if</span> ~mexopencv.isOctave()
        <span class="comment">%HACK: not implemented in Octave</span>
        movegui(h.fig, <span class="string">'center'</span>);
    <span class="keyword">end</span>
    h.ax(1) = axes(<span class="string">'Parent'</span>,h.fig, <span class="keyword">...</span>
        <span class="string">'Units'</span>,<span class="string">'pixels'</span>, <span class="string">'Position'</span>,[1 80 sz(2) hsz(1)]);
    h.ax(2) = axes(<span class="string">'Parent'</span>,h.fig, <span class="keyword">...</span>
        <span class="string">'Units'</span>,<span class="string">'pixels'</span>, <span class="string">'Position'</span>,[1 hsz(1)+80 sz(2) sz(1)]);
    <span class="keyword">if</span> ~mexopencv.isOctave()
        h.img(1) = imshow(histimg, <span class="string">'Parent'</span>,h.ax(1));
        h.img(2) = imshow(img, <span class="string">'Parent'</span>,h.ax(2));
    <span class="keyword">else</span>
        <span class="comment">%HACK: https://savannah.gnu.org/bugs/index.php?45473</span>
        axes(h.ax(1));
        h.img(1) = imshow(histimg);
        axes(h.ax(2));
        h.img(2) = imshow(img);
    <span class="keyword">end</span>
    h.txt(1) = uicontrol(<span class="string">'Parent'</span>,h.fig, <span class="string">'Style'</span>,<span class="string">'text'</span>, <span class="keyword">...</span>
        <span class="string">'Position'</span>,[5 5 130 20], <span class="string">'FontSize'</span>,11, <span class="keyword">...</span>
        <span class="string">'String'</span>,sprintf(<span class="string">'Vmin: %3d'</span>,app.vmin));
    h.txt(2) = uicontrol(<span class="string">'Parent'</span>,h.fig, <span class="string">'Style'</span>,<span class="string">'text'</span>, <span class="keyword">...</span>
        <span class="string">'Position'</span>,[5 30 130 20], <span class="string">'FontSize'</span>,11, <span class="keyword">...</span>
        <span class="string">'String'</span>,sprintf(<span class="string">'Vmax: %3d'</span>,app.vmax));
    h.txt(3) = uicontrol(<span class="string">'Parent'</span>,h.fig, <span class="string">'Style'</span>,<span class="string">'text'</span>, <span class="keyword">...</span>
        <span class="string">'Position'</span>,[5 55 130 20], <span class="string">'FontSize'</span>,11, <span class="keyword">...</span>
        <span class="string">'String'</span>,sprintf(<span class="string">'Smin: %3d'</span>,app.smin));
    h.slid(1) = uicontrol(<span class="string">'Parent'</span>,h.fig, <span class="string">'Style'</span>,<span class="string">'slider'</span>, <span class="keyword">...</span>
        <span class="string">'Position'</span>,[135 5 sz(2)-135-5 20], <span class="string">'Value'</span>,app.vmin, <span class="keyword">...</span>
        <span class="string">'Min'</span>,0, <span class="string">'Max'</span>,255, <span class="string">'SliderStep'</span>,[1 10]./255);
    h.slid(2) = uicontrol(<span class="string">'Parent'</span>,h.fig, <span class="string">'Style'</span>,<span class="string">'slider'</span>, <span class="keyword">...</span>
        <span class="string">'Position'</span>,[135 30 sz(2)-135-5 20], <span class="string">'Value'</span>,app.vmax, <span class="keyword">...</span>
        <span class="string">'Min'</span>,0, <span class="string">'Max'</span>,255, <span class="string">'SliderStep'</span>,[1 10]./255);
    h.slid(3) = uicontrol(<span class="string">'Parent'</span>,h.fig, <span class="string">'Style'</span>,<span class="string">'slider'</span>, <span class="keyword">...</span>
        <span class="string">'Position'</span>,[135 55 sz(2)-135-5 20], <span class="string">'Value'</span>,app.smin, <span class="keyword">...</span>
        <span class="string">'Min'</span>,0, <span class="string">'Max'</span>,255, <span class="string">'SliderStep'</span>,[1 10]./255);
<span class="keyword">end</span></pre><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div><script type="text/x-mathjax-config">
  // https://stackoverflow.com/a/14631703/97160
  MathJax.Extension.myImg2jax = {
    version: "1.0",
    PreProcess: function (element) {
      var images = element.getElementsByTagName("img");
      for (var i = images.length - 1; i >= 0; i--) {
        var img = images[i];
        if (img.className === "equation") {
          var match = img.alt.match(/^(\$\$?)([\s\S]*)\1$/m);
          if (!match) continue;
          var script = document.createElement("script");
          script.type = "math/tex";
          if (match[1] === "$$") {script.type += ";mode=display"}
          MathJax.HTML.setScript(script, match[2]);
          img.parentNode.replaceChild(script, img);
        }
      }
    }
  };
  MathJax.Hub.Register.PreProcessor(["PreProcess", MathJax.Extension.myImg2jax]);
  </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
      <!--
##### SOURCE BEGIN #####
%% CAMShift
%
% In this demo, we learn about Meanshift and Camshift algorithms to find and
% track objects in videos.
%
% This is a demo that shows mean-shift based tracking.
% You select a color objects such as your face and it tracks it.
% It reads from video camera by default.
%
% Sources:
%
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/camshiftdemo.cpp>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/tapi/camshift.cpp>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/python/camshift.py>
% * <https://docs.opencv.org/3.2.0/db/df8/tutorial_py_meanshift.html>
%

%% Meanshift
%
% The intuition behind the meanshift is simple. Consider you have a set of
% points. (It can be a pixel distribution like histogram backprojection). You
% are given a small window (may be a circle) and you have to move that window
% to the area of maximum pixel density (or maximum number of points). It is
% illustrated in the simple image given below:
%
% <<https://docs.opencv.org/3.2.0/meanshift_basics.jpg>>
%
% The initial window is shown in blue circle with the name "C1". Its original
% center is marked in blue rectangle, named "C1_o". But if you find the
% centroid of the points inside that window, you will get the point "C1_r"
% (marked in small blue circle) which is the real centroid of window. Surely
% they don't match. So move your window such that circle of the new window
% matches with previous centroid. Again find the new centroid. Most probably,
% it won't match. So move it again, and continue the iterations such that
% center of window and its centroid falls on the same location (or with a
% small desired error). So finally what you obtain is a window with maximum
% pixel distribution. It is marked with green circle, named "C2". As you can
% see in image, it has maximum number of points. The whole process is
% demonstrated on a static image below:
%
% <<https://docs.opencv.org/3.2.0/meanshift_face.gif>>
%
% So we normally pass the histogram backprojected image and initial target
% location. When the object moves, obviously the movement is reflected in
% histogram backprojected image. As a result, meanshift algorithm moves our
% window to the new location with maximum density.
%
% To use meanshift in OpenCV, first we need to setup the target, find its
% histogram so that we can backproject the target on each frame for
% calculation of meanshift. We also need to provide initial location of
% window. For histogram, only Hue is considered here. Also, to avoid false
% values due to low light, low light values are discarded using |cv.inRange|
% function.
%
%% Camshift
%
% There is a problem with the approach described above. The window always has
% the same size even when the tracked object moves farther away or very close
% to the camera. That is not good. We need to adapt the window size with size
% and rotation of the target. Once again, the solution came from "OpenCV Labs"
% and it is called *CAMshift (Continuously Adaptive Meanshift)* published by
% Gary Bradsky in his paper
% "Computer Vision Face Tracking for Use in a Perceptual User Interface"
% in 1988.
%
% It applies meanshift first. Once meanshift converges, it updates the size of
% the window as, $s = 2 \times \sqrt{\frac{M_{00}}{256}}$. It also calculates
% the orientation of best fitting ellipse to it. Again it applies the
% meanshift with new scaled search window and previous window location. The
% process is continued until required accuracy is met.
%
% <<https://docs.opencv.org/3.2.0/camshift_face.gif>>
%
% In OpenCV, camshift is almost same as meanshift, but it returns a rotated
% rectangle (that is our result) and box parameters (used to be passed as
% search window in next iteration).
%
% For additional resources, see:
%
% * French Wikipedia page on <https://fr.wikipedia.org/wiki/Camshift Camshift>.
%   (The two animations are taken from there)
% * Bradski, G.R., "Real time face and object tracking as a component of a
%   perceptual user interface," Applications of Computer Vision, 1998.
%   WACV '98. Proceedings., Fourth IEEE Workshop on , pp.214,219, Oct 1998
%

%% Code

function varargout = camshift_demo_gui(varargin)
    % setup video capture
    cap = createVideoCapture([], 'cube');
    assert(cap.isOpened(), 'Could not initialize capturing');
    frame = cap.read();
    assert(~isempty(frame) && size(frame,3)==3 && isa(frame,'uint8'));

    % program state
    app = appState();
    app.sz = size(frame);
    app.hsz = [200 app.sz(2) 3];

    % create the UI, and hook event handlers
    h = buildGUI(frame, app);
    opts = {'Interruptible','off', 'BusyAction','cancel'};
    set(h.slid, 'Callback',@onChange, opts{:});
    set(h.fig, 'WindowKeyPressFcn',@onType, ...
        'WindowButtonDownFcn',@onMouseDown, opts{:});
    onType([], struct('Key','e'));

    if nargout > 0, varargout{1} = h; end
    if nargout > 1, varargout{2} = app; end

    % main loop
    while ishghandle(h.fig)
        % get next frame
        frame = cap.read();
        if isempty(frame), break; end
        out = frame;

        % extract hue channel, and range-threshold in HSV colorspace
        frameHSV = cv.cvtColor(frame, 'RGB2HSV');
        hue = frameHSV(:,:,1);
        mask = cv.inRange(frameHSV, ...
            [0 app.smin min(app.vmin,app.vmax)], ...
            [180 255 max(app.vmin,app.vmax)]);
        mask = uint8(mask * 255);  % logical -> uint8 (for bitwise ops)

        % process mouse selection (during onMouseMove and onMouseUp)
        if ~isempty(app.rct) && cv.Rect.area(app.rct) > 0
            % compute and display hue histogram of selection
            [app.histo, histimg] = computeHistogram(hue, mask, app.rct, app);
            set(h.img(1), 'CData',histimg);

            % highlight selection region
            out = drawSelection(out, app.rct);
        end

        % mask-out output using HSV thresholding result
        if app.threshView || ~isempty(app.rct)
            out = cv.bitwise_and(out, uint8(255), 'Mask',mask);
        end

        % check if the rectangle selection was fully made
        if ~isempty(app.win)
            % clear mouse selection once onMouseUp is triggered
            app.rct = [];

            % perform CAMShift to track object using its histogram
            backproj = cv.calcBackProject(hue, app.histo, {[0 180]}, 'Uniform',true);
            backproj = cv.bitwise_and(backproj, mask);
            [rbox, app.win] = cv.CamShift(backproj, app.win, 'Criteria',app.crit);

            % expand search window if it gets too small
            if cv.Rect.area(app.win) <= 1
                r = (min(app.sz(1:2)) + 5) / 6;
                app.win = cv.Rect.from2points(app.win(1:2) - r, app.win(1:2) + r);
                app.win = cv.Rect.intersect(app.win, [0 0 app.sz(2) app.sz(1)]);
            end

            % switch to backproject probability instead of frame as output
            if app.backprojView
                out = cv.cvtColor(backproj, 'GRAY2RGB');
            end

            % draw location of tracked object
            out = cv.ellipse(out, rbox, ...
                'Color',[0 0 255], 'Thickness',3, 'LineType','AA');
        end

        % show output
        set(h.img(2), 'CData',out);
        drawnow limitrate;
    end
    cap.release();  % release video source

    %% Callback functions
    % User draws box around object to track. This triggers CAMShift to start
    % tracking

    function onMouseDown(~,~)
        %ONMOUSEDOWN  Event handler for mouse down on figure

        % start selection
        onClear();   % clear any previous trackig
        app.pt0 = getCurrentPoint(h.ax(2));
        app.rct = [app.pt0 0 0];

        % attach event handlers, and change mouse pointer
        set(h.fig, 'Pointer','cross', ...
            'WindowButtonMotionFcn',@onMouseMove, ...
            'WindowButtonUpFcn',@onMouseUp);
    end

    function onMouseMove(~,~)
        %ONMOUSEMOVE  Event handler for mouse move on figure

        % update selection rectangle
        p = getCurrentPoint(h.ax(2));
        app.rct = cv.Rect.from2points(app.pt0, p);
        app.rct = cv.Rect.intersect(app.rct, [0 0 app.sz(2) app.sz(1)]);
    end

    function onMouseUp(~,~)
        %ONMOUSEUP  Event handler for mouse up on figure

        % detach event handlers, and restore mouse pointer
        set(h.fig, 'Pointer','arrow', ...
            'WindowButtonMotionFcn','', ...
            'WindowButtonUpFcn','');

        % finish selection
        app.pt0 = [];
        if cv.Rect.area(app.rct) > 0
            % tracking is now activate in main loop
            app.win = app.rct;
        else
            % ignore selection
            app.rct = [];
        end
    end

    function onChange(~,~)
        %ONCHANGE  Event handler for UI controls

        % retrieve current values from UI controls
        app.vmin = round(get(h.slid(1), 'Value'));
        app.vmax = round(get(h.slid(2), 'Value'));
        app.smin = round(get(h.slid(3), 'Value'));
        set(h.txt(1), 'String',sprintf('Vmin: %3d',app.vmin));
        set(h.txt(2), 'String',sprintf('Vmax: %3d',app.vmax));
        set(h.txt(3), 'String',sprintf('Smin: %3d',app.smin));
        drawnow;
    end

    function onType(~,e)
        %ONTYPE  Event handler for key press on figure

        % handle keys
        switch e.Key
            case 'h'
                helpdlg({
                    'To initialize tracking, select the object with mouse.'
                    'Hot keys:'
                    'h - this help dialog'
                    'q - quit the program'
                    'f - initialize tracking by auto-detecting face'
                    'c - clear the tracking'
                    'b - toggle backprojection probability view'
                    't - toggle threshold mask view'
                });

            case {'q', 'escape'}
                close(h.fig);

            case 'f'
                img = get(h.img(2), 'CData');  %TODO
                rct = findFace(img);
                if ~isempty(rct)
                    app.rct = rct;
                    app.win = rct;
                else
                    disp('No face detected')
                end

            case {'c', 'add', 'subtract'}
                if strcmp(e.Character, '+')
                    app.nbins = min(app.nbins + 1, 180);
                elseif strcmp(e.Character, '-')
                    app.nbins = max(app.nbins - 1, 2);
                end
                onClear();

            case 'b'
                app.backprojView = ~app.backprojView;

            case 't'
                app.threshView = ~app.threshView;
        end
    end

    function onClear()
        %ONCLEAR  Clear tracking

        % clear tracked object
        app.rct = [];
        app.win = [];
        app.histo = zeros([app.nbins 1], 'single');

        % redraw histogram
        histimg = drawHistogram(app.histo, app.hsz);
        set(h.img(1), 'CData',histimg);
    end
end

%% Helper functions

function app = appState()
    %APPSTATE  Returns initial program state

    app = struct();
    app.pt0 = [];              % mouse selection origin point
    app.rct = [];              % mouse selection rectangle
    app.win = [];              % camshift search window
    app.crit = struct('type','Count+EPS', 'maxCount',10, 'epsilon',1);  % camshift termination
    app.smin = 60;             % lower saturation threshold (HSV)
    app.vmin = 32;             % lower value threshold (HSV)
    app.vmax = 255;            % upper value threshold (HSV)
    app.nbins = 16;            % histogram size (number of bins)
    app.histo = zeros([app.nbins 1], 'single');  % hue histogram of tracked object
    app.backprojView = false;  % whether to display frame or backproj
    app.threshView = true;     % whether to display thresholded frame
end

function rct = findFace(img)
    %FINDFACE  Detect biggest face in image

    xmlfile = fullfile(mexopencv.root(),'test','haarcascade_frontalface_alt2.xml');
    classifier = cv.CascadeClassifier(xmlfile);
    gray = cv.cvtColor(img, 'RGB2GRAY');
    gray = cv.equalizeHist(gray);
    boxes = classifier.detect(gray);
    if ~isempty(boxes)
        %TODO: we can further improve this by detecting nose within face,
        % as it provides more accurate measure of skin tone with less
        % background pixels
        [~,idx] = max(cellfun(@(b) cv.Rect.area(b), boxes));
        rct = boxes{idx};
    else
        rct = [];
    end
end

function [histo, histimg] = computeHistogram(hue, mask, rct, app)
    %COMPUTEHISTOGRAM  Compute hue channel histogram

    % crop to selection rectangle
    roi = cv.Rect.crop(hue, rct);
    maskroi = cv.Rect.crop(mask, rct);

    % compute normalized hue histogram
    histo = cv.calcHist(roi, {[0 180]}, 'HistSize',app.nbins, ...
        'Uniform',true, 'Mask',maskroi);
    histo = cv.normalize(histo, 'Alpha',0, 'Beta',255, 'NormType','MinMax');

    if nargout > 1
        % draw histogram (bar chart)
        histimg = drawHistogram(histo, app.hsz);
    end
end

function histimg = drawHistogram(histo, hsz)
    %DRAWHISTORGRAM  Draw 1D histogram

    % output image
    histimg = zeros(hsz, 'uint8');
    nbins = numel(histo);
    binW = hsz(2) / nbins;

    %clr = uint8(hsv(nbins) * 255);
    clr = zeros([nbins 1 3], 'uint8');
    clr(:,1) = uint8(linspace(0,180,nbins));
    clr(:,2:3) = 255;
    clr = cv.cvtColor(clr, 'HSV2RGB');
    clr = permute(clr, [1 3 2]);

    % draw bars
    for i=1:nbins
        val = round(histo(i)/255 * hsz(1));
        histimg = cv.rectangle(histimg, ...
            [(i-1)*binW, hsz(1)], [i*binW, hsz(1) - val], ...
            'Color',clr(i,:), 'Thickness','Filled');
    end

    % show number of bins
    histimg = cv.putText(histimg, sprintf('nbins = %2d', nbins), [10 20], ...
        'FontScale',0.5, 'Color',[255 255 255], 'LineType','AA');
end

function out = drawSelection(out, rct)
    %DRAWSELECTION  Draw selection rectangle

    if true
        % invert selection region
        rctmask = zeros(size(out,1), size(out,2), 'uint8');
        rctmask = cv.rectangle(rctmask, rct, 'Color',255, 'Thickness','Filled');
        out = cv.bitwise_not(out, 'Dest',out, 'Mask',rctmask);
    else
        % draw rectangle around selection region
        out = cv.rectangle(out, rct, 'Color',[0 255 0], 'Thickness',2);
    end
end

function p = getCurrentPoint(ax)
    %GETCURRENTPOINT  Retrieve current mouse location

    p = get(ax, 'CurrentPoint');
    p = p(1,1:2) - 1;
end

function h = buildGUI(img, app)
    %BUILDGUI  Creates the UI

    % parameters
    histimg = drawHistogram(app.histo, app.hsz);
    hsz = app.hsz;
    sz = app.sz;
    sz(2) = max(sz(2), 250);  % minimum figure width
    hsz(2) = sz(2);

    % build the user interface (no resizing to keep it simple)
    h = struct();
    h.fig = figure('Name','CAMShift', 'NumberTitle','off', 'Menubar','none', ...
        'Resize','off', 'Position',[200 200 sz(2) sz(1)+hsz(1)+80-1]);
    if ~mexopencv.isOctave()
        %HACK: not implemented in Octave
        movegui(h.fig, 'center');
    end
    h.ax(1) = axes('Parent',h.fig, ...
        'Units','pixels', 'Position',[1 80 sz(2) hsz(1)]);
    h.ax(2) = axes('Parent',h.fig, ...
        'Units','pixels', 'Position',[1 hsz(1)+80 sz(2) sz(1)]);
    if ~mexopencv.isOctave()
        h.img(1) = imshow(histimg, 'Parent',h.ax(1));
        h.img(2) = imshow(img, 'Parent',h.ax(2));
    else
        %HACK: https://savannah.gnu.org/bugs/index.php?45473
        axes(h.ax(1));
        h.img(1) = imshow(histimg);
        axes(h.ax(2));
        h.img(2) = imshow(img);
    end
    h.txt(1) = uicontrol('Parent',h.fig, 'Style','text', ...
        'Position',[5 5 130 20], 'FontSize',11, ...
        'String',sprintf('Vmin: %3d',app.vmin));
    h.txt(2) = uicontrol('Parent',h.fig, 'Style','text', ...
        'Position',[5 30 130 20], 'FontSize',11, ...
        'String',sprintf('Vmax: %3d',app.vmax));
    h.txt(3) = uicontrol('Parent',h.fig, 'Style','text', ...
        'Position',[5 55 130 20], 'FontSize',11, ...
        'String',sprintf('Smin: %3d',app.smin));
    h.slid(1) = uicontrol('Parent',h.fig, 'Style','slider', ...
        'Position',[135 5 sz(2)-135-5 20], 'Value',app.vmin, ...
        'Min',0, 'Max',255, 'SliderStep',[1 10]./255);
    h.slid(2) = uicontrol('Parent',h.fig, 'Style','slider', ...
        'Position',[135 30 sz(2)-135-5 20], 'Value',app.vmax, ...
        'Min',0, 'Max',255, 'SliderStep',[1 10]./255);
    h.slid(3) = uicontrol('Parent',h.fig, 'Style','slider', ...
        'Position',[135 55 sz(2)-135-5 20], 'Value',app.smin, ...
        'Min',0, 'Max',255, 'SliderStep',[1 10]./255);
end

##### SOURCE END #####
--></body>
</html>