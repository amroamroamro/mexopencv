<!DOCTYPE html>
<html>
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   
      <!--This HTML was auto-generated from published MATLAB code.-->
      <title>Stereo Image Matching</title>
      <meta name="generator" content="MATLAB 9.2">
      <link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
      <meta name="DC.date" content="2017-11-27">
      <meta name="DC.source" content="stereo_match_demo.m">
      <link rel="stylesheet" type="text/css" href="publish_custom.css">
   </head>
   <body>
      <div class="content">
         <h1 id="1">Stereo Image Matching</h1>
         <!--introduction-->
         <p>Example of stereo image matching to produce a disparity map and point cloud generation.</p>
         <p>Resulting .ply file can also be viewed using <a href="http://meshlab.sourceforge.net/">MeshLab</a>.
         </p>
         <p>Sources:</p>
         <div>
            <ul>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/python/stereo_match.py">https://github.com/opencv/opencv/blob/3.2.0/samples/python/stereo_match.py</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/stereo_match.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/stereo_match.cpp</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/gpu/stereo_match.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/gpu/stereo_match.cpp</a></li>
               <li><a href="https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/calib3d/stereoBM/SBM_Sample.cpp">https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/calib3d/stereoBM/SBM_Sample.cpp</a></li>
               <li><a href="https://docs.opencv.org/3.2.0/dd/d53/tutorial_py_depthmap.html">https://docs.opencv.org/3.2.0/dd/d53/tutorial_py_depthmap.html</a></li>
            </ul>
         </div>
         <!--/introduction-->
         <h2 id="toc">Contents</h2>
         <div>
            <ul>
               <li><a href="#2">Theory</a></li>
               <li><a href="#3">Code</a></li>
               <li><a href="#4">Images</a></li>
               <li><a href="#7">Stereo Matching</a></li>
               <li><a href="#9">Point Cloud</a></li>
               <li><a href="#11">Helper functions</a></li>
            </ul>
         </div>
         <h2 id="2">Theory</h2>
         <p>Previously, we saw basic concepts like epipolar constraints and other related terms. We also saw that if we have two images
            of same scene, we can get depth information from that in an intuitive way. Below is an image and some simple mathematical
            formulas which prove that intuition:
         </p>
         <p><img src="https://docs.opencv.org/3.2.0/stereo_depth.jpg"></p>
         <p>The above diagram contains equivalent triangles. Writing their equivalent equations will yield us following result:</p>
         <p><img src="stereo_match_demo_eq09548238623070568391.png" alt="$$disparity = x - x' = \frac{Bf}{Z}$$" class="equation" width="159" height="31"></p>
         <p><img src="stereo_match_demo_eq12428413953531653171.png" alt="$x$" class="equation" width="8" height="7"> and <img src="stereo_match_demo_eq16467412212572334508.png" alt="$x'$" class="equation" width="12" height="12"> are the distance between points in image plane corresponding to the scene point 3D and their camera center. <img src="stereo_match_demo_eq10170753361147586657.png" alt="$B$" class="equation" width="11" height="10"> is the distance between two cameras (which we know) and <img src="stereo_match_demo_eq18096895394918367257.png" alt="$f$" class="equation" width="8" height="14"> is the focal length of camera (already known). So in short, the above equation says that the depth of a point in a scene
            is inversely proportional to the difference in distance of corresponding image points and their camera centers. So with this
            information, we can derive the depth of all pixels in an image.
         </p>
         <p>So it finds corresponding matches between two images. We have already seen how epiline constraint make this operation faster
            and accurate. Once it finds matches, it finds the disparity.
         </p>
         <h2 id="3">Code</h2><pre class="codeinput"><span class="keyword">function</span> stereo_match_demo()</pre><h2 id="4">Images</h2>
         <p>load pair of images (SGBM works with either grayscale or color images, BM only grayscale)</p><pre class="codeinput">    imgL = cv.imread(fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'aloeL.jpg'</span>), <span class="string">'Color'</span>,true);
    imgR = cv.imread(fullfile(mexopencv.root(),<span class="string">'test'</span>,<span class="string">'aloeR.jpg'</span>), <span class="string">'Color'</span>,true);
    subplot(121), imshow(imgL), title(<span class="string">'Left'</span>)
    subplot(122), imshow(imgR), title(<span class="string">'Right'</span>)</pre><img src="stereo_match_demo_01.png"><p>downscale for faster processing</p><pre class="codeinput">    scale = 0.5;
    [imgL, imgR] = scale_images(imgL, imgR, scale);
    whos <span class="string">imgL</span> <span class="string">imgR</span>
    [h,w,cn] = size(imgL);</pre><p>disparity-to-depth mapping 4x4 matrix, used to compute point cloud</p><pre class="codeinput">    <span class="keyword">if</span> true
        <span class="comment">% manually enter Q matrix</span>
        <span class="comment">% (turns points 180 deg around x-axis, so that y-axis looks up)</span>
        f = 0.8*w;  <span class="comment">% guess for local length</span>
        Q = [1 0 0 -0.5*w; 0 -1 0 0.5*h; 0 0 0 -f; 0 0 1 0];
    <span class="keyword">elseif</span> false
        <span class="comment">% images must be rectified, if not we rectify and get Q matrix</span>
        <span class="comment">% (requires calibrated stereo camera, see stereo_calibration_demo.m)</span>
        intrinsicFile = fullfile(tempdir(), <span class="string">'stereo_intrinsic.yml'</span>);
        extrinsicFile = fullfile(tempdir(), <span class="string">'stereo_extrinsic.yml'</span>);
        [imgL, imgR, Q] = rectify_images(imgL, imgR, scale, <span class="keyword">...</span>
            intrinsicFile, extrinsicFile);
    <span class="keyword">else</span>
        <span class="comment">% when empty, point cloud generation is skipped</span>
        Q = [];
    <span class="keyword">end</span>
    display(Q)</pre><pre class="codeoutput">Q =
    1.0000         0         0 -320.5000
         0   -1.0000         0  277.5000
         0         0         0 -512.8000
         0         0    1.0000         0
</pre><h2 id="7">Stereo Matching</h2>
         <p>create stereo matcher, with params tuned for 'aloe' image pair</p><pre class="codeinput">    win_size = 3;
    min_disp = 16;             <span class="comment">% 0</span>
    num_disp = 112 - min_disp; <span class="comment">% fix(w/8) + 15</span>
    num_disp = double(bitand(int32(num_disp), int32(-16))); <span class="comment">% divisible by 16</span>
    stereo = cv.StereoSGBM(<span class="string">'MinDisparity'</span>,min_disp, <span class="string">'NumDisparities'</span>,num_disp, <span class="keyword">...</span>
        <span class="string">'BlockSize'</span>,16, <span class="string">'P1'</span>,8*cn*win_size^2, <span class="string">'P2'</span>,32*cn*win_size^2, <span class="keyword">...</span>
        <span class="string">'Disp12MaxDiff'</span>,1, <span class="string">'UniquenessRatio'</span>,10, <span class="keyword">...</span>
        <span class="string">'SpeckleWindowSize'</span>,100, <span class="string">'SpeckleRange'</span>,32, <span class="string">'Mode'</span>,<span class="string">'SGBM'</span>);
    display(stereo)</pre><pre class="codeoutput">stereo = 
  StereoSGBM with properties:

                   id: 2
         MinDisparity: 16
       NumDisparities: 96
            BlockSize: 16
    SpeckleWindowSize: 100
         SpeckleRange: 32
        Disp12MaxDiff: 1
         PreFilterCap: 0
      UniquenessRatio: 10
                   P1: 216
                   P2: 864
                 Mode: 'SGBM'
</pre><p>compute disparity map (from a pair of rectified stereo images)</p><pre class="codeinput">    tic, D = stereo.compute(imgL, imgR); toc
    fprintf(<span class="string">'16-bit disparity map: min=%d, max=%d\n'</span>, min(D(:)), max(D(:)));
    D = single(D) / 16; <span class="comment">% fixed-point numbers with 4 fractional bits -&gt; float</span>
    DD = (D - stereo.MinDisparity) / stereo.NumDisparities; <span class="comment">% normalized [0,1]</span>
    figure, imshow(DD), colorbar, title(<span class="string">'Disparity'</span>)</pre><pre class="codeoutput">Elapsed time is 0.165371 seconds.
16-bit disparity map: min=240, max=1631
</pre><img src="stereo_match_demo_02.png"><h2 id="9">Point Cloud</h2><pre class="codeinput">    <span class="keyword">if</span> ~isempty(Q)
        <span class="comment">% generate 3d point cloud</span>
        ptc = create_point_cloud(D, Q, imgL, false);
        fprintf(<span class="string">'%d point cloud\n'</span>, ptc.Count);

        <span class="comment">% write point cloud to PLY file</span>
        plyfile = fullfile(tempdir(), <span class="string">'aloe.ply'</span>);
        write_point_cloud(ptc, plyfile);
        fprintf(<span class="string">'Point cloud saved to: %s\n'</span>, plyfile);

        <span class="comment">% visualize point cloud</span>
        <span class="keyword">if</span> ~mexopencv.isOctave()
            <span class="comment">%HACK: Octave hangs if we plot too many scatter points</span>
            figure, vis_point_cloud(ptc);
            title(<span class="string">'Point Cloud'</span>); xlabel(<span class="string">'X'</span>); ylabel(<span class="string">'Y'</span>); zlabel(<span class="string">'Z'</span>);
            <span class="comment">%axis([-10 10 -10 10 -20 0])</span>
        <span class="keyword">end</span>
    <span class="keyword">end</span></pre><pre class="codeoutput">228950 point cloud
Point cloud saved to: C:\Users\Amro\AppData\Local\Temp\aloe.ply
</pre><img src="stereo_match_demo_03.png"><pre class="codeinput"><span class="keyword">end</span></pre><h2 id="11">Helper functions</h2><pre class="codeinput"><span class="keyword">function</span> [imgL, imgR] = scale_images(imgL, imgR, scale)
    <span class="keyword">if</span> scale ~= 1
        <span class="keyword">if</span> scale &lt; 1
            interpo = <span class="string">'Area'</span>;
        <span class="keyword">else</span>
            interpo = <span class="string">'Cubic'</span>;
        <span class="keyword">end</span>
        imgL = cv.resize(imgL, scale, scale, <span class="string">'Interpolation'</span>,interpo);
        imgR = cv.resize(imgR, scale, scale, <span class="string">'Interpolation'</span>,interpo);
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> [imgL, imgR, Q] = rectify_images(imgL, imgR, scale, intrinsicFile, extrinsicFile)
    <span class="comment">% load params from previously calibrated stereo camera</span>
    assert(exist(intrinsicFile, <span class="string">'file'</span>) == 2, <span class="string">'missing intrinsic params'</span>);
    assert(exist(extrinsicFile, <span class="string">'file'</span>) == 2, <span class="string">'missing extrinsic params'</span>);
    I = cv.FileStorage(intrinsicFile);  <span class="comment">% intrinsic: M1, D1, M2, D2</span>
    E = cv.FileStorage(extrinsicFile);  <span class="comment">% extrinsic: R, T</span>

    <span class="comment">% account for new image size by scaling camera matrix: fx, fy, cx, cy</span>
    I.M1 = I.M1 * scale;
    I.M2 = I.M2 * scale;

    <span class="comment">% Note: we assume that cameras were calibrated using images of same size</span>
    <span class="comment">% as the original image size here, i.e: [I.width, I.height] == sz/scale)</span>
    sz = [size(imgL,2) size(imgL,1)];

    <span class="comment">% re-rectify using scaled image size</span>
    RCT = cv.stereoRectify(I.M1, I.D1, I.M2, I.D2, sz, E.R, E.T);
    Q = RCT.Q;

    <span class="comment">% apply rectification</span>
    [map11, map12] = cv.initUndistortRectifyMap(I.M1, I.D1, sz, <span class="keyword">...</span>
        <span class="string">'P'</span>,RCT.P1, <span class="string">'R'</span>,RCT.R1);
    [map21, map22] = cv.initUndistortRectifyMap(I.M2, I.D2, sz, <span class="keyword">...</span>
        <span class="string">'P'</span>,RCT.P2, <span class="string">'R'</span>,RCT.R2);
    imgL = cv.remap(imgL, map11, map12, <span class="string">'Interpolation'</span>,<span class="string">'Linear'</span>);
    imgR = cv.remap(imgR, map21, map22, <span class="string">'Interpolation'</span>,<span class="string">'Linear'</span>);
<span class="keyword">end</span>

<span class="keyword">function</span> ptc = create_point_cloud(D, Q, imgL, cvst)
    xyz = cv.reprojectImageTo3D(D, Q);
    mask = repmat(D &gt; min(D(:)), [1 1 3]);  <span class="comment">% where disparity was not computed</span>
    xyz = reshape(xyz(mask), [], 3);
    <span class="keyword">if</span> size(imgL,3) == 3
        clr = reshape(imgL(mask), [], 3);
    <span class="keyword">else</span>
        clr = repmat(imgL(mask(:,:,1)), 1, 3);
    <span class="keyword">end</span>

    <span class="keyword">if</span> nargin &lt; 4, cvst = true; <span class="keyword">end</span>
    <span class="keyword">if</span> cvst &amp;&amp; ~mexopencv.isOctave() &amp;&amp; mexopencv.require(<span class="string">'vision'</span>)
        ptc = pointCloud(xyz, <span class="string">'Color'</span>,clr);
    <span class="keyword">else</span>
        <span class="comment">%HACK: pointCloud and related functions are not implemented in Octave</span>
        ptc = struct(<span class="string">'Location'</span>,xyz, <span class="string">'Color'</span>,clr, <span class="string">'Count'</span>,size(xyz,1));
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> vis_point_cloud(ptc)
    <span class="keyword">if</span> isobject(ptc)
        pcshow(ptc);
    <span class="keyword">else</span>
        scatter3(ptc.Location(:,1), ptc.Location(:,2), ptc.Location(:,3), <span class="keyword">...</span>
            6, single(ptc.Color)/255, <span class="string">'.'</span>)
        axis <span class="string">tight</span> <span class="string">vis3d</span>
        rotate3d <span class="string">on</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>

<span class="keyword">function</span> write_point_cloud(ptc, fname)
    <span class="keyword">if</span> isobject(ptc)
        pcwrite(ptc, fname, <span class="string">'Encoding'</span>,<span class="string">'ascii'</span>);
    <span class="keyword">else</span>
        fid = fopen(fname, <span class="string">'wt'</span>);
        fprintf(fid, <span class="string">'ply\n'</span>);
        fprintf(fid, <span class="string">'format ascii 1.0\n'</span>);
        fprintf(fid, <span class="string">'element vertex %d\n'</span>, ptc.Count);
        fprintf(fid, <span class="string">'property float x\n'</span>);
        fprintf(fid, <span class="string">'property float y\n'</span>);
        fprintf(fid, <span class="string">'property float z\n'</span>);
        fprintf(fid, <span class="string">'property uchar red\n'</span>);
        fprintf(fid, <span class="string">'property uchar green\n'</span>);
        fprintf(fid, <span class="string">'property uchar blue\n'</span>);
        fprintf(fid, <span class="string">'end_header\n'</span>);
        fprintf(fid, <span class="string">'%f %f %f %d %d %d\n'</span>, [ptc.Location single(ptc.Color)].');
        fclose(fid);
    <span class="keyword">end</span>
<span class="keyword">end</span></pre><pre class="codeoutput">  Name        Size                 Bytes  Class    Attributes

  imgL      555x641x3            1067265  uint8              
  imgR      555x641x3            1067265  uint8              

</pre><div class="footer">
            <p><a href="https://www.mathworks.com/products/matlab.html">Published with MATLAB&reg; R2017a</a></p>
         </div>
      </div><script type="text/x-mathjax-config">
  // https://stackoverflow.com/a/14631703/97160
  MathJax.Extension.myImg2jax = {
    version: "1.0",
    PreProcess: function (element) {
      var images = element.getElementsByTagName("img");
      for (var i = images.length - 1; i >= 0; i--) {
        var img = images[i];
        if (img.className === "equation") {
          var match = img.alt.match(/^(\$\$?)([\s\S]*)\1$/m);
          if (!match) continue;
          var script = document.createElement("script");
          script.type = "math/tex";
          if (match[1] === "$$") {script.type += ";mode=display"}
          MathJax.HTML.setScript(script, match[2]);
          img.parentNode.replaceChild(script, img);
        }
      }
    }
  };
  MathJax.Hub.Register.PreProcessor(["PreProcess", MathJax.Extension.myImg2jax]);
  </script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML"></script>
      <!--
##### SOURCE BEGIN #####
%% Stereo Image Matching
%
% Example of stereo image matching to produce a disparity map and point cloud
% generation.
%
% Resulting .ply file can also be viewed using
% <http://meshlab.sourceforge.net/ MeshLab>.
%
% Sources:
%
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/python/stereo_match.py>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/stereo_match.cpp>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/gpu/stereo_match.cpp>
% * <https://github.com/opencv/opencv/blob/3.2.0/samples/cpp/tutorial_code/calib3d/stereoBM/SBM_Sample.cpp>
% * <https://docs.opencv.org/3.2.0/dd/d53/tutorial_py_depthmap.html>
%

%% Theory
%
% Previously, we saw basic concepts like epipolar constraints and other
% related terms. We also saw that if we have two images of same scene, we can
% get depth information from that in an intuitive way. Below is an image and
% some simple mathematical formulas which prove that intuition:
%
% <<https://docs.opencv.org/3.2.0/stereo_depth.jpg>>
%
% The above diagram contains equivalent triangles. Writing their equivalent
% equations will yield us following result:
%
% $$disparity = x - x' = \frac{Bf}{Z}$$
%
% $x$ and $x'$ are the distance between points in image plane corresponding to
% the scene point 3D and their camera center. $B$ is the distance between two
% cameras (which we know) and $f$ is the focal length of camera (already
% known). So in short, the above equation says that the depth of a point in a
% scene is inversely proportional to the difference in distance of
% corresponding image points and their camera centers. So with this
% information, we can derive the depth of all pixels in an image.
%
% So it finds corresponding matches between two images. We have already seen
% how epiline constraint make this operation faster and accurate. Once it
% finds matches, it finds the disparity.
%

%% Code

function stereo_match_demo()
    %% Images
    % load pair of images
    % (SGBM works with either grayscale or color images, BM only grayscale)
    imgL = cv.imread(fullfile(mexopencv.root(),'test','aloeL.jpg'), 'Color',true);
    imgR = cv.imread(fullfile(mexopencv.root(),'test','aloeR.jpg'), 'Color',true);
    subplot(121), imshow(imgL), title('Left')
    subplot(122), imshow(imgR), title('Right')

    %%
    % downscale for faster processing
    scale = 0.5;
    [imgL, imgR] = scale_images(imgL, imgR, scale);
    whos imgL imgR
    [h,w,cn] = size(imgL);

    %%
    % disparity-to-depth mapping 4x4 matrix, used to compute point cloud
    if true
        % manually enter Q matrix
        % (turns points 180 deg around x-axis, so that y-axis looks up)
        f = 0.8*w;  % guess for local length
        Q = [1 0 0 -0.5*w; 0 -1 0 0.5*h; 0 0 0 -f; 0 0 1 0];
    elseif false
        % images must be rectified, if not we rectify and get Q matrix
        % (requires calibrated stereo camera, see stereo_calibration_demo.m)
        intrinsicFile = fullfile(tempdir(), 'stereo_intrinsic.yml');
        extrinsicFile = fullfile(tempdir(), 'stereo_extrinsic.yml');
        [imgL, imgR, Q] = rectify_images(imgL, imgR, scale, ...
            intrinsicFile, extrinsicFile);
    else
        % when empty, point cloud generation is skipped
        Q = [];
    end
    display(Q)

    %% Stereo Matching
    % create stereo matcher, with params tuned for 'aloe' image pair
    win_size = 3;
    min_disp = 16;             % 0
    num_disp = 112 - min_disp; % fix(w/8) + 15
    num_disp = double(bitand(int32(num_disp), int32(-16))); % divisible by 16
    stereo = cv.StereoSGBM('MinDisparity',min_disp, 'NumDisparities',num_disp, ...
        'BlockSize',16, 'P1',8*cn*win_size^2, 'P2',32*cn*win_size^2, ...
        'Disp12MaxDiff',1, 'UniquenessRatio',10, ...
        'SpeckleWindowSize',100, 'SpeckleRange',32, 'Mode','SGBM');
    display(stereo)

    %%
    % compute disparity map (from a pair of rectified stereo images)
    tic, D = stereo.compute(imgL, imgR); toc
    fprintf('16-bit disparity map: min=%d, max=%d\n', min(D(:)), max(D(:)));
    D = single(D) / 16; % fixed-point numbers with 4 fractional bits -> float
    DD = (D - stereo.MinDisparity) / stereo.NumDisparities; % normalized [0,1]
    figure, imshow(DD), colorbar, title('Disparity')

    %% Point Cloud
    if ~isempty(Q)
        % generate 3d point cloud
        ptc = create_point_cloud(D, Q, imgL, false);
        fprintf('%d point cloud\n', ptc.Count);

        % write point cloud to PLY file
        plyfile = fullfile(tempdir(), 'aloe.ply');
        write_point_cloud(ptc, plyfile);
        fprintf('Point cloud saved to: %s\n', plyfile);

        % visualize point cloud
        if ~mexopencv.isOctave()
            %HACK: Octave hangs if we plot too many scatter points
            figure, vis_point_cloud(ptc);
            title('Point Cloud'); xlabel('X'); ylabel('Y'); zlabel('Z');
            %axis([-10 10 -10 10 -20 0])
        end
    end
end

%% Helper functions

function [imgL, imgR] = scale_images(imgL, imgR, scale)
    if scale ~= 1
        if scale < 1
            interpo = 'Area';
        else
            interpo = 'Cubic';
        end
        imgL = cv.resize(imgL, scale, scale, 'Interpolation',interpo);
        imgR = cv.resize(imgR, scale, scale, 'Interpolation',interpo);
    end
end

function [imgL, imgR, Q] = rectify_images(imgL, imgR, scale, intrinsicFile, extrinsicFile)
    % load params from previously calibrated stereo camera
    assert(exist(intrinsicFile, 'file') == 2, 'missing intrinsic params');
    assert(exist(extrinsicFile, 'file') == 2, 'missing extrinsic params');
    I = cv.FileStorage(intrinsicFile);  % intrinsic: M1, D1, M2, D2
    E = cv.FileStorage(extrinsicFile);  % extrinsic: R, T

    % account for new image size by scaling camera matrix: fx, fy, cx, cy
    I.M1 = I.M1 * scale;
    I.M2 = I.M2 * scale;

    % Note: we assume that cameras were calibrated using images of same size
    % as the original image size here, i.e: [I.width, I.height] == sz/scale)
    sz = [size(imgL,2) size(imgL,1)];

    % re-rectify using scaled image size
    RCT = cv.stereoRectify(I.M1, I.D1, I.M2, I.D2, sz, E.R, E.T);
    Q = RCT.Q;

    % apply rectification
    [map11, map12] = cv.initUndistortRectifyMap(I.M1, I.D1, sz, ...
        'P',RCT.P1, 'R',RCT.R1);
    [map21, map22] = cv.initUndistortRectifyMap(I.M2, I.D2, sz, ...
        'P',RCT.P2, 'R',RCT.R2);
    imgL = cv.remap(imgL, map11, map12, 'Interpolation','Linear');
    imgR = cv.remap(imgR, map21, map22, 'Interpolation','Linear');
end

function ptc = create_point_cloud(D, Q, imgL, cvst)
    xyz = cv.reprojectImageTo3D(D, Q);
    mask = repmat(D > min(D(:)), [1 1 3]);  % where disparity was not computed
    xyz = reshape(xyz(mask), [], 3);
    if size(imgL,3) == 3
        clr = reshape(imgL(mask), [], 3);
    else
        clr = repmat(imgL(mask(:,:,1)), 1, 3);
    end

    if nargin < 4, cvst = true; end
    if cvst && ~mexopencv.isOctave() && mexopencv.require('vision')
        ptc = pointCloud(xyz, 'Color',clr);
    else
        %HACK: pointCloud and related functions are not implemented in Octave
        ptc = struct('Location',xyz, 'Color',clr, 'Count',size(xyz,1));
    end
end

function vis_point_cloud(ptc)
    if isobject(ptc)
        pcshow(ptc);
    else
        scatter3(ptc.Location(:,1), ptc.Location(:,2), ptc.Location(:,3), ...
            6, single(ptc.Color)/255, '.')
        axis tight vis3d
        rotate3d on
    end
end

function write_point_cloud(ptc, fname)
    if isobject(ptc)
        pcwrite(ptc, fname, 'Encoding','ascii');
    else
        fid = fopen(fname, 'wt');
        fprintf(fid, 'ply\n');
        fprintf(fid, 'format ascii 1.0\n');
        fprintf(fid, 'element vertex %d\n', ptc.Count);
        fprintf(fid, 'property float x\n');
        fprintf(fid, 'property float y\n');
        fprintf(fid, 'property float z\n');
        fprintf(fid, 'property uchar red\n');
        fprintf(fid, 'property uchar green\n');
        fprintf(fid, 'property uchar blue\n');
        fprintf(fid, 'end_header\n');
        fprintf(fid, '%f %f %f %d %d %d\n', [ptc.Location single(ptc.Color)].');
        fclose(fid);
    end
end

##### SOURCE END #####
--></body>
</html>